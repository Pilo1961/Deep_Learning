{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de StackGan_jp.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pilo1961/Deep_Learning/blob/master/proyecto_final/stackGan_infersent_2048-p-biasFalse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FVkPIGr7YRG",
        "colab_type": "text"
      },
      "source": [
        "# Notebook setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-lVSnra7aqE",
        "colab_type": "code",
        "outputId": "7de174b5-3e51-4134-c6ab-8183f368e982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# mount drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrGnmynhB4xR",
        "colab_type": "code",
        "outputId": "75f7c7b4-6f89-4883-d548-f83474a10ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# importa modulos propios\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/')\n",
        "\n",
        "import model\n",
        "#import util"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNqBV38ewQjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imsave\n",
        "from skimage.transform import rescale\n",
        "from skimage import img_as_ubyte\n",
        "import pickle\n",
        "import datetime as dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgQ8ok-a7vC6",
        "colab_type": "text"
      },
      "source": [
        "### Modulo de utiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDkDKDkgzsyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#esto se debe de ir al modulo util\n",
        "def add_fileName(df):\n",
        "  '''\n",
        "    Add filename column to the ID-description list\n",
        "  '''\n",
        "  df['filename']='a'\n",
        "  for index, row in df.iterrows():\n",
        "      try:\n",
        "        new_name = row['ID'][:-6] + '_' + row['ID'][-1] + '.jpg'\n",
        "        row['filename']=new_name\n",
        "      except:\n",
        "        found_n.append(row['ID'])\n",
        "\n",
        "  return df\n",
        "\n",
        "def train_test(df):\n",
        "  x_train = df[df.index % 5 != 0]     # Excludes every 5th row starting from 0\n",
        "  x_test = df[df.index % 5 == 0]      # Selects every 5th row starting from 0\n",
        "  #print(x_train.shape)\n",
        "  #print(x_test.shape)  \n",
        "  return x_train, x_test\n",
        "\n",
        "\n",
        "# Load image\n",
        "def load_image(img_id,src='Flicker8k_Dataset/'):\n",
        "    I = imread('/content/drive/My Drive/'+src+img_id)\n",
        "    #I = margin_img(I)\n",
        "    return I\n",
        "\n",
        "# Hacemos un pickle que tiene un arreglo de numpy con toda la informacion de las imagenes\n",
        "# ojo:\n",
        "#file not found:  2258277193_586949ec62.j_1.jpg\n",
        "#file not found:  2258277193_586949ec62.j_2.jpg\n",
        "#file not found:  2258277193_586949ec62.j_3.jpg\n",
        "#file not found:  2258277193_586949ec62.j_4.jpg\n",
        "\n",
        "def img_train_pickle(x_train):\n",
        "  src='test_64/'\n",
        "  img_train=[]\n",
        "  print(\"Images to load: \", len(x_train[\"filename\"]))\n",
        "  for i, img_name in enumerate(x_train[\"filename\"]):\n",
        "    try:\n",
        "      img=load_image(img_name,src)\n",
        "      img_train.append(img)\n",
        "    except:\n",
        "      print(\"file not found: \",img_name)\n",
        "    if i%3000==0: print(\"Loaded images: \",i)\n",
        "  \n",
        "  img_train=np.array(img_train)\n",
        "  \n",
        "  with open(\"/content/drive/My Drive/img_test_data.pkl\", 'wb') as f:\n",
        "    pickle.dump(img_train,f) \n",
        "  \n",
        "def save_rgb_img(img, path, epoca=None):\n",
        "    \"\"\"\n",
        "    Save a rgb image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image infersent 2024, epoca {}\".format(epoca))\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFWxJBV47t9L",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "## Image list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY52LMsuzs1U",
        "colab_type": "code",
        "outputId": "5348be28-e887-4fe3-dede-417effadbfa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Flickr8k.token.txt\", sep='\\t', names=['ID', 'Text'], index_col=False)\n",
        "df=add_fileName(df)\n",
        "print(df.shape)\n",
        "\n",
        "# Remove entries with nan values\n",
        "df.dropna(inplace=True)\n",
        "df.isnull().values.any()\n",
        "df.head()\n",
        "\n",
        "#Quito los registros de una imagen que falta\n",
        "df.drop([6730,6731,6732,6733,6734],inplace=True)\n",
        "df.reset_index()\n",
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40460, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40455, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v6oPqorCQgj",
        "colab_type": "text"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_wFVCDnzs4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(\"/content/drive/My Drive/embeddings_jp/infersent_2048_encoding.pkl\", 'rb') as f:\n",
        "  embedding = pickle.load(f) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8YrhJk8DGI3",
        "colab_type": "code",
        "outputId": "5501adc7-9135-4056-9139-5c3f8356d084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(embedding.shape)\n",
        "embedding[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40455, 2048)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.39345706, 0.40068054, 0.        , ..., 0.25473678, 0.        ,\n",
              "        0.        ],\n",
              "       [0.45194066, 0.35207438, 0.17238629, ..., 0.29099917, 0.        ,\n",
              "        0.        ],\n",
              "       [0.24859764, 0.41610572, 0.01076891, ..., 0.47545895, 0.        ,\n",
              "        0.        ],\n",
              "       [0.18924333, 0.46832794, 0.17909272, ..., 0.42658257, 0.        ,\n",
              "        0.        ],\n",
              "       [0.29078767, 0.35777974, 0.12543346, ..., 0.4609754 , 0.        ,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X32yOjfFEl_Q",
        "colab_type": "code",
        "outputId": "86dec68c-ab48-47fc-c3df-d3bb6a170f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df_emb=pd.DataFrame(embedding)\n",
        "df_emb.head()\n",
        "\n",
        "#solo correr esto si se necesita borrar la foto que no esta\n",
        "#Quito los registros de una imagen que falta\n",
        "#df_emb.drop([6730,6731,6732,6733,6734],inplace=True)\n",
        "#df_emb.reset_index()\n",
        "#df_emb.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "      <th>2018</th>\n",
              "      <th>2019</th>\n",
              "      <th>2020</th>\n",
              "      <th>2021</th>\n",
              "      <th>2022</th>\n",
              "      <th>2023</th>\n",
              "      <th>2024</th>\n",
              "      <th>2025</th>\n",
              "      <th>2026</th>\n",
              "      <th>2027</th>\n",
              "      <th>2028</th>\n",
              "      <th>2029</th>\n",
              "      <th>2030</th>\n",
              "      <th>2031</th>\n",
              "      <th>2032</th>\n",
              "      <th>2033</th>\n",
              "      <th>2034</th>\n",
              "      <th>2035</th>\n",
              "      <th>2036</th>\n",
              "      <th>2037</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.393457</td>\n",
              "      <td>0.400681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.605102</td>\n",
              "      <td>0.603657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.310660</td>\n",
              "      <td>0.460136</td>\n",
              "      <td>0.629839</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.429817</td>\n",
              "      <td>0.330119</td>\n",
              "      <td>0.199772</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.466192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.296616</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.110367</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010036</td>\n",
              "      <td>0.047128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.688111</td>\n",
              "      <td>0.292551</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375790</td>\n",
              "      <td>0.251747</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208159</td>\n",
              "      <td>0.17865</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.180510</td>\n",
              "      <td>0.623039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.210284</td>\n",
              "      <td>0.028305</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.306471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.455848</td>\n",
              "      <td>0.986642</td>\n",
              "      <td>0.468128</td>\n",
              "      <td>0.140055</td>\n",
              "      <td>0.471230</td>\n",
              "      <td>0.109100</td>\n",
              "      <td>0.572713</td>\n",
              "      <td>0.130740</td>\n",
              "      <td>0.165485</td>\n",
              "      <td>0.235110</td>\n",
              "      <td>0.160681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.248038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.614182</td>\n",
              "      <td>0.321173</td>\n",
              "      <td>0.288185</td>\n",
              "      <td>0.429266</td>\n",
              "      <td>0.518778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.359982</td>\n",
              "      <td>0.361368</td>\n",
              "      <td>0.266434</td>\n",
              "      <td>0.250522</td>\n",
              "      <td>0.319693</td>\n",
              "      <td>0.254737</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.451941</td>\n",
              "      <td>0.352074</td>\n",
              "      <td>0.172386</td>\n",
              "      <td>0.440772</td>\n",
              "      <td>0.005154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344489</td>\n",
              "      <td>0.334634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080569</td>\n",
              "      <td>0.180571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298772</td>\n",
              "      <td>0.279546</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.932882</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.280277</td>\n",
              "      <td>0.349072</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034793</td>\n",
              "      <td>0.447044</td>\n",
              "      <td>0.434647</td>\n",
              "      <td>0.825875</td>\n",
              "      <td>0.326774</td>\n",
              "      <td>0.238294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.515401</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.04105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.337161</td>\n",
              "      <td>0.238164</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.519621</td>\n",
              "      <td>0.807512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.104816</td>\n",
              "      <td>0.360734</td>\n",
              "      <td>0.401849</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.945788</td>\n",
              "      <td>0.300323</td>\n",
              "      <td>0.406306</td>\n",
              "      <td>0.603262</td>\n",
              "      <td>0.371539</td>\n",
              "      <td>0.443428</td>\n",
              "      <td>0.057582</td>\n",
              "      <td>0.697827</td>\n",
              "      <td>0.128658</td>\n",
              "      <td>0.482927</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.498570</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278461</td>\n",
              "      <td>0.429938</td>\n",
              "      <td>0.358614</td>\n",
              "      <td>0.002374</td>\n",
              "      <td>0.684432</td>\n",
              "      <td>0.238420</td>\n",
              "      <td>0.740736</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264105</td>\n",
              "      <td>0.332310</td>\n",
              "      <td>0.084901</td>\n",
              "      <td>0.255255</td>\n",
              "      <td>0.404508</td>\n",
              "      <td>0.290999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.248598</td>\n",
              "      <td>0.416106</td>\n",
              "      <td>0.010769</td>\n",
              "      <td>0.543384</td>\n",
              "      <td>0.015789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386013</td>\n",
              "      <td>0.383023</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.369491</td>\n",
              "      <td>0.142123</td>\n",
              "      <td>0.290697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.051800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.403375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.292453</td>\n",
              "      <td>0.295890</td>\n",
              "      <td>0.766576</td>\n",
              "      <td>0.272735</td>\n",
              "      <td>0.042542</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.440485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.286601</td>\n",
              "      <td>0.406133</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135493</td>\n",
              "      <td>0.458384</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074983</td>\n",
              "      <td>0.333794</td>\n",
              "      <td>0.251219</td>\n",
              "      <td>0.212585</td>\n",
              "      <td>0.762402</td>\n",
              "      <td>0.119447</td>\n",
              "      <td>0.384135</td>\n",
              "      <td>0.442917</td>\n",
              "      <td>0.325842</td>\n",
              "      <td>0.306054</td>\n",
              "      <td>0.024473</td>\n",
              "      <td>0.833010</td>\n",
              "      <td>0.279502</td>\n",
              "      <td>0.289738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.602752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.508006</td>\n",
              "      <td>0.362864</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.809515</td>\n",
              "      <td>0.056514</td>\n",
              "      <td>0.418886</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112307</td>\n",
              "      <td>0.404958</td>\n",
              "      <td>0.074921</td>\n",
              "      <td>0.486090</td>\n",
              "      <td>0.389143</td>\n",
              "      <td>0.475459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.189243</td>\n",
              "      <td>0.468328</td>\n",
              "      <td>0.179093</td>\n",
              "      <td>0.690814</td>\n",
              "      <td>0.063529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317280</td>\n",
              "      <td>0.369442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.576502</td>\n",
              "      <td>0.254274</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.327239</td>\n",
              "      <td>0.103807</td>\n",
              "      <td>0.029828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343289</td>\n",
              "      <td>0.098532</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103317</td>\n",
              "      <td>0.448898</td>\n",
              "      <td>0.193215</td>\n",
              "      <td>0.680711</td>\n",
              "      <td>0.130816</td>\n",
              "      <td>0.235150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264838</td>\n",
              "      <td>0.147049</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054174</td>\n",
              "      <td>0.563837</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057120</td>\n",
              "      <td>0.461223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287317</td>\n",
              "      <td>0.336544</td>\n",
              "      <td>0.318999</td>\n",
              "      <td>0.742067</td>\n",
              "      <td>0.162903</td>\n",
              "      <td>0.477865</td>\n",
              "      <td>0.267034</td>\n",
              "      <td>0.250423</td>\n",
              "      <td>0.284150</td>\n",
              "      <td>0.115264</td>\n",
              "      <td>0.709942</td>\n",
              "      <td>0.201977</td>\n",
              "      <td>0.283285</td>\n",
              "      <td>0.051158</td>\n",
              "      <td>0.838226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012997</td>\n",
              "      <td>0.469488</td>\n",
              "      <td>0.238626</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.830770</td>\n",
              "      <td>0.097226</td>\n",
              "      <td>0.132916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055869</td>\n",
              "      <td>0.392147</td>\n",
              "      <td>0.074827</td>\n",
              "      <td>0.239808</td>\n",
              "      <td>0.347895</td>\n",
              "      <td>0.426583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.290788</td>\n",
              "      <td>0.357780</td>\n",
              "      <td>0.125433</td>\n",
              "      <td>0.487169</td>\n",
              "      <td>0.203958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.249074</td>\n",
              "      <td>0.345931</td>\n",
              "      <td>0.179054</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055264</td>\n",
              "      <td>0.209145</td>\n",
              "      <td>0.168953</td>\n",
              "      <td>0.061240</td>\n",
              "      <td>0.277065</td>\n",
              "      <td>0.585758</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.563393</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.281685</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.523397</td>\n",
              "      <td>0.439483</td>\n",
              "      <td>0.290979</td>\n",
              "      <td>0.403227</td>\n",
              "      <td>0.208883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.273554</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.366652</td>\n",
              "      <td>0.219396</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.481603</td>\n",
              "      <td>0.828163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501454</td>\n",
              "      <td>0.786829</td>\n",
              "      <td>0.265662</td>\n",
              "      <td>0.412488</td>\n",
              "      <td>0.631893</td>\n",
              "      <td>0.290748</td>\n",
              "      <td>0.539540</td>\n",
              "      <td>0.385839</td>\n",
              "      <td>0.218969</td>\n",
              "      <td>0.354981</td>\n",
              "      <td>0.099708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520495</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042597</td>\n",
              "      <td>0.609290</td>\n",
              "      <td>0.541537</td>\n",
              "      <td>0.129401</td>\n",
              "      <td>0.590753</td>\n",
              "      <td>0.405863</td>\n",
              "      <td>0.461316</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372925</td>\n",
              "      <td>0.251038</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>0.191232</td>\n",
              "      <td>0.499930</td>\n",
              "      <td>0.460975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2048 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3     ...      2044      2045  2046  2047\n",
              "0  0.393457  0.400681  0.000000  0.605102  ...  0.319693  0.254737   0.0   0.0\n",
              "1  0.451941  0.352074  0.172386  0.440772  ...  0.404508  0.290999   0.0   0.0\n",
              "2  0.248598  0.416106  0.010769  0.543384  ...  0.389143  0.475459   0.0   0.0\n",
              "3  0.189243  0.468328  0.179093  0.690814  ...  0.347895  0.426583   0.0   0.0\n",
              "4  0.290788  0.357780  0.125433  0.487169  ...  0.499930  0.460975   0.0   0.0\n",
              "\n",
              "[5 rows x 2048 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyE5zirIDtzS",
        "colab_type": "text"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-8wXURlDGMX",
        "colab_type": "code",
        "outputId": "47f330dd-3b01-426c-b3ef-3d3ed8c92ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "x_train, x_test= train_test(df)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "x_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32364, 3)\n",
            "(8091, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg#1</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "      <td>1000268201_693b08cb0e_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg#2</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "      <td>1000268201_693b08cb0e_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000268201_693b08cb0e.jpg#3</td>\n",
              "      <td>A little girl climbing the stairs to her playh...</td>\n",
              "      <td>1000268201_693b08cb0e_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000268201_693b08cb0e.jpg#4</td>\n",
              "      <td>A little girl in a pink dress going into a woo...</td>\n",
              "      <td>1000268201_693b08cb0e_4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1001773457_577c3a7d70.jpg#1</td>\n",
              "      <td>A black dog and a tri-colored dog playing with...</td>\n",
              "      <td>1001773457_577c3a7d70_1.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            ID  ...                     filename\n",
              "1  1000268201_693b08cb0e.jpg#1  ...  1000268201_693b08cb0e_1.jpg\n",
              "2  1000268201_693b08cb0e.jpg#2  ...  1000268201_693b08cb0e_2.jpg\n",
              "3  1000268201_693b08cb0e.jpg#3  ...  1000268201_693b08cb0e_3.jpg\n",
              "4  1000268201_693b08cb0e.jpg#4  ...  1000268201_693b08cb0e_4.jpg\n",
              "6  1001773457_577c3a7d70.jpg#1  ...  1001773457_577c3a7d70_1.jpg\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWEYHagWEP0V",
        "colab_type": "code",
        "outputId": "2e72e377-c241-4457-d8b4-f33c969255ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "emb_train, emb_test= train_test(df_emb)\n",
        "emb_train=emb_train.to_numpy()\n",
        "emb_test=emb_test.to_numpy()\n",
        "print(emb_train.shape)\n",
        "print(emb_test.shape)\n",
        "print(emb_train[:5])\n",
        "\n",
        "#emb_train=embedding\n",
        "#print(emb_train.shape)\n",
        "#emb_train[:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32364, 2048)\n",
            "(8091, 2048)\n",
            "[[0.45194066 0.35207438 0.17238629 ... 0.29099917 0.         0.        ]\n",
            " [0.24859764 0.41610572 0.01076891 ... 0.47545895 0.         0.        ]\n",
            " [0.18924333 0.46832794 0.17909272 ... 0.42658257 0.         0.        ]\n",
            " [0.29078767 0.35777974 0.12543346 ... 0.4609754  0.         0.        ]\n",
            " [0.37243274 0.         0.11580959 ... 0.5485679  0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmunFw6tEQXd",
        "colab_type": "text"
      },
      "source": [
        "# Prepara imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qm4A_My9m3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  with open(\"/content/drive/My Drive/img_train_data.pkl\", 'rb') as f:\n",
        "    img_train=pickle.load(f) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjlDZoFvzCy",
        "colab_type": "code",
        "outputId": "824c7a76-782d-4e34-d7cd-fdb756cfd23d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(img_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YR88lIBztP6",
        "colab_type": "text"
      },
      "source": [
        "# Creating models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J4j_04oz38t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bf00150-d1b2-43a2-cbaf-1d8bbc36ea3d"
      },
      "source": [
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from keras.optimizers import adam\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "import tensorflow as tf\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "from tensorflow.keras.layers import concatenate, Embedding, Dense, Dropout, Reshape, UpSampling2D, Conv2D, BatchNormalization, Activation, Input, Concatenate, LeakyReLU, Flatten, Lambda"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxIpCGnX2cL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KL_loss(y_true, y_pred):\n",
        "    mean = y_pred[:, :128]\n",
        "    logsigma = y_pred[:, :128]\n",
        "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
        "    loss = K.mean(loss)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E42XFmhJZI4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python3\n",
        "#conditional Augmentation model\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import concatenate, Embedding, Dense, Dropout, Reshape, UpSampling2D, Conv2D, BatchNormalization, Activation, Input, Concatenate, LeakyReLU, Flatten, Lambda\n",
        "\n",
        "def create_c(x):\n",
        "  '''\n",
        "    Función auxiliar a la función create_CA_model\n",
        "    genera variables condicionales\n",
        "    Mete ruido en la variable de entrada\n",
        "  '''\n",
        "  mean=x[:,:128]\n",
        "  log_sigma=x[:,128:]\n",
        "  stddev=K.exp(log_sigma)\n",
        "  epsilon=K.random_normal(shape=K.constant((mean.shape[1], ), dtype='int32'))\n",
        "  c=stddev*epsilon+mean\n",
        "\n",
        "  return c\n",
        "\n",
        "def create_CA_model(len_embedding=20):\n",
        "  '''\n",
        "    Red que genera el conditional augmentation\n",
        "    ** params:\n",
        "      * len_embedding: longitud del embedding utilizado para los textos\n",
        "    ** salida:\n",
        "      * Conditional augmentation network\n",
        "  '''\n",
        "  input_layer=Input(shape=(len_embedding,))\n",
        "  layer=Dense(256)(input_layer)\n",
        "  mean_logsigma=LeakyReLU(alpha=0.2)(layer)\n",
        "  c=Lambda(create_c)(mean_logsigma)\n",
        "\n",
        "  CA_model=Model(inputs=[input_layer],outputs=[c])\n",
        "  return CA_model\n",
        "\n",
        "# Crear red generadora\n",
        "def create_gen_st1(len_embedding=20):\n",
        "  '''\n",
        "  Crea la red generadora de la primera etapa\n",
        "  '''\n",
        "  #conditional augmentation\n",
        "  input_layer=Input(shape=(len_embedding,))\n",
        "  layer=Dense(256)(input_layer)\n",
        "  mean_logsigma=LeakyReLU(alpha=0.2)(layer)\n",
        "  c=Lambda(create_c)(mean_logsigma)\n",
        "\n",
        "  #noise from normal dist.\n",
        "  input_layer2=Input(shape=(100,))\n",
        "\n",
        "  #generate input. conditional augmentation + noise\n",
        "  gen_input=Concatenate(axis=1)([c,input_layer2])\n",
        "\n",
        "  #upsampling\n",
        "  gen_model=Dense(units=128*8*4*4,activation=\"relu\",use_bias=False)(gen_input)\n",
        "  gen_model=Reshape((4,4,128*8),input_shape=(128*8*4*4,))(gen_model)\n",
        "\n",
        "  gen_model=UpSampling2D(size=(2,2))(gen_model)\n",
        "  gen_model=Conv2D(512,kernel_size=3, padding='same', strides=1,use_bias=False)(gen_model)\n",
        "  gen_model=BatchNormalization()(gen_model)\n",
        "  gen_model=Activation('relu')(gen_model)\n",
        "\n",
        "  gen_model=UpSampling2D(size=(2,2))(gen_model)\n",
        "  gen_model=Conv2D(256,kernel_size=3, padding='same', strides=1,use_bias=False)(gen_model)\n",
        "  gen_model=BatchNormalization()(gen_model)\n",
        "  gen_model=Activation('relu')(gen_model)\n",
        "\n",
        "  gen_model=UpSampling2D(size=(2,2))(gen_model)\n",
        "  gen_model=Conv2D(128,kernel_size=3, padding='same', strides=1,use_bias=False)(gen_model)\n",
        "  gen_model=BatchNormalization()(gen_model)\n",
        "  gen_model=Activation('relu')(gen_model)\n",
        "\n",
        "  gen_model=UpSampling2D(size=(2,2))(gen_model)\n",
        "  gen_model=Conv2D(64,kernel_size=3, padding='same', strides=1,use_bias=False)(gen_model)\n",
        "  gen_model=BatchNormalization()(gen_model)\n",
        "  gen_model=Activation('relu')(gen_model)\n",
        "\n",
        "  out=Conv2D(3,kernel_size=3, padding='same', strides=1,activation='tanh')(gen_model)\n",
        "\n",
        "  generator=Model(inputs=[input_layer,input_layer2],outputs=[out,mean_logsigma])\n",
        "  return generator\n",
        "\n",
        " # Crea una red con layers Embedding, LSTM, Dense\n",
        "#discriminator = Sequential()\n",
        "def create_disc_st1():\n",
        "  '''\n",
        "  Crea la red discrimidaora de la primera etapa\n",
        "  '''\n",
        "\n",
        "  input_layer=Input(shape=(64,64,3))\n",
        "\n",
        "  disc=Conv2D(64,kernel_size=(4,4), padding='same', strides=2,use_bias=False)(input_layer)\n",
        "  disc=LeakyReLU(alpha=0.2)(disc)\n",
        "\n",
        "  disc=Conv2D(128,kernel_size=(4,4), padding='same', strides=2,use_bias=False)(disc)\n",
        "  disc=BatchNormalization()(disc)\n",
        "  disc=LeakyReLU(alpha=0.2)(disc)\n",
        "\n",
        "  disc=Conv2D(256,kernel_size=(4,4), padding='same', strides=2,use_bias=False)(disc)\n",
        "  disc=BatchNormalization()(disc)\n",
        "  disc=LeakyReLU(alpha=0.2)(disc)\n",
        "\n",
        "  disc=Conv2D(512,kernel_size=(4,4), padding='same', strides=2,use_bias=False)(disc)\n",
        "  disc=BatchNormalization()(disc)\n",
        "  disc=LeakyReLU(alpha=0.2)(disc)\n",
        "\n",
        "  input_layer2=Input(shape=(4,4,128))\n",
        "\n",
        "  merged_input=concatenate([disc,input_layer2])\n",
        "\n",
        "  disc2=Conv2D(64*8,kernel_size=1, padding='same', strides=1)(merged_input)\n",
        "  disc2=BatchNormalization()(disc2)\n",
        "  disc2=LeakyReLU(alpha=0.2)(disc2)\n",
        "\n",
        "  disc2=Flatten()(disc2)\n",
        "  disc2=Dense(1,activation='sigmoid')(disc2)\n",
        "\n",
        "  return Model(inputs=[input_layer,input_layer2],outputs=[disc2])\n",
        "\n",
        "def create_adversarial_model(gen, disc, len_embedding=20):\n",
        "  input_layer=Input(shape=(len_embedding,))\n",
        "  input_layer2=Input(shape=(100,))\n",
        "  input_layer3=Input(shape=(4,4,128))\n",
        "\n",
        "  x, mean_logsigma= gen([input_layer,input_layer2])\n",
        "\n",
        "  disc.trainable=False\n",
        "  valid=disc([x,input_layer3])\n",
        "\n",
        "  model=Model(inputs=[input_layer,input_layer2,input_layer3],outputs=[valid,mean_logsigma])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFshF-ZSzycK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_embedding=2048\n",
        "\n",
        "ca_model = create_CA_model(len_embedding=len_embedding)\n",
        "ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "stage1_dis = create_disc_st1()\n",
        "stage1_dis.compile(loss='binary_crossentropy', optimizer=\"adam\")#dis_optimizer)\n",
        "#stage1_dis.load_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_dis_50.h5\")\n",
        "\n",
        "stage1_gen = create_gen_st1(len_embedding=len_embedding)\n",
        "stage1_gen.compile(loss=\"mse\", optimizer=\"adam\")#gen_optimizer)\n",
        "#stage1_gen.load_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_gen_50.h5\")\n",
        "\n",
        "adversarial_model = create_adversarial_model(gen=stage1_gen, disc=stage1_dis,len_embedding=len_embedding)\n",
        "adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n",
        "                          optimizer=\"adam\", metrics=None)#gen_optimizer, metrics=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CmvEE3fYznc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKhtEMf9GAh1",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRt9Kq2uvkOb",
        "colab_type": "text"
      },
      "source": [
        "Earlier, label/target values for a classifier were 0 or 1; 0 for fake images and 1 for real images. Because of this, GANs were prone to adversarial examples, which are inputs to a neural network that result in an incorrect output from the network. Label smoothing is an approach to provide smoothed labels to the discriminator network. This means we can have decimal values such as 0.9 (true), 0.8 (true), 0.1 (fake), or 0.2 (fake), instead of labeling every example as either 1 (true) or 0 (fake). We smooth the target values (label values) of the real images as well as of the fake images. Label smoothing can reduce the risk of adversarial examples in GANs. To apply label smoothing, assign the labels 0.9, 0.8, and 0.7, and 0.1, 0.2, and 0.3, to the images. To find out more about label smoothing, refer to the following paper.\n",
        "\n",
        "[Improved techniques for training GAN](https://arxiv.org/pdf/1606.03498.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33c4gr7A2PGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "image_size = 64\n",
        "z_dim = 100\n",
        "stage1_generator_lr = 0.0002\n",
        "stage1_discriminator_lr = 0.0002\n",
        "stage1_lr_decay_step = 600\n",
        "epochs = 1000\n",
        "condition_dim = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ciz-XkESI0XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis_optimizer = adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "gen_optimizer = adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ew0otTFGGoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=64\n",
        "initial_epoch=0\n",
        "epochs=800\n",
        "run=1\n",
        "\n",
        "real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
        "fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
        "\n",
        "for epoch in range(initial_epoch,epochs):\n",
        "  print(\"========================================\")\n",
        "  print(\"Epoch is:\", epoch)\n",
        "  print(\"Number of batches\", int(img_train.shape[0] / batch_size))\n",
        "\n",
        "  gen_losses = []\n",
        "  dis_losses = []\n",
        "\n",
        "  number_of_batches = int(img_train.shape[0] / batch_size)\n",
        "  for index in range(number_of_batches):\n",
        "    #print(\"Batch:{}\".format(index+1))\n",
        "\n",
        "     # Create a batch of noise vectors\n",
        "    z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "    image_batch = img_train[index * batch_size:(index + 1) * batch_size]\n",
        "    embedding_batch = emb_train[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "    # Normalize images\n",
        "    image_batch = image_batch/255 #(image_batch - 127.5) / 127.5\n",
        "\n",
        "    fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n",
        "    \n",
        "    #embedding compression\n",
        "    #compressed_embedding = np.hstack((embedding_batch,embedding_batch))\n",
        "    compressed_embedding = np.reshape(embedding_batch, (batch_size, 4, 4, condition_dim))\n",
        "\n",
        "    #calc losses\n",
        "    dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],np.reshape(real_labels, (batch_size, 1)))\n",
        "    dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],np.reshape(fake_labels, (batch_size, 1)))\n",
        "    dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
        "\n",
        "    g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n",
        "\n",
        "    d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
        "\n",
        "    if index%100 ==0:\n",
        "      print(\"Batch:{}\".format(index+1))\n",
        "      print(\"d_loss:{}\".format(d_loss))  \n",
        "      print(\"g_loss:{}\".format(g_loss))\n",
        "\n",
        "    dis_losses.append(d_loss)\n",
        "    gen_losses.append(g_loss)\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    # empieza a guardar desde época 0\n",
        "    print(\"Guardo 3 imagenes\")                     \n",
        "    z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "    embedding_batch = emb_test[0:batch_size]\n",
        "    fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n",
        "\n",
        "    # Save images\n",
        "    for i, img in enumerate(fake_images[:1]):\n",
        "      show_rgb_img(img,epoch)\n",
        "      show_rgb_img((fake_images[60]+1)/2)\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Guardo pesos\")\n",
        "    stage1_gen.save_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_gen_{}.h5\".format(epoch))\n",
        "    stage1_dis.save_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_dis_{}.h5\".format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G65lzOUexYN",
        "colab_type": "text"
      },
      "source": [
        "#Aqui solamente agregue el parametro de bias=false en las redes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dR4EBZwa8cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def show_rgb_img(img, epoca=None):\n",
        "    \"\"\"\n",
        "    Save a rgb image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image infersent 2024, epoca {}\".format(epoca))\n",
        "\n",
        "    plt.show()\n",
        "    #plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPdYmYpG64Hk",
        "colab_type": "code",
        "outputId": "2213ba6d-f189-43a9-8b92-2ca91afbcba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "#salva alguna imagenes\n",
        "\n",
        "z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "embedding_batch = emb_test[0:batch_size]\n",
        "fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n",
        "\n",
        "  # Save images\n",
        "for i, img in enumerate(fake_images[:10]):\n",
        "  save_rgb_img(img, \"/content/drive/My Drive/fake_img/gen_{}_{}.png\".format(epoch, i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR479_u7HIUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# guarda los pesos de la red\n",
        "stage1_gen.save_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_gen_{}.h5\".format(epoch))\n",
        "stage1_dis.save_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_gen_{}.h5\".format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}