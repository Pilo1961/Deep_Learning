{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de StackGan_jp.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pilo1961/Deep_Learning/blob/master/proyecto_final/stackGan_infersent_2048.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FVkPIGr7YRG",
        "colab_type": "text"
      },
      "source": [
        "# Notebook setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-lVSnra7aqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "73ba2c4e-ab82-4390-dbe8-3721b768ed76"
      },
      "source": [
        "# mount drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrGnmynhB4xR",
        "colab_type": "code",
        "outputId": "75f7c7b4-6f89-4883-d548-f83474a10ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# importa modulos propios\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/')\n",
        "\n",
        "import model\n",
        "#import util"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNqBV38ewQjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imsave\n",
        "from skimage.transform import rescale\n",
        "from skimage import img_as_ubyte\n",
        "import pickle\n",
        "import datetime as dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgQ8ok-a7vC6",
        "colab_type": "text"
      },
      "source": [
        "### Modulo de utiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDkDKDkgzsyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#esto se debe de ir al modulo util\n",
        "def add_fileName(df):\n",
        "  '''\n",
        "    Add filename column to the ID-description list\n",
        "  '''\n",
        "  df['filename']='a'\n",
        "  for index, row in df.iterrows():\n",
        "      try:\n",
        "        new_name = row['ID'][:-6] + '_' + row['ID'][-1] + '.jpg'\n",
        "        row['filename']=new_name\n",
        "      except:\n",
        "        found_n.append(row['ID'])\n",
        "\n",
        "  return df\n",
        "\n",
        "def train_test(df):\n",
        "  x_train = df[df.index % 5 != 0]     # Excludes every 5th row starting from 0\n",
        "  x_test = df[df.index % 5 == 0]      # Selects every 5th row starting from 0\n",
        "  #print(x_train.shape)\n",
        "  #print(x_test.shape)  \n",
        "  return x_train, x_test\n",
        "\n",
        "\n",
        "# Load image\n",
        "def load_image(img_id,src='Flicker8k_Dataset/'):\n",
        "    I = imread('/content/drive/My Drive/'+src+img_id)\n",
        "    #I = margin_img(I)\n",
        "    return I\n",
        "\n",
        "# Hacemos un pickle que tiene un arreglo de numpy con toda la informacion de las imagenes\n",
        "# ojo:\n",
        "#file not found:  2258277193_586949ec62.j_1.jpg\n",
        "#file not found:  2258277193_586949ec62.j_2.jpg\n",
        "#file not found:  2258277193_586949ec62.j_3.jpg\n",
        "#file not found:  2258277193_586949ec62.j_4.jpg\n",
        "\n",
        "def img_train_pickle(x_train):\n",
        "  src='test_64/'\n",
        "  img_train=[]\n",
        "  print(\"Images to load: \", len(x_train[\"filename\"]))\n",
        "  for i, img_name in enumerate(x_train[\"filename\"]):\n",
        "    try:\n",
        "      img=load_image(img_name,src)\n",
        "      img_train.append(img)\n",
        "    except:\n",
        "      print(\"file not found: \",img_name)\n",
        "    if i%3000==0: print(\"Loaded images: \",i)\n",
        "  \n",
        "  img_train=np.array(img_train)\n",
        "  \n",
        "  with open(\"/content/drive/My Drive/img_test_data.pkl\", 'wb') as f:\n",
        "    pickle.dump(img_train,f) \n",
        "  \n",
        "  def save_rgb_img(img, path, epoca=None):\n",
        "    \"\"\"\n",
        "    Save a rgb image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image infersent 2024, epoca {}\".format(epoca))\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFWxJBV47t9L",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "## Image list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY52LMsuzs1U",
        "colab_type": "code",
        "outputId": "baee84f6-ac13-432f-923d-133069f88c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Flickr8k.token.txt\", sep='\\t', names=['ID', 'Text'], index_col=False)\n",
        "df=add_fileName(df)\n",
        "print(df.shape)\n",
        "\n",
        "# Remove entries with nan values\n",
        "df.dropna(inplace=True)\n",
        "df.isnull().values.any()\n",
        "df.head()\n",
        "\n",
        "#Quito los registros de una imagen que falta\n",
        "df.drop([6730,6731,6732,6733,6734],inplace=True)\n",
        "df.reset_index()\n",
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40460, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40455, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v6oPqorCQgj",
        "colab_type": "text"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_wFVCDnzs4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(\"/content/drive/My Drive/embeddings_jp/infersent_2048_encoding.pkl\", 'rb') as f:\n",
        "  embedding = pickle.load(f) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8YrhJk8DGI3",
        "colab_type": "code",
        "outputId": "0e2a83af-210a-4011-f097-d9b484707175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(embedding.shape)\n",
        "embedding[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40455, 2048)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.39345706, 0.40068054, 0.        , ..., 0.25473678, 0.        ,\n",
              "        0.        ],\n",
              "       [0.45194066, 0.35207438, 0.17238629, ..., 0.29099917, 0.        ,\n",
              "        0.        ],\n",
              "       [0.24859764, 0.41610572, 0.01076891, ..., 0.47545895, 0.        ,\n",
              "        0.        ],\n",
              "       [0.18924333, 0.46832794, 0.17909272, ..., 0.42658257, 0.        ,\n",
              "        0.        ],\n",
              "       [0.29078767, 0.35777974, 0.12543346, ..., 0.4609754 , 0.        ,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X32yOjfFEl_Q",
        "colab_type": "code",
        "outputId": "30f4fd93-ff53-4d41-d0dc-f94759500cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df_emb=pd.DataFrame(embedding)\n",
        "df_emb.head()\n",
        "\n",
        "#solo correr esto si se necesita borrar la foto que no esta\n",
        "#Quito los registros de una imagen que falta\n",
        "#df_emb.drop([6730,6731,6732,6733,6734],inplace=True)\n",
        "#df_emb.reset_index()\n",
        "#df_emb.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "      <th>2018</th>\n",
              "      <th>2019</th>\n",
              "      <th>2020</th>\n",
              "      <th>2021</th>\n",
              "      <th>2022</th>\n",
              "      <th>2023</th>\n",
              "      <th>2024</th>\n",
              "      <th>2025</th>\n",
              "      <th>2026</th>\n",
              "      <th>2027</th>\n",
              "      <th>2028</th>\n",
              "      <th>2029</th>\n",
              "      <th>2030</th>\n",
              "      <th>2031</th>\n",
              "      <th>2032</th>\n",
              "      <th>2033</th>\n",
              "      <th>2034</th>\n",
              "      <th>2035</th>\n",
              "      <th>2036</th>\n",
              "      <th>2037</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.393457</td>\n",
              "      <td>0.400681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.605102</td>\n",
              "      <td>0.603657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.310660</td>\n",
              "      <td>0.460136</td>\n",
              "      <td>0.629839</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.429817</td>\n",
              "      <td>0.330119</td>\n",
              "      <td>0.199772</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.466192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.296616</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.110367</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010036</td>\n",
              "      <td>0.047128</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.688111</td>\n",
              "      <td>0.292551</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375790</td>\n",
              "      <td>0.251747</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208159</td>\n",
              "      <td>0.17865</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.180510</td>\n",
              "      <td>0.623039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.210284</td>\n",
              "      <td>0.028305</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.306471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.455848</td>\n",
              "      <td>0.986642</td>\n",
              "      <td>0.468128</td>\n",
              "      <td>0.140055</td>\n",
              "      <td>0.471230</td>\n",
              "      <td>0.109100</td>\n",
              "      <td>0.572713</td>\n",
              "      <td>0.130740</td>\n",
              "      <td>0.165485</td>\n",
              "      <td>0.235110</td>\n",
              "      <td>0.160681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.248038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.614182</td>\n",
              "      <td>0.321173</td>\n",
              "      <td>0.288185</td>\n",
              "      <td>0.429266</td>\n",
              "      <td>0.518778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.359982</td>\n",
              "      <td>0.361368</td>\n",
              "      <td>0.266434</td>\n",
              "      <td>0.250522</td>\n",
              "      <td>0.319693</td>\n",
              "      <td>0.254737</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.451941</td>\n",
              "      <td>0.352074</td>\n",
              "      <td>0.172386</td>\n",
              "      <td>0.440772</td>\n",
              "      <td>0.005154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344489</td>\n",
              "      <td>0.334634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.080569</td>\n",
              "      <td>0.180571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298772</td>\n",
              "      <td>0.279546</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.932882</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.280277</td>\n",
              "      <td>0.349072</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034793</td>\n",
              "      <td>0.447044</td>\n",
              "      <td>0.434647</td>\n",
              "      <td>0.825875</td>\n",
              "      <td>0.326774</td>\n",
              "      <td>0.238294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.515401</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.04105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.337161</td>\n",
              "      <td>0.238164</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.519621</td>\n",
              "      <td>0.807512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.104816</td>\n",
              "      <td>0.360734</td>\n",
              "      <td>0.401849</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.945788</td>\n",
              "      <td>0.300323</td>\n",
              "      <td>0.406306</td>\n",
              "      <td>0.603262</td>\n",
              "      <td>0.371539</td>\n",
              "      <td>0.443428</td>\n",
              "      <td>0.057582</td>\n",
              "      <td>0.697827</td>\n",
              "      <td>0.128658</td>\n",
              "      <td>0.482927</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.498570</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278461</td>\n",
              "      <td>0.429938</td>\n",
              "      <td>0.358614</td>\n",
              "      <td>0.002374</td>\n",
              "      <td>0.684432</td>\n",
              "      <td>0.238420</td>\n",
              "      <td>0.740736</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264105</td>\n",
              "      <td>0.332310</td>\n",
              "      <td>0.084901</td>\n",
              "      <td>0.255255</td>\n",
              "      <td>0.404508</td>\n",
              "      <td>0.290999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.248598</td>\n",
              "      <td>0.416106</td>\n",
              "      <td>0.010769</td>\n",
              "      <td>0.543384</td>\n",
              "      <td>0.015789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386013</td>\n",
              "      <td>0.383023</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366081</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.369491</td>\n",
              "      <td>0.142123</td>\n",
              "      <td>0.290697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.051800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.403375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.292453</td>\n",
              "      <td>0.295890</td>\n",
              "      <td>0.766576</td>\n",
              "      <td>0.272735</td>\n",
              "      <td>0.042542</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.440485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.286601</td>\n",
              "      <td>0.406133</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135493</td>\n",
              "      <td>0.458384</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074983</td>\n",
              "      <td>0.333794</td>\n",
              "      <td>0.251219</td>\n",
              "      <td>0.212585</td>\n",
              "      <td>0.762402</td>\n",
              "      <td>0.119447</td>\n",
              "      <td>0.384135</td>\n",
              "      <td>0.442917</td>\n",
              "      <td>0.325842</td>\n",
              "      <td>0.306054</td>\n",
              "      <td>0.024473</td>\n",
              "      <td>0.833010</td>\n",
              "      <td>0.279502</td>\n",
              "      <td>0.289738</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.602752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.508006</td>\n",
              "      <td>0.362864</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.809515</td>\n",
              "      <td>0.056514</td>\n",
              "      <td>0.418886</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112307</td>\n",
              "      <td>0.404958</td>\n",
              "      <td>0.074921</td>\n",
              "      <td>0.486090</td>\n",
              "      <td>0.389143</td>\n",
              "      <td>0.475459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.189243</td>\n",
              "      <td>0.468328</td>\n",
              "      <td>0.179093</td>\n",
              "      <td>0.690814</td>\n",
              "      <td>0.063529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317280</td>\n",
              "      <td>0.369442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.576502</td>\n",
              "      <td>0.254274</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.327239</td>\n",
              "      <td>0.103807</td>\n",
              "      <td>0.029828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343289</td>\n",
              "      <td>0.098532</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103317</td>\n",
              "      <td>0.448898</td>\n",
              "      <td>0.193215</td>\n",
              "      <td>0.680711</td>\n",
              "      <td>0.130816</td>\n",
              "      <td>0.235150</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264838</td>\n",
              "      <td>0.147049</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.054174</td>\n",
              "      <td>0.563837</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057120</td>\n",
              "      <td>0.461223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287317</td>\n",
              "      <td>0.336544</td>\n",
              "      <td>0.318999</td>\n",
              "      <td>0.742067</td>\n",
              "      <td>0.162903</td>\n",
              "      <td>0.477865</td>\n",
              "      <td>0.267034</td>\n",
              "      <td>0.250423</td>\n",
              "      <td>0.284150</td>\n",
              "      <td>0.115264</td>\n",
              "      <td>0.709942</td>\n",
              "      <td>0.201977</td>\n",
              "      <td>0.283285</td>\n",
              "      <td>0.051158</td>\n",
              "      <td>0.838226</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012997</td>\n",
              "      <td>0.469488</td>\n",
              "      <td>0.238626</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.830770</td>\n",
              "      <td>0.097226</td>\n",
              "      <td>0.132916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055869</td>\n",
              "      <td>0.392147</td>\n",
              "      <td>0.074827</td>\n",
              "      <td>0.239808</td>\n",
              "      <td>0.347895</td>\n",
              "      <td>0.426583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.290788</td>\n",
              "      <td>0.357780</td>\n",
              "      <td>0.125433</td>\n",
              "      <td>0.487169</td>\n",
              "      <td>0.203958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.249074</td>\n",
              "      <td>0.345931</td>\n",
              "      <td>0.179054</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.055264</td>\n",
              "      <td>0.209145</td>\n",
              "      <td>0.168953</td>\n",
              "      <td>0.061240</td>\n",
              "      <td>0.277065</td>\n",
              "      <td>0.585758</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.563393</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.281685</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.523397</td>\n",
              "      <td>0.439483</td>\n",
              "      <td>0.290979</td>\n",
              "      <td>0.403227</td>\n",
              "      <td>0.208883</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.273554</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.366652</td>\n",
              "      <td>0.219396</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.481603</td>\n",
              "      <td>0.828163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501454</td>\n",
              "      <td>0.786829</td>\n",
              "      <td>0.265662</td>\n",
              "      <td>0.412488</td>\n",
              "      <td>0.631893</td>\n",
              "      <td>0.290748</td>\n",
              "      <td>0.539540</td>\n",
              "      <td>0.385839</td>\n",
              "      <td>0.218969</td>\n",
              "      <td>0.354981</td>\n",
              "      <td>0.099708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520495</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042597</td>\n",
              "      <td>0.609290</td>\n",
              "      <td>0.541537</td>\n",
              "      <td>0.129401</td>\n",
              "      <td>0.590753</td>\n",
              "      <td>0.405863</td>\n",
              "      <td>0.461316</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372925</td>\n",
              "      <td>0.251038</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>0.191232</td>\n",
              "      <td>0.499930</td>\n",
              "      <td>0.460975</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2048 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3     ...      2044      2045  2046  2047\n",
              "0  0.393457  0.400681  0.000000  0.605102  ...  0.319693  0.254737   0.0   0.0\n",
              "1  0.451941  0.352074  0.172386  0.440772  ...  0.404508  0.290999   0.0   0.0\n",
              "2  0.248598  0.416106  0.010769  0.543384  ...  0.389143  0.475459   0.0   0.0\n",
              "3  0.189243  0.468328  0.179093  0.690814  ...  0.347895  0.426583   0.0   0.0\n",
              "4  0.290788  0.357780  0.125433  0.487169  ...  0.499930  0.460975   0.0   0.0\n",
              "\n",
              "[5 rows x 2048 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyE5zirIDtzS",
        "colab_type": "text"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-8wXURlDGMX",
        "colab_type": "code",
        "outputId": "1e2f8215-182c-4995-ddf0-71460856d551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "x_train, x_test= train_test(df)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "x_train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32364, 3)\n",
            "(8091, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg#1</td>\n",
              "      <td>A girl going into a wooden building .</td>\n",
              "      <td>1000268201_693b08cb0e_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg#2</td>\n",
              "      <td>A little girl climbing into a wooden playhouse .</td>\n",
              "      <td>1000268201_693b08cb0e_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000268201_693b08cb0e.jpg#3</td>\n",
              "      <td>A little girl climbing the stairs to her playh...</td>\n",
              "      <td>1000268201_693b08cb0e_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000268201_693b08cb0e.jpg#4</td>\n",
              "      <td>A little girl in a pink dress going into a woo...</td>\n",
              "      <td>1000268201_693b08cb0e_4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1001773457_577c3a7d70.jpg#1</td>\n",
              "      <td>A black dog and a tri-colored dog playing with...</td>\n",
              "      <td>1001773457_577c3a7d70_1.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            ID  ...                     filename\n",
              "1  1000268201_693b08cb0e.jpg#1  ...  1000268201_693b08cb0e_1.jpg\n",
              "2  1000268201_693b08cb0e.jpg#2  ...  1000268201_693b08cb0e_2.jpg\n",
              "3  1000268201_693b08cb0e.jpg#3  ...  1000268201_693b08cb0e_3.jpg\n",
              "4  1000268201_693b08cb0e.jpg#4  ...  1000268201_693b08cb0e_4.jpg\n",
              "6  1001773457_577c3a7d70.jpg#1  ...  1001773457_577c3a7d70_1.jpg\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWEYHagWEP0V",
        "colab_type": "code",
        "outputId": "94c5ab00-f113-46ec-e279-d6d0cd8275ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "emb_train, emb_test= train_test(df_emb)\n",
        "emb_train=emb_train.to_numpy()\n",
        "emb_test=emb_test.to_numpy()\n",
        "print(emb_train.shape)\n",
        "print(emb_test.shape)\n",
        "print(emb_train[:5])\n",
        "\n",
        "#emb_train=embedding\n",
        "#print(emb_train.shape)\n",
        "#emb_train[:5]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32364, 2048)\n",
            "(8091, 2048)\n",
            "[[0.45194066 0.35207438 0.17238629 ... 0.29099917 0.         0.        ]\n",
            " [0.24859764 0.41610572 0.01076891 ... 0.47545895 0.         0.        ]\n",
            " [0.18924333 0.46832794 0.17909272 ... 0.42658257 0.         0.        ]\n",
            " [0.29078767 0.35777974 0.12543346 ... 0.4609754  0.         0.        ]\n",
            " [0.37243274 0.         0.11580959 ... 0.5485679  0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmunFw6tEQXd",
        "colab_type": "text"
      },
      "source": [
        "# Prepara imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qm4A_My9m3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  with open(\"/content/drive/My Drive/img_train_data.pkl\", 'rb') as f:\n",
        "    img_train=pickle.load(f) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjlDZoFvzCy",
        "colab_type": "code",
        "outputId": "72524e63-bb3c-4d01-d383-d23258cb228f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(img_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YR88lIBztP6",
        "colab_type": "text"
      },
      "source": [
        "# Creating models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J4j_04oz38t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from keras.optimizers import adam\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "import tensorflow as tf\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "from tensorflow.keras.layers import concatenate, Embedding, Dense, Dropout, Reshape, UpSampling2D, Conv2D, BatchNormalization, Activation, Input, Concatenate, LeakyReLU, Flatten, Lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxIpCGnX2cL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KL_loss(y_true, y_pred):\n",
        "    mean = y_pred[:, :128]\n",
        "    logsigma = y_pred[:, :128]\n",
        "    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))\n",
        "    loss = K.mean(loss)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFshF-ZSzycK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_embedding=2048\n",
        "\n",
        "ca_model = model.create_CA_model(len_embedding=len_embedding)\n",
        "ca_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "stage1_dis = model.create_disc_st1()\n",
        "stage1_dis.compile(loss='binary_crossentropy', optimizer=\"adam\")#dis_optimizer)\n",
        "stage1_dis.load_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_dis_50.h5\")\n",
        "\n",
        "stage1_gen = model.create_gen_st1(len_embedding=len_embedding)\n",
        "stage1_gen.compile(loss=\"mse\", optimizer=\"adam\")#gen_optimizer)\n",
        "stage1_gen.load_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_gen_50.h5\")\n",
        "\n",
        "adversarial_model = model.create_adversarial_model(gen=stage1_gen, disc=stage1_dis,len_embedding=len_embedding)\n",
        "adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],\n",
        "                          optimizer=\"adam\", metrics=None)#gen_optimizer, metrics=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKhtEMf9GAh1",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRt9Kq2uvkOb",
        "colab_type": "text"
      },
      "source": [
        "Earlier, label/target values for a classifier were 0 or 1; 0 for fake images and 1 for real images. Because of this, GANs were prone to adversarial examples, which are inputs to a neural network that result in an incorrect output from the network. Label smoothing is an approach to provide smoothed labels to the discriminator network. This means we can have decimal values such as 0.9 (true), 0.8 (true), 0.1 (fake), or 0.2 (fake), instead of labeling every example as either 1 (true) or 0 (fake). We smooth the target values (label values) of the real images as well as of the fake images. Label smoothing can reduce the risk of adversarial examples in GANs. To apply label smoothing, assign the labels 0.9, 0.8, and 0.7, and 0.1, 0.2, and 0.3, to the images. To find out more about label smoothing, refer to the following paper.\n",
        "\n",
        "[Improved techniques for training GAN](https://arxiv.org/pdf/1606.03498.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33c4gr7A2PGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "image_size = 64\n",
        "z_dim = 100\n",
        "stage1_generator_lr = 0.0002\n",
        "stage1_discriminator_lr = 0.0002\n",
        "stage1_lr_decay_step = 600\n",
        "epochs = 1000\n",
        "condition_dim = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ciz-XkESI0XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis_optimizer = adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "gen_optimizer = adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ew0otTFGGoj",
        "colab_type": "code",
        "outputId": "d1328d3c-d216-4853-9bed-2fe1873ff617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size=64\n",
        "initial_epoch=51\n",
        "epochs=800\n",
        "run=1\n",
        "\n",
        "real_labels = np.ones((batch_size, 1), dtype=float) * 0.9\n",
        "fake_labels = np.zeros((batch_size, 1), dtype=float) * 0.1\n",
        "\n",
        "for epoch in range(initial_epoch,epochs):\n",
        "  print(\"========================================\")\n",
        "  print(\"Epoch is:\", epoch)\n",
        "  print(\"Number of batches\", int(img_train.shape[0] / batch_size))\n",
        "\n",
        "  gen_losses = []\n",
        "  dis_losses = []\n",
        "\n",
        "  number_of_batches = int(img_train.shape[0] / batch_size)\n",
        "  for index in range(number_of_batches):\n",
        "    #print(\"Batch:{}\".format(index+1))\n",
        "\n",
        "     # Create a batch of noise vectors\n",
        "    z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "    image_batch = img_train[index * batch_size:(index + 1) * batch_size]\n",
        "    embedding_batch = emb_train[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "    # Normalize images\n",
        "    image_batch = image_batch/255 #(image_batch - 127.5) / 127.5\n",
        "\n",
        "    fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)\n",
        "    \n",
        "    #embedding compression\n",
        "    #compressed_embedding = np.hstack((embedding_batch,embedding_batch))\n",
        "    compressed_embedding = np.reshape(embedding_batch, (batch_size, 4, 4, condition_dim))\n",
        "\n",
        "    #calc losses\n",
        "    dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],np.reshape(real_labels, (batch_size, 1)))\n",
        "    dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],np.reshape(fake_labels, (batch_size, 1)))\n",
        "    dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],np.reshape(fake_labels[1:], (batch_size-1, 1)))\n",
        "\n",
        "    g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])\n",
        "\n",
        "    d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
        "\n",
        "    if index%100 ==0:\n",
        "      print(\"Batch:{}\".format(index+1))\n",
        "      print(\"d_loss:{}\".format(d_loss))  \n",
        "      print(\"g_loss:{}\".format(g_loss))\n",
        "\n",
        "    dis_losses.append(d_loss)\n",
        "    gen_losses.append(g_loss)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    # empieza a guardar desde época 0\n",
        "    print(\"Guardo 3 imagenes\")                     \n",
        "    z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "    embedding_batch = emb_test[0:batch_size]\n",
        "    fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n",
        "\n",
        "    # Save images\n",
        "    for i, img in enumerate(fake_images[:3]):\n",
        "      save_rgb_img(img,\"/content/drive/My Drive/red_infersent_2048/gen_{}_{}_{}.png\".format(epoch, i,run),epoch)\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Guardo pesos\")\n",
        "    stage1_gen.save_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_gen_{}.h5\".format(epoch))\n",
        "    stage1_dis.save_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_dis_{}.h5\".format(epoch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Epoch is: 51\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5368343296590865\n",
            "g_loss:[0.6363070011138916, 0.6069129109382629, 0.014697052538394928]\n",
            "Batch:101\n",
            "d_loss:0.5378536449879903\n",
            "g_loss:[0.5868242383003235, 0.5866566896438599, 8.378174243262038e-05]\n",
            "Batch:201\n",
            "d_loss:0.5384612063071472\n",
            "g_loss:[0.5836842656135559, 0.583597719669342, 4.3278712837491184e-05]\n",
            "Batch:301\n",
            "d_loss:0.5383608004158305\n",
            "g_loss:[0.5707008838653564, 0.5700867176055908, 0.00030708746635355055]\n",
            "Batch:401\n",
            "d_loss:0.538533612916126\n",
            "g_loss:[0.579799473285675, 0.5795214772224426, 0.00013901179772801697]\n",
            "Batch:501\n",
            "d_loss:0.5385474181639438\n",
            "g_loss:[0.5624805688858032, 0.5623764991760254, 5.2031176892342046e-05]\n",
            "========================================\n",
            "Epoch is: 52\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.538578778909141\n",
            "g_loss:[0.5554980039596558, 0.5553098917007446, 9.404910815646872e-05]\n",
            "Batch:101\n",
            "d_loss:0.5386251189029281\n",
            "g_loss:[0.5590745210647583, 0.5577826499938965, 0.0006459472933784127]\n",
            "Batch:201\n",
            "d_loss:0.5386971976427049\n",
            "g_loss:[0.7248667478561401, 0.7177637815475464, 0.0035514896735548973]\n",
            "Batch:301\n",
            "d_loss:0.5384583466907316\n",
            "g_loss:[0.7550169825553894, 0.754716157913208, 0.00015039840945973992]\n",
            "Batch:401\n",
            "d_loss:0.5386122635627544\n",
            "g_loss:[0.7596542835235596, 0.7594809532165527, 8.665859058964998e-05]\n",
            "Batch:501\n",
            "d_loss:0.5385480470054063\n",
            "g_loss:[0.7590939998626709, 0.7590283155441284, 3.2842559448909014e-05]\n",
            "========================================\n",
            "Epoch is: 53\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5386416514502343\n",
            "g_loss:[0.7552163004875183, 0.7551525235176086, 3.1901217880658805e-05]\n",
            "Batch:101\n",
            "d_loss:0.5387836153308854\n",
            "g_loss:[0.7590169310569763, 0.7588035464286804, 0.00010667863534763455]\n",
            "Batch:201\n",
            "d_loss:0.5386990039405646\n",
            "g_loss:[0.7545395493507385, 0.7533900737762451, 0.000574734469410032]\n",
            "Batch:301\n",
            "d_loss:0.5384621180646718\n",
            "g_loss:[0.7488539218902588, 0.7484262585639954, 0.0002138464478775859]\n",
            "Batch:401\n",
            "d_loss:0.5387143861298682\n",
            "g_loss:[0.7555258870124817, 0.7553154230117798, 0.00010521856893319637]\n",
            "Batch:501\n",
            "d_loss:0.5385194360742389\n",
            "g_loss:[0.7529058456420898, 0.7518119215965271, 0.0005469691241160035]\n",
            "========================================\n",
            "Epoch is: 54\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5386757688193029\n",
            "g_loss:[0.7479407787322998, 0.7472154498100281, 0.0003626639081630856]\n",
            "Batch:101\n",
            "d_loss:0.5387645664650336\n",
            "g_loss:[0.7544565796852112, 0.7526851892471313, 0.0008857061038725078]\n",
            "Batch:201\n",
            "d_loss:0.5387675902429692\n",
            "g_loss:[0.7534940838813782, 0.7512785196304321, 0.0011077721137553453]\n",
            "Batch:301\n",
            "d_loss:0.5384798951508856\n",
            "g_loss:[0.7429398894309998, 0.7425113916397095, 0.00021424111037049443]\n",
            "Batch:401\n",
            "d_loss:0.5388171219756259\n",
            "g_loss:[0.7558895349502563, 0.754278838634491, 0.0008053560741245747]\n",
            "Batch:501\n",
            "d_loss:0.5384887583104501\n",
            "g_loss:[0.7522326111793518, 0.751528263092041, 0.0003521844046190381]\n",
            "========================================\n",
            "Epoch is: 55\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5388702685427234\n",
            "g_loss:[0.7558097839355469, 0.7514439225196838, 0.0021829158067703247]\n",
            "Batch:101\n",
            "d_loss:0.5388383931094722\n",
            "g_loss:[0.7501569390296936, 0.7487473487854004, 0.00070479407440871]\n",
            "Batch:201\n",
            "d_loss:0.5387696435664111\n",
            "g_loss:[0.7486305236816406, 0.7473728656768799, 0.0006288158474490047]\n",
            "Batch:301\n",
            "d_loss:0.538404206096402\n",
            "g_loss:[0.7395316958427429, 0.7389161586761475, 0.00030776095809414983]\n",
            "Batch:401\n",
            "d_loss:0.5394246569412644\n",
            "g_loss:[0.7637681365013123, 0.7597329616546631, 0.0020175883546471596]\n",
            "Batch:501\n",
            "d_loss:0.5383397064315432\n",
            "g_loss:[0.7467648386955261, 0.7465158700942993, 0.0001244822342414409]\n",
            "========================================\n",
            "Epoch is: 56\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5387743986880196\n",
            "g_loss:[0.7399623394012451, 0.7395440340042114, 0.00020915549248456955]\n",
            "Batch:101\n",
            "d_loss:0.5389330052294099\n",
            "g_loss:[0.7404968738555908, 0.7393656373023987, 0.0005656080320477486]\n",
            "Batch:201\n",
            "d_loss:0.5387040649511619\n",
            "g_loss:[0.7360868453979492, 0.7357656359672546, 0.00016060334746725857]\n",
            "Batch:301\n",
            "d_loss:0.5383170033301212\n",
            "g_loss:[0.7169559597969055, 0.7132652997970581, 0.0018453325610607862]\n",
            "Batch:401\n",
            "d_loss:0.5390334095113758\n",
            "g_loss:[0.70652836561203, 0.7049005031585693, 0.0008139301789924502]\n",
            "Batch:501\n",
            "d_loss:0.5381497800162833\n",
            "g_loss:[0.6160205602645874, 0.6151654720306396, 0.0004275323008187115]\n",
            "========================================\n",
            "Epoch is: 57\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5390235016075167\n",
            "g_loss:[0.5901132822036743, 0.589155912399292, 0.0004786851932294667]\n",
            "Batch:101\n",
            "d_loss:0.5390758400749291\n",
            "g_loss:[0.732330858707428, 0.7305819392204285, 0.0008744645747356117]\n",
            "Batch:201\n",
            "d_loss:0.538711938810593\n",
            "g_loss:[0.7425751686096191, 0.740536630153656, 0.0010192643385380507]\n",
            "Batch:301\n",
            "d_loss:0.5381075391046579\n",
            "g_loss:[0.7311537265777588, 0.7282555103302002, 0.0014490957837551832]\n",
            "Batch:401\n",
            "d_loss:0.5391357511193746\n",
            "g_loss:[0.7389882802963257, 0.7384661436080933, 0.00026105361757799983]\n",
            "Batch:501\n",
            "d_loss:0.5380402910900557\n",
            "g_loss:[0.7255796194076538, 0.7211995124816895, 0.0021900488063693047]\n",
            "========================================\n",
            "Epoch is: 58\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.539025741241403\n",
            "g_loss:[0.7151913642883301, 0.7112427949905396, 0.001974293729290366]\n",
            "Batch:101\n",
            "d_loss:0.5390718065182227\n",
            "g_loss:[0.6881200075149536, 0.6861890554428101, 0.0009654663153924048]\n",
            "Batch:201\n",
            "d_loss:0.53863686840441\n",
            "g_loss:[0.7373524904251099, 0.7345698475837708, 0.0013913288712501526]\n",
            "Batch:301\n",
            "d_loss:0.5376902188218082\n",
            "g_loss:[0.7196826338768005, 0.7191499471664429, 0.0002663462655618787]\n",
            "Batch:401\n",
            "d_loss:0.5392548239851749\n",
            "g_loss:[0.7339828610420227, 0.7334866523742676, 0.0002480976691003889]\n",
            "Batch:501\n",
            "d_loss:0.5377729454103246\n",
            "g_loss:[0.7242392301559448, 0.7235575318336487, 0.0003408447082620114]\n",
            "========================================\n",
            "Epoch is: 59\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5387495125723945\n",
            "g_loss:[0.7212030291557312, 0.7199982404708862, 0.000602385844103992]\n",
            "Batch:101\n",
            "d_loss:0.5388575040769865\n",
            "g_loss:[0.7203734517097473, 0.7190674543380737, 0.0006530077662318945]\n",
            "Batch:201\n",
            "d_loss:0.5383169021097274\n",
            "g_loss:[0.7204915881156921, 0.7202116847038269, 0.00013996372581459582]\n",
            "Batch:301\n",
            "d_loss:0.5367022839509445\n",
            "g_loss:[0.6991986632347107, 0.6977929472923279, 0.0007028598338365555]\n",
            "Batch:401\n",
            "d_loss:0.5391843084416905\n",
            "g_loss:[0.7112048268318176, 0.7106278538703918, 0.0002884932910092175]\n",
            "Batch:501\n",
            "d_loss:0.5375719450785255\n",
            "g_loss:[0.6963675618171692, 0.695709228515625, 0.000329164118738845]\n",
            "========================================\n",
            "Epoch is: 60\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.538399627961553\n",
            "g_loss:[0.6855207681655884, 0.6844309568405151, 0.0005449154996313155]\n",
            "Batch:101\n",
            "d_loss:0.5383381205119804\n",
            "g_loss:[0.6914557814598083, 0.6892352104187012, 0.0011102887801826]\n",
            "Batch:201\n",
            "d_loss:0.5378124844974081\n",
            "g_loss:[0.7026068568229675, 0.7011074423789978, 0.0007497214828617871]\n",
            "Batch:301\n",
            "d_loss:0.5349991411094379\n",
            "g_loss:[0.67023104429245, 0.6690816879272461, 0.0005746635142713785]\n",
            "Batch:401\n",
            "d_loss:0.538871743341133\n",
            "g_loss:[0.7087542414665222, 0.7074360251426697, 0.0006591108394786716]\n",
            "Batch:501\n",
            "d_loss:0.537092779829436\n",
            "g_loss:[0.6885367631912231, 0.6877893805503845, 0.00037367764161899686]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 61\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5376393625820128\n",
            "g_loss:[0.6942551136016846, 0.6935511827468872, 0.0003519640304148197]\n",
            "Batch:101\n",
            "d_loss:0.537593082186504\n",
            "g_loss:[0.6940734386444092, 0.6925802826881409, 0.0007465928792953491]\n",
            "Batch:201\n",
            "d_loss:0.5375198283309146\n",
            "g_loss:[0.6793403625488281, 0.6784065961837769, 0.00046687066787853837]\n",
            "Batch:301\n",
            "d_loss:0.5327101816028517\n",
            "g_loss:[0.6616237759590149, 0.6610556840896606, 0.00028404215117916465]\n",
            "Batch:401\n",
            "d_loss:0.5377091493592161\n",
            "g_loss:[0.6541091799736023, 0.6534849405288696, 0.00031213127658702433]\n",
            "Batch:501\n",
            "d_loss:0.5366136663778889\n",
            "g_loss:[0.6291225552558899, 0.6247596144676208, 0.0021814601495862007]\n",
            "========================================\n",
            "Epoch is: 62\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5370284700720731\n",
            "g_loss:[0.6262786984443665, 0.6250131130218506, 0.0006327901501208544]\n",
            "Batch:101\n",
            "d_loss:0.5362767289143449\n",
            "g_loss:[0.6118224859237671, 0.6098285913467407, 0.0009969386737793684]\n",
            "Batch:201\n",
            "d_loss:0.536776044707949\n",
            "g_loss:[0.6022705435752869, 0.5990391969680786, 0.001615660497918725]\n",
            "Batch:301\n",
            "d_loss:0.5295355821217527\n",
            "g_loss:[0.5700496435165405, 0.5669001936912537, 0.0015747144352644682]\n",
            "Batch:401\n",
            "d_loss:0.5374291214038749\n",
            "g_loss:[0.5627402067184448, 0.5602409839630127, 0.001249605556949973]\n",
            "Batch:501\n",
            "d_loss:0.5355518419200962\n",
            "g_loss:[0.5180715918540955, 0.5169034004211426, 0.0005840820958837867]\n",
            "========================================\n",
            "Epoch is: 63\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5362559991017406\n",
            "g_loss:[0.5087802410125732, 0.5082213878631592, 0.0002794178144540638]\n",
            "Batch:101\n",
            "d_loss:0.5341325314798269\n",
            "g_loss:[0.5558593273162842, 0.5538968443870544, 0.000981250312179327]\n",
            "Batch:201\n",
            "d_loss:0.5363066036857163\n",
            "g_loss:[0.5519083142280579, 0.5507897138595581, 0.0005593116511590779]\n",
            "Batch:301\n",
            "d_loss:0.5282327044760677\n",
            "g_loss:[0.4649987518787384, 0.4623541235923767, 0.001322307507507503]\n",
            "Batch:401\n",
            "d_loss:0.536422444370146\n",
            "g_loss:[0.46010535955429077, 0.45819854736328125, 0.0009534067939966917]\n",
            "Batch:501\n",
            "d_loss:0.5350866919634427\n",
            "g_loss:[0.4644906520843506, 0.46426522731781006, 0.00011271580297034234]\n",
            "========================================\n",
            "Epoch is: 64\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5358408155211691\n",
            "g_loss:[0.4577206075191498, 0.4574599862098694, 0.0001303165772696957]\n",
            "Batch:101\n",
            "d_loss:0.5317038475741356\n",
            "g_loss:[0.46382609009742737, 0.46221494674682617, 0.00080557179171592]\n",
            "Batch:201\n",
            "d_loss:0.5351731324435605\n",
            "g_loss:[0.4819079637527466, 0.4809378385543823, 0.0004850662953685969]\n",
            "Batch:301\n",
            "d_loss:0.5268992648143467\n",
            "g_loss:[0.5986595153808594, 0.5737593770027161, 0.012450057081878185]\n",
            "Batch:401\n",
            "d_loss:0.5364314872804243\n",
            "g_loss:[0.5990915298461914, 0.5982587933540344, 0.0004163553239777684]\n",
            "Batch:501\n",
            "d_loss:0.5343335703073535\n",
            "g_loss:[0.579818069934845, 0.5796454548835754, 8.630807133158669e-05]\n",
            "========================================\n",
            "Epoch is: 65\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5349015197880362\n",
            "g_loss:[0.5983135104179382, 0.5980944037437439, 0.000109559201519005]\n",
            "Batch:101\n",
            "d_loss:0.5309084464652187\n",
            "g_loss:[0.45239290595054626, 0.45123252272605896, 0.0005801910883747041]\n",
            "Batch:201\n",
            "d_loss:0.5345583160974456\n",
            "g_loss:[0.3593340218067169, 0.35905271768569946, 0.00014064513379707932]\n",
            "Batch:301\n",
            "d_loss:0.52534984797785\n",
            "g_loss:[0.3276234567165375, 0.3273147940635681, 0.00015433350927196443]\n",
            "Batch:401\n",
            "d_loss:0.5360465911235224\n",
            "g_loss:[0.36435332894325256, 0.3639594614505768, 0.00019692671776283532]\n",
            "Batch:501\n",
            "d_loss:0.533154353764985\n",
            "g_loss:[0.39558297395706177, 0.3941156268119812, 0.0007336748531088233]\n",
            "========================================\n",
            "Epoch is: 66\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5346390945951498\n",
            "g_loss:[0.3979819118976593, 0.3942822217941284, 0.0018498522695153952]\n",
            "Batch:101\n",
            "d_loss:0.5289789373000531\n",
            "g_loss:[0.39881354570388794, 0.3979039192199707, 0.0004548078286461532]\n",
            "Batch:201\n",
            "d_loss:0.5335832884611591\n",
            "g_loss:[0.47087499499320984, 0.4683668911457062, 0.0012540512252599]\n",
            "Batch:301\n",
            "d_loss:0.5233800101195811\n",
            "g_loss:[0.38470935821533203, 0.38392412662506104, 0.00039261984056793153]\n",
            "Batch:401\n",
            "d_loss:0.535471027375479\n",
            "g_loss:[0.46533921360969543, 0.46227648854255676, 0.0015313634648919106]\n",
            "Batch:501\n",
            "d_loss:0.5315719400368835\n",
            "g_loss:[0.516767680644989, 0.5143484473228455, 0.0012096163118258119]\n",
            "========================================\n",
            "Epoch is: 67\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5333441477323504\n",
            "g_loss:[0.5284010767936707, 0.5267287492752075, 0.0008361660875380039]\n",
            "Batch:101\n",
            "d_loss:0.5270352853613076\n",
            "g_loss:[0.4937014579772949, 0.4914722442626953, 0.0011146112810820341]\n",
            "Batch:201\n",
            "d_loss:0.5327713788215078\n",
            "g_loss:[0.39687007665634155, 0.3964843153953552, 0.00019287352915853262]\n",
            "Batch:301\n",
            "d_loss:0.5215376518071935\n",
            "g_loss:[0.3351741135120392, 0.3349810540676117, 9.652318840380758e-05]\n",
            "Batch:401\n",
            "d_loss:0.5345768237798438\n",
            "g_loss:[0.3280665874481201, 0.3272450566291809, 0.000410767097491771]\n",
            "Batch:501\n",
            "d_loss:0.5291211852968445\n",
            "g_loss:[0.3277382552623749, 0.3257181644439697, 0.001010044477880001]\n",
            "========================================\n",
            "Epoch is: 68\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5325816936465344\n",
            "g_loss:[0.32626625895500183, 0.3256719708442688, 0.00029714585980400443]\n",
            "Batch:101\n",
            "d_loss:0.5252341844707189\n",
            "g_loss:[0.3422425091266632, 0.3420409858226776, 0.00010076445323647931]\n",
            "Batch:201\n",
            "d_loss:0.5309438992626383\n",
            "g_loss:[0.33873438835144043, 0.3383367657661438, 0.00019880800391547382]\n",
            "Batch:301\n",
            "d_loss:0.5176234855198345\n",
            "g_loss:[0.3342222273349762, 0.33397895097732544, 0.00012163718929514289]\n",
            "Batch:401\n",
            "d_loss:0.5357142382836173\n",
            "g_loss:[0.32984814047813416, 0.3295116424560547, 0.00016824493650346994]\n",
            "Batch:501\n",
            "d_loss:0.5266073331949883\n",
            "g_loss:[0.33288052678108215, 0.3314310908317566, 0.0007247129105962813]\n",
            "========================================\n",
            "Epoch is: 69\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5325472770264241\n",
            "g_loss:[0.3323545753955841, 0.3314143419265747, 0.00047011542483232915]\n",
            "Batch:101\n",
            "d_loss:0.5222144682074941\n",
            "g_loss:[0.3498322069644928, 0.3488650321960449, 0.00048358520143665373]\n",
            "Batch:201\n",
            "d_loss:0.5293305023860739\n",
            "g_loss:[0.3550876975059509, 0.35439807176589966, 0.0003448112984187901]\n",
            "Batch:301\n",
            "d_loss:0.5131239270917831\n",
            "g_loss:[0.3366023898124695, 0.33036553859710693, 0.0031184274703264236]\n",
            "Batch:401\n",
            "d_loss:0.5353623447435893\n",
            "g_loss:[0.3329828381538391, 0.33136099576950073, 0.0008109183982014656]\n",
            "Batch:501\n",
            "d_loss:0.5240095068356823\n",
            "g_loss:[0.3420012295246124, 0.3414120078086853, 0.0002946133608929813]\n",
            "========================================\n",
            "Epoch is: 70\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5323251278514363\n",
            "g_loss:[0.34262093901634216, 0.3422430157661438, 0.0001889576087705791]\n",
            "Batch:101\n",
            "d_loss:0.5198424188947683\n",
            "g_loss:[0.34117358922958374, 0.3377011716365814, 0.0017362093785777688]\n",
            "Batch:201\n",
            "d_loss:0.5266191322266423\n",
            "g_loss:[0.3670996129512787, 0.36408284306526184, 0.0015083893667906523]\n",
            "Batch:301\n",
            "d_loss:0.5074258687527617\n",
            "g_loss:[0.3561515808105469, 0.3557882308959961, 0.00018166968948207796]\n",
            "Batch:401\n",
            "d_loss:0.5369111172722114\n",
            "g_loss:[0.3279270529747009, 0.32759353518486023, 0.00016676136874593794]\n",
            "Batch:501\n",
            "d_loss:0.5206783189719317\n",
            "g_loss:[0.3282635807991028, 0.32745569944381714, 0.0004039451014250517]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 71\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5305974095263082\n",
            "g_loss:[0.3294244408607483, 0.3285595178604126, 0.0004324684268794954]\n",
            "Batch:101\n",
            "d_loss:0.516328104848526\n",
            "g_loss:[0.3297930359840393, 0.32819265127182007, 0.0008001878159120679]\n",
            "Batch:201\n",
            "d_loss:0.5234179682447575\n",
            "g_loss:[0.3340940773487091, 0.3335241675376892, 0.00028494943398982286]\n",
            "Batch:301\n",
            "d_loss:0.5035014596296605\n",
            "g_loss:[0.32929104566574097, 0.32878944277763367, 0.0002507941971998662]\n",
            "Batch:401\n",
            "d_loss:0.5358871036287383\n",
            "g_loss:[0.3276144564151764, 0.3273237347602844, 0.00014535858645103872]\n",
            "Batch:501\n",
            "d_loss:0.5153302775488555\n",
            "g_loss:[0.33110037446022034, 0.3292638063430786, 0.0009182823705486953]\n",
            "========================================\n",
            "Epoch is: 72\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5278544438810968\n",
            "g_loss:[0.3286401927471161, 0.32679063081741333, 0.0009247857378795743]\n",
            "Batch:101\n",
            "d_loss:0.5137049366203428\n",
            "g_loss:[0.33973556756973267, 0.3375459611415863, 0.0010948004201054573]\n",
            "Batch:201\n",
            "d_loss:0.5204387174107978\n",
            "g_loss:[0.33580896258354187, 0.33510658144950867, 0.0003511933609843254]\n",
            "Batch:301\n",
            "d_loss:0.49647437609564804\n",
            "g_loss:[0.33964282274246216, 0.33733439445495605, 0.0011542148422449827]\n",
            "Batch:401\n",
            "d_loss:0.5349453056705897\n",
            "g_loss:[0.34301143884658813, 0.34191417694091797, 0.0005486253648996353]\n",
            "Batch:501\n",
            "d_loss:0.5106380918496143\n",
            "g_loss:[0.33193284273147583, 0.32939016819000244, 0.0012713323812931776]\n",
            "========================================\n",
            "Epoch is: 73\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.52729632714545\n",
            "g_loss:[0.3300342559814453, 0.32862454652786255, 0.0007048490224406123]\n",
            "Batch:101\n",
            "d_loss:0.5109050578125789\n",
            "g_loss:[0.3302396833896637, 0.32849544286727905, 0.0008721198537386954]\n",
            "Batch:201\n",
            "d_loss:0.5161717518431033\n",
            "g_loss:[0.33147427439689636, 0.32978928089141846, 0.0008424936095252633]\n",
            "Batch:301\n",
            "d_loss:0.4906345245481134\n",
            "g_loss:[0.3340299725532532, 0.33378052711486816, 0.0001247273467015475]\n",
            "Batch:401\n",
            "d_loss:0.53315480024321\n",
            "g_loss:[0.3319043517112732, 0.3279636800289154, 0.0019703374709933996]\n",
            "Batch:501\n",
            "d_loss:0.5051739222544711\n",
            "g_loss:[0.3311209976673126, 0.32750219106674194, 0.001809402252547443]\n",
            "========================================\n",
            "Epoch is: 74\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5230883565241129\n",
            "g_loss:[0.33032873272895813, 0.32833877205848694, 0.0009949766099452972]\n",
            "Batch:101\n",
            "d_loss:0.5098056270235247\n",
            "g_loss:[0.3358033299446106, 0.3307890295982361, 0.002507150638848543]\n",
            "Batch:201\n",
            "d_loss:0.5119087295315694\n",
            "g_loss:[0.3348937928676605, 0.3325023055076599, 0.001195736462250352]\n",
            "Batch:301\n",
            "d_loss:0.48469896276583313\n",
            "g_loss:[0.337319552898407, 0.336337685585022, 0.0004909287672489882]\n",
            "Batch:401\n",
            "d_loss:0.5297070040724066\n",
            "g_loss:[0.3302631080150604, 0.3281891942024231, 0.0010369527153670788]\n",
            "Batch:501\n",
            "d_loss:0.49843002079251164\n",
            "g_loss:[0.332329124212265, 0.3307065963745117, 0.0008112671202979982]\n",
            "========================================\n",
            "Epoch is: 75\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5181967769049152\n",
            "g_loss:[0.3310340344905853, 0.32955238223075867, 0.0007408240344375372]\n",
            "Batch:101\n",
            "d_loss:0.5072323751319345\n",
            "g_loss:[0.3309824466705322, 0.3294615149497986, 0.0007604637648910284]\n",
            "Batch:201\n",
            "d_loss:0.5071097161708167\n",
            "g_loss:[0.3273553252220154, 0.3263428807258606, 0.0005062235286459327]\n",
            "Batch:301\n",
            "d_loss:0.4773599157533681\n",
            "g_loss:[0.3297100067138672, 0.3290266990661621, 0.0003416531253606081]\n",
            "Batch:401\n",
            "d_loss:0.5277055608776209\n",
            "g_loss:[0.3295430839061737, 0.32817205786705017, 0.0006855070823803544]\n",
            "Batch:501\n",
            "d_loss:0.49234346026696585\n",
            "g_loss:[0.329906702041626, 0.32826635241508484, 0.0008201772579923272]\n",
            "========================================\n",
            "Epoch is: 76\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5130852869178852\n",
            "g_loss:[0.3355275094509125, 0.3337884247303009, 0.0008695495780557394]\n",
            "Batch:101\n",
            "d_loss:0.5030683608442814\n",
            "g_loss:[0.3303489089012146, 0.3298506438732147, 0.0002491327468305826]\n",
            "Batch:201\n",
            "d_loss:0.5028601790800167\n",
            "g_loss:[0.3275512158870697, 0.32646018266677856, 0.0005455092177726328]\n",
            "Batch:301\n",
            "d_loss:0.47042346964008175\n",
            "g_loss:[0.32835984230041504, 0.3276973068714142, 0.0003312653861939907]\n",
            "Batch:401\n",
            "d_loss:0.52391329846796\n",
            "g_loss:[0.3331822454929352, 0.3289341330528259, 0.0021240629721432924]\n",
            "Batch:501\n",
            "d_loss:0.48662938461802696\n",
            "g_loss:[0.3292301893234253, 0.3269723355770111, 0.0011289229150861502]\n",
            "========================================\n",
            "Epoch is: 77\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5067126819085388\n",
            "g_loss:[0.3376932442188263, 0.336983323097229, 0.00035496026976034045]\n",
            "Batch:101\n",
            "d_loss:0.5024189110190491\n",
            "g_loss:[0.331956148147583, 0.33043426275253296, 0.0007609364110976458]\n",
            "Batch:201\n",
            "d_loss:0.4976675843772682\n",
            "g_loss:[0.3275979459285736, 0.32692503929138184, 0.0003364558797329664]\n",
            "Batch:301\n",
            "d_loss:0.4628341082279803\n",
            "g_loss:[0.33119997382164, 0.32835131883621216, 0.0014243264449760318]\n",
            "Batch:401\n",
            "d_loss:0.5229868135074867\n",
            "g_loss:[0.3300522267818451, 0.32922691106796265, 0.0004126566054765135]\n",
            "Batch:501\n",
            "d_loss:0.48124782271816\n",
            "g_loss:[0.3298105299472809, 0.3269232511520386, 0.001443645916879177]\n",
            "========================================\n",
            "Epoch is: 78\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5028076782473363\n",
            "g_loss:[0.3397213816642761, 0.3363916575908661, 0.0016648585442453623]\n",
            "Batch:101\n",
            "d_loss:0.49770911868245094\n",
            "g_loss:[0.33127057552337646, 0.33066239953041077, 0.00030408898601308465]\n",
            "Batch:201\n",
            "d_loss:0.49362917457528965\n",
            "g_loss:[0.33044520020484924, 0.3266291618347168, 0.0019080161582678556]\n",
            "Batch:301\n",
            "d_loss:0.4559610675341901\n",
            "g_loss:[0.3303173780441284, 0.32732176780700684, 0.0014978053513914347]\n",
            "Batch:401\n",
            "d_loss:0.5200410776651552\n",
            "g_loss:[0.3299802541732788, 0.32848024368286133, 0.0007500026258639991]\n",
            "Batch:501\n",
            "d_loss:0.47426444181837724\n",
            "g_loss:[0.3298659026622772, 0.3267609179019928, 0.0015524961054325104]\n",
            "========================================\n",
            "Epoch is: 79\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.49800451133069146\n",
            "g_loss:[0.33982008695602417, 0.33933931589126587, 0.00024038826813921332]\n",
            "Batch:101\n",
            "d_loss:0.4982217982210386\n",
            "g_loss:[0.3331453800201416, 0.32947611808776855, 0.0018346271244809031]\n",
            "Batch:201\n",
            "d_loss:0.4883643611210573\n",
            "g_loss:[0.3301147222518921, 0.32720908522605896, 0.0014528241008520126]\n",
            "Batch:301\n",
            "d_loss:0.4474214426927574\n",
            "g_loss:[0.32852157950401306, 0.3272453546524048, 0.000638115219771862]\n",
            "Batch:401\n",
            "d_loss:0.5203463047300829\n",
            "g_loss:[0.32894447445869446, 0.32659125328063965, 0.0011766069801524282]\n",
            "Batch:501\n",
            "d_loss:0.46897234595735426\n",
            "g_loss:[0.3463953137397766, 0.33128970861434937, 0.007552802562713623]\n",
            "========================================\n",
            "Epoch is: 80\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4924101249544037\n",
            "g_loss:[0.36298006772994995, 0.33693480491638184, 0.013022631406784058]\n",
            "Batch:101\n",
            "d_loss:0.4943409062352657\n",
            "g_loss:[0.33674660325050354, 0.3352559208869934, 0.0007453441503457725]\n",
            "Batch:201\n",
            "d_loss:0.48261690899016685\n",
            "g_loss:[0.32909226417541504, 0.32887035608291626, 0.00011095614900114015]\n",
            "Batch:301\n",
            "d_loss:0.43961607205983455\n",
            "g_loss:[0.33144623041152954, 0.3306768536567688, 0.0003846897161565721]\n",
            "Batch:401\n",
            "d_loss:0.5186810554841941\n",
            "g_loss:[0.3303668797016144, 0.32878464460372925, 0.0007911183056421578]\n",
            "Batch:501\n",
            "d_loss:0.465495728987662\n",
            "g_loss:[0.32894575595855713, 0.3287290632724762, 0.00010834029671968892]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Epoch is: 81\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4906320188265454\n",
            "g_loss:[0.34147340059280396, 0.34116458892822266, 0.00015440135030075908]\n",
            "Batch:101\n",
            "d_loss:0.49108451118172525\n",
            "g_loss:[0.3341129422187805, 0.3339763879776001, 6.828399637015536e-05]\n",
            "Batch:201\n",
            "d_loss:0.4773235896554979\n",
            "g_loss:[0.33030110597610474, 0.3299301862716675, 0.00018545279453974217]\n",
            "Batch:301\n",
            "d_loss:0.43262178036980004\n",
            "g_loss:[0.3289712071418762, 0.3281930387020111, 0.00038907950511202216]\n",
            "Batch:401\n",
            "d_loss:0.5152246319903497\n",
            "g_loss:[0.32810962200164795, 0.32720744609832764, 0.00045108702033758163]\n",
            "Batch:501\n",
            "d_loss:0.4576922705277866\n",
            "g_loss:[0.3287512958049774, 0.32756394147872925, 0.0005936749512329698]\n",
            "========================================\n",
            "Epoch is: 82\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4877260979512812\n",
            "g_loss:[0.33858534693717957, 0.33689814805984497, 0.0008435948984697461]\n",
            "Batch:101\n",
            "d_loss:0.4857932315162543\n",
            "g_loss:[0.3347886800765991, 0.33372795581817627, 0.0005303674843162298]\n",
            "Batch:201\n",
            "d_loss:0.47050980831409106\n",
            "g_loss:[0.32833823561668396, 0.3276853859424591, 0.0003264215192757547]\n",
            "Batch:301\n",
            "d_loss:0.42758172246976756\n",
            "g_loss:[0.3293837308883667, 0.3285925090312958, 0.00039561191806569695]\n",
            "Batch:401\n",
            "d_loss:0.5160890818624466\n",
            "g_loss:[0.3305585980415344, 0.327576220035553, 0.0014911924954503775]\n",
            "Batch:501\n",
            "d_loss:0.4533483943887404\n",
            "g_loss:[0.3555237650871277, 0.35492807626724243, 0.00029783870559185743]\n",
            "========================================\n",
            "Epoch is: 83\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.48406042745432387\n",
            "g_loss:[0.34198126196861267, 0.3407447934150696, 0.0006182343931868672]\n",
            "Batch:101\n",
            "d_loss:0.48479641396625084\n",
            "g_loss:[0.3354863226413727, 0.3330395817756653, 0.0012233657762408257]\n",
            "Batch:201\n",
            "d_loss:0.46524588846659753\n",
            "g_loss:[0.32924702763557434, 0.32843488454818726, 0.00040607352275401354]\n",
            "Batch:301\n",
            "d_loss:0.4197728601552626\n",
            "g_loss:[0.3305092453956604, 0.3280838131904602, 0.0012127123773097992]\n",
            "Batch:401\n",
            "d_loss:0.5089741539977695\n",
            "g_loss:[0.3312643766403198, 0.32793688774108887, 0.0016637507360428572]\n",
            "Batch:501\n",
            "d_loss:0.4465379405155545\n",
            "g_loss:[0.3335137665271759, 0.32795584201812744, 0.0027789659798145294]\n",
            "========================================\n",
            "Epoch is: 84\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4778742434191372\n",
            "g_loss:[0.34412020444869995, 0.3413076102733612, 0.0014063003472983837]\n",
            "Batch:101\n",
            "d_loss:0.48272123416791146\n",
            "g_loss:[0.3345266580581665, 0.33358293771743774, 0.00047185871517285705]\n",
            "Batch:201\n",
            "d_loss:0.4599313286425968\n",
            "g_loss:[0.3306276798248291, 0.3282618820667267, 0.001182903302833438]\n",
            "Batch:301\n",
            "d_loss:0.4131093623961988\n",
            "g_loss:[0.32962021231651306, 0.32845354080200195, 0.0005833307513967156]\n",
            "Batch:401\n",
            "d_loss:0.5061055347650836\n",
            "g_loss:[0.33201152086257935, 0.33079028129577637, 0.0006106197251938283]\n",
            "Batch:501\n",
            "d_loss:0.43851837110105407\n",
            "g_loss:[0.3284098505973816, 0.3280078172683716, 0.0002010213356697932]\n",
            "========================================\n",
            "Epoch is: 85\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4613363549769929\n",
            "g_loss:[0.3395967185497284, 0.3392128348350525, 0.0001919370552059263]\n",
            "Batch:101\n",
            "d_loss:0.47188519540213747\n",
            "g_loss:[0.3382485508918762, 0.3355596959590912, 0.0013444209471344948]\n",
            "Batch:201\n",
            "d_loss:0.45486738591307585\n",
            "g_loss:[0.3293192982673645, 0.3275880813598633, 0.0008656092686578631]\n",
            "Batch:301\n",
            "d_loss:0.40374804848397616\n",
            "g_loss:[0.3293158710002899, 0.32859140634536743, 0.00036223040660843253]\n",
            "Batch:401\n",
            "d_loss:0.5056523801094954\n",
            "g_loss:[0.33081528544425964, 0.32907718420028687, 0.0008690556278452277]\n",
            "Batch:501\n",
            "d_loss:0.43187690973309145\n",
            "g_loss:[0.33005663752555847, 0.32809978723526, 0.0009784214198589325]\n",
            "========================================\n",
            "Epoch is: 86\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.45072214074480144\n",
            "g_loss:[0.3355993330478668, 0.33270934224128723, 0.0014449909795075655]\n",
            "Batch:101\n",
            "d_loss:0.467586524179751\n",
            "g_loss:[0.33164602518081665, 0.3301089406013489, 0.0007685432210564613]\n",
            "Batch:201\n",
            "d_loss:0.45116118309942976\n",
            "g_loss:[0.33031317591667175, 0.3281424343585968, 0.0010853670537471771]\n",
            "Batch:301\n",
            "d_loss:0.38951255393340034\n",
            "g_loss:[0.3302322328090668, 0.3279644548892975, 0.0011338833719491959]\n",
            "Batch:401\n",
            "d_loss:0.49606720125120773\n",
            "g_loss:[0.33321812748908997, 0.3317912220954895, 0.0007134570041671395]\n",
            "Batch:501\n",
            "d_loss:0.42176721662963246\n",
            "g_loss:[0.3277589976787567, 0.32696467638015747, 0.0003971615806221962]\n",
            "========================================\n",
            "Epoch is: 87\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4364967444580543\n",
            "g_loss:[0.33749350905418396, 0.3369205594062805, 0.00028648105217143893]\n",
            "Batch:101\n",
            "d_loss:0.4620154450676637\n",
            "g_loss:[0.3404003083705902, 0.33967748284339905, 0.0003614157612901181]\n",
            "Batch:201\n",
            "d_loss:0.4464181304306294\n",
            "g_loss:[0.3312312960624695, 0.328800767660141, 0.001215263968333602]\n",
            "Batch:301\n",
            "d_loss:0.3826116777546531\n",
            "g_loss:[0.34259849786758423, 0.34169894456863403, 0.0004497832851484418]\n",
            "Batch:401\n",
            "d_loss:0.4898248807976415\n",
            "g_loss:[0.33867567777633667, 0.3370344638824463, 0.0008206098573282361]\n",
            "Batch:501\n",
            "d_loss:0.42095800773495284\n",
            "g_loss:[0.3305109143257141, 0.33001863956451416, 0.000246131734456867]\n",
            "========================================\n",
            "Epoch is: 88\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.41282630828766287\n",
            "g_loss:[0.34039992094039917, 0.33523714542388916, 0.0025813868269324303]\n",
            "Batch:101\n",
            "d_loss:0.4579654006065539\n",
            "g_loss:[0.36012697219848633, 0.35853713750839233, 0.0007949165301397443]\n",
            "Batch:201\n",
            "d_loss:0.44470332860009876\n",
            "g_loss:[0.3300747871398926, 0.32948172092437744, 0.00029652577359229326]\n",
            "Batch:301\n",
            "d_loss:0.3625039975308937\n",
            "g_loss:[0.3424466848373413, 0.33121010661125183, 0.005618293769657612]\n",
            "Batch:401\n",
            "d_loss:0.4776363136575128\n",
            "g_loss:[0.33643123507499695, 0.33522480726242065, 0.0006032200763002038]\n",
            "Batch:501\n",
            "d_loss:0.40984210143119526\n",
            "g_loss:[0.33169132471084595, 0.33139747381210327, 0.00014692801050841808]\n",
            "========================================\n",
            "Epoch is: 89\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.40643759376212074\n",
            "g_loss:[0.33754396438598633, 0.33715564012527466, 0.00019416621944401413]\n",
            "Batch:101\n",
            "d_loss:0.4540977630113048\n",
            "g_loss:[0.3642059564590454, 0.3634580671787262, 0.0003739520034287125]\n",
            "Batch:201\n",
            "d_loss:0.44146149120911105\n",
            "g_loss:[0.3315347135066986, 0.33053576946258545, 0.0004994721384719014]\n",
            "Batch:301\n",
            "d_loss:0.3498235067903579\n",
            "g_loss:[0.33251023292541504, 0.3299746513366699, 0.0012677876511588693]\n",
            "Batch:401\n",
            "d_loss:0.4772435616105213\n",
            "g_loss:[0.33861491084098816, 0.3371492922306061, 0.0007328051142394543]\n",
            "Batch:501\n",
            "d_loss:0.40546441451510873\n",
            "g_loss:[0.33186283707618713, 0.329789936542511, 0.0010364532936364412]\n",
            "========================================\n",
            "Epoch is: 90\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3865332673345847\n",
            "g_loss:[0.33141443133354187, 0.33057698607444763, 0.00041872530709952116]\n",
            "Batch:101\n",
            "d_loss:0.4486076520529423\n",
            "g_loss:[0.33946022391319275, 0.33825185894966125, 0.0006041867891326547]\n",
            "Batch:201\n",
            "d_loss:0.4412699935667206\n",
            "g_loss:[0.3328772187232971, 0.3322908282279968, 0.00029319338500499725]\n",
            "Batch:301\n",
            "d_loss:0.33233175566965656\n",
            "g_loss:[0.330227255821228, 0.3291400074958801, 0.0005436219507828355]\n",
            "Batch:401\n",
            "d_loss:0.46098623335637967\n",
            "g_loss:[0.367206871509552, 0.3622392416000366, 0.0024838116951286793]\n",
            "Batch:501\n",
            "d_loss:0.3740796702993521\n",
            "g_loss:[0.33239102363586426, 0.32905977964401245, 0.001665616175159812]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 91\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.38834710260198335\n",
            "g_loss:[0.33391231298446655, 0.33241426944732666, 0.0007490291027352214]\n",
            "Batch:101\n",
            "d_loss:0.4439085854926361\n",
            "g_loss:[0.35284215211868286, 0.35212990641593933, 0.00035611752537079155]\n",
            "Batch:201\n",
            "d_loss:0.4298319057701292\n",
            "g_loss:[0.33968427777290344, 0.33567875623703003, 0.0020027575083076954]\n",
            "Batch:301\n",
            "d_loss:0.3127773811582415\n",
            "g_loss:[0.33926472067832947, 0.3386569023132324, 0.00030391529435291886]\n",
            "Batch:401\n",
            "d_loss:0.4613382264575421\n",
            "g_loss:[0.33507874608039856, 0.333086222410202, 0.0009962618350982666]\n",
            "Batch:501\n",
            "d_loss:0.3701282609449663\n",
            "g_loss:[0.3326362371444702, 0.33087030053138733, 0.0008829723228700459]\n",
            "========================================\n",
            "Epoch is: 92\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3655084418133612\n",
            "g_loss:[0.3311891257762909, 0.3298460841178894, 0.0006715237395837903]\n",
            "Batch:101\n",
            "d_loss:0.4391252783004802\n",
            "g_loss:[0.348336786031723, 0.3480578660964966, 0.00013945925456937402]\n",
            "Batch:201\n",
            "d_loss:0.42462136040057885\n",
            "g_loss:[0.3399186432361603, 0.33767205476760864, 0.00112329819239676]\n",
            "Batch:301\n",
            "d_loss:0.2956494530667442\n",
            "g_loss:[0.3338746726512909, 0.333551824092865, 0.00016142294043675065]\n",
            "Batch:401\n",
            "d_loss:0.4449545738884808\n",
            "g_loss:[0.33577582240104675, 0.3352926969528198, 0.00024156112340278924]\n",
            "Batch:501\n",
            "d_loss:0.37546775397248666\n",
            "g_loss:[0.34292545914649963, 0.33870255947113037, 0.002111446112394333]\n",
            "========================================\n",
            "Epoch is: 93\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3146791465115939\n",
            "g_loss:[0.3479157090187073, 0.3445972800254822, 0.001659221714362502]\n",
            "Batch:101\n",
            "d_loss:0.45107818167093683\n",
            "g_loss:[0.36027857661247253, 0.3592696189880371, 0.0005044826539233327]\n",
            "Batch:201\n",
            "d_loss:0.4197057229500274\n",
            "g_loss:[0.33965998888015747, 0.3388935625553131, 0.0003832140064332634]\n",
            "Batch:301\n",
            "d_loss:0.2746049617418862\n",
            "g_loss:[0.3577694892883301, 0.3518216907978058, 0.002973903901875019]\n",
            "Batch:401\n",
            "d_loss:0.4497054810796044\n",
            "g_loss:[0.33262476325035095, 0.33008670806884766, 0.0012690207222476602]\n",
            "Batch:501\n",
            "d_loss:0.3903977128295537\n",
            "g_loss:[0.33612334728240967, 0.33572840690612793, 0.0001974674523808062]\n",
            "========================================\n",
            "Epoch is: 94\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.31267018383402956\n",
            "g_loss:[0.36056405305862427, 0.3595975637435913, 0.0004832452395930886]\n",
            "Batch:101\n",
            "d_loss:0.43228728002668504\n",
            "g_loss:[0.36385378241539, 0.36331889033317566, 0.00026745256036520004]\n",
            "Batch:201\n",
            "d_loss:0.3723100945483111\n",
            "g_loss:[0.3356994688510895, 0.33361929655075073, 0.0010400810278952122]\n",
            "Batch:301\n",
            "d_loss:0.2610146350177729\n",
            "g_loss:[0.3445269465446472, 0.3391231298446655, 0.002701911609619856]\n",
            "Batch:401\n",
            "d_loss:0.4240539996553707\n",
            "g_loss:[0.33813372254371643, 0.33648979663848877, 0.0008219607407227159]\n",
            "Batch:501\n",
            "d_loss:0.33712641488909867\n",
            "g_loss:[0.333557665348053, 0.3325936198234558, 0.000482024101074785]\n",
            "========================================\n",
            "Epoch is: 95\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.300573430495092\n",
            "g_loss:[0.39665377140045166, 0.39520618319511414, 0.0007237960235215724]\n",
            "Batch:101\n",
            "d_loss:0.4196950325422222\n",
            "g_loss:[0.33796262741088867, 0.33683493733406067, 0.0005638456204906106]\n",
            "Batch:201\n",
            "d_loss:0.369275213808578\n",
            "g_loss:[0.33838167786598206, 0.3376215696334839, 0.000380058481823653]\n",
            "Batch:301\n",
            "d_loss:0.2561221912054066\n",
            "g_loss:[0.3372669816017151, 0.33661088347435, 0.00032804859802126884]\n",
            "Batch:401\n",
            "d_loss:0.4074451071896874\n",
            "g_loss:[0.36478734016418457, 0.3619037866592407, 0.0014417797792702913]\n",
            "Batch:501\n",
            "d_loss:0.33699235206177036\n",
            "g_loss:[0.3389008045196533, 0.33870139718055725, 9.970244718715549e-05]\n",
            "========================================\n",
            "Epoch is: 96\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2480723571929957\n",
            "g_loss:[0.3365294337272644, 0.3364049792289734, 6.222491356311366e-05]\n",
            "Batch:101\n",
            "d_loss:0.4376399329794367\n",
            "g_loss:[0.3449508249759674, 0.3436231315135956, 0.0006638475460931659]\n",
            "Batch:201\n",
            "d_loss:0.3349177237814729\n",
            "g_loss:[0.3348901569843292, 0.333700954914093, 0.0005946079036220908]\n",
            "Batch:301\n",
            "d_loss:0.24208087055194483\n",
            "g_loss:[0.5496158599853516, 0.3468776345252991, 0.10136912018060684]\n",
            "Batch:401\n",
            "d_loss:0.40515812419516806\n",
            "g_loss:[0.3738313615322113, 0.3721824288368225, 0.0008244655909948051]\n",
            "Batch:501\n",
            "d_loss:0.35549916333229703\n",
            "g_loss:[0.3388229012489319, 0.3384570777416229, 0.00018291137530468404]\n",
            "========================================\n",
            "Epoch is: 97\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2815810609612157\n",
            "g_loss:[0.34044551849365234, 0.34001725912094116, 0.0002141338773071766]\n",
            "Batch:101\n",
            "d_loss:0.40165701361229367\n",
            "g_loss:[0.34676864743232727, 0.34632235765457153, 0.0002231379330623895]\n",
            "Batch:201\n",
            "d_loss:0.306870996374073\n",
            "g_loss:[0.33973318338394165, 0.3395870327949524, 7.307120540644974e-05]\n",
            "Batch:301\n",
            "d_loss:0.2235680338947077\n",
            "g_loss:[0.34414947032928467, 0.34394845366477966, 0.00010051544813904911]\n",
            "Batch:401\n",
            "d_loss:0.3904148907640774\n",
            "g_loss:[0.34317871928215027, 0.3431171774864197, 3.0776122002862394e-05]\n",
            "Batch:501\n",
            "d_loss:0.26437690471311726\n",
            "g_loss:[0.3875356912612915, 0.3874284625053406, 5.361446528695524e-05]\n",
            "========================================\n",
            "Epoch is: 98\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3618119831846798\n",
            "g_loss:[0.3972582221031189, 0.39721447229385376, 2.1869884221814573e-05]\n",
            "Batch:101\n",
            "d_loss:0.39747108998926706\n",
            "g_loss:[0.34398770332336426, 0.34383127093315125, 7.821668987162411e-05]\n",
            "Batch:201\n",
            "d_loss:0.33345363817352336\n",
            "g_loss:[0.3396468758583069, 0.3392711281776428, 0.00018787034787237644]\n",
            "Batch:301\n",
            "d_loss:0.2002736849262874\n",
            "g_loss:[0.3471424877643585, 0.34503018856048584, 0.001056151115335524]\n",
            "Batch:401\n",
            "d_loss:0.3338502170782931\n",
            "g_loss:[0.34959179162979126, 0.34932446479797363, 0.0001336621935479343]\n",
            "Batch:501\n",
            "d_loss:0.2831754877884123\n",
            "g_loss:[0.346340149641037, 0.3462049663066864, 6.758631207048893e-05]\n",
            "========================================\n",
            "Epoch is: 99\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2204558081004393\n",
            "g_loss:[0.4439702033996582, 0.44378870725631714, 9.075363050214946e-05]\n",
            "Batch:101\n",
            "d_loss:0.37787944739557133\n",
            "g_loss:[0.4163055717945099, 0.41589683294296265, 0.00020436356135178357]\n",
            "Batch:201\n",
            "d_loss:0.3931678538756387\n",
            "g_loss:[0.35642778873443604, 0.35213178396224976, 0.002147996798157692]\n",
            "Batch:301\n",
            "d_loss:0.19882337795610283\n",
            "g_loss:[0.34502649307250977, 0.34422767162323, 0.00039940548595041037]\n",
            "Batch:401\n",
            "d_loss:0.3043623462406231\n",
            "g_loss:[0.3735675811767578, 0.3715151846408844, 0.0010261943098157644]\n",
            "Batch:501\n",
            "d_loss:0.32964741467799286\n",
            "g_loss:[0.34818363189697266, 0.34691759943962097, 0.0006330199539661407]\n",
            "========================================\n",
            "Epoch is: 100\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.21217651017207118\n",
            "g_loss:[0.3930372893810272, 0.39261123538017273, 0.00021302068489603698]\n",
            "Batch:101\n",
            "d_loss:0.5414745635571308\n",
            "g_loss:[0.3439657688140869, 0.34354662895202637, 0.00020957311789970845]\n",
            "Batch:201\n",
            "d_loss:0.2434832717772224\n",
            "g_loss:[0.34237101674079895, 0.341775119304657, 0.0002979477576445788]\n",
            "Batch:301\n",
            "d_loss:0.2794781271401803\n",
            "g_loss:[0.39490753412246704, 0.3925012946128845, 0.0012031211517751217]\n",
            "Batch:401\n",
            "d_loss:0.3460483144781392\n",
            "g_loss:[0.36223623156547546, 0.35647305846214294, 0.0028815921396017075]\n",
            "Batch:501\n",
            "d_loss:0.23007964439511852\n",
            "g_loss:[0.34855180978775024, 0.3471759557723999, 0.0006879311986267567]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo pesos\n",
            "========================================\n",
            "Epoch is: 101\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.349757607795425\n",
            "g_loss:[0.46869179606437683, 0.46804937720298767, 0.00032120427931658924]\n",
            "Batch:101\n",
            "d_loss:0.2561693364405073\n",
            "g_loss:[0.42839527130126953, 0.42789000272750854, 0.0002526275347918272]\n",
            "Batch:201\n",
            "d_loss:0.24770475811237702\n",
            "g_loss:[0.3514929413795471, 0.35116463899612427, 0.00016415731806773692]\n",
            "Batch:301\n",
            "d_loss:0.20549763763790452\n",
            "g_loss:[0.4499691128730774, 0.44414135813713074, 0.002913884585723281]\n",
            "Batch:401\n",
            "d_loss:0.48546098883480227\n",
            "g_loss:[0.37956011295318604, 0.37802207469940186, 0.0007690188940614462]\n",
            "Batch:501\n",
            "d_loss:0.23233784310650663\n",
            "g_loss:[0.3721955120563507, 0.3690240979194641, 0.0015857014805078506]\n",
            "========================================\n",
            "Epoch is: 102\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3707342217677265\n",
            "g_loss:[0.3873268663883209, 0.3830031454563141, 0.0021618560422211885]\n",
            "Batch:101\n",
            "d_loss:0.3348593407390581\n",
            "g_loss:[0.3525509238243103, 0.35095518827438354, 0.0007978719659149647]\n",
            "Batch:201\n",
            "d_loss:0.3743847803925746\n",
            "g_loss:[0.40344589948654175, 0.4025399684906006, 0.0004529666039161384]\n",
            "Batch:301\n",
            "d_loss:0.2156478564724864\n",
            "g_loss:[0.3799377977848053, 0.3796865940093994, 0.00012560767936520278]\n",
            "Batch:401\n",
            "d_loss:0.27193940181678045\n",
            "g_loss:[0.38249677419662476, 0.3815741539001465, 0.0004613174241967499]\n",
            "Batch:501\n",
            "d_loss:0.2439392698706797\n",
            "g_loss:[0.3507084548473358, 0.34808284044265747, 0.0013128068530932069]\n",
            "========================================\n",
            "Epoch is: 103\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3804708493560156\n",
            "g_loss:[0.4081560969352722, 0.406586229801178, 0.0007849378744140267]\n",
            "Batch:101\n",
            "d_loss:0.47442847332786187\n",
            "g_loss:[0.3452015817165375, 0.3427807092666626, 0.001210442278534174]\n",
            "Batch:201\n",
            "d_loss:0.2965374322957359\n",
            "g_loss:[0.3450463116168976, 0.3446561396121979, 0.00019508801051415503]\n",
            "Batch:301\n",
            "d_loss:0.4541146869461272\n",
            "g_loss:[0.35676735639572144, 0.35660120844841003, 8.307932876050472e-05]\n",
            "Batch:401\n",
            "d_loss:0.32997414132842096\n",
            "g_loss:[0.3556855320930481, 0.35338446497917175, 0.001150527154095471]\n",
            "Batch:501\n",
            "d_loss:0.40793926675542025\n",
            "g_loss:[0.43523508310317993, 0.4341633915901184, 0.0005358507623896003]\n",
            "========================================\n",
            "Epoch is: 104\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.25017020738550855\n",
            "g_loss:[0.35701191425323486, 0.35571688413619995, 0.0006475178524851799]\n",
            "Batch:101\n",
            "d_loss:0.2729503138771179\n",
            "g_loss:[0.3476886451244354, 0.3441295325756073, 0.0017795574385672808]\n",
            "Batch:201\n",
            "d_loss:0.34882318234303966\n",
            "g_loss:[0.378232479095459, 0.37704282999038696, 0.0005948304897174239]\n",
            "Batch:301\n",
            "d_loss:0.21403478389379416\n",
            "g_loss:[0.36584264039993286, 0.36542561650276184, 0.00020850554574280977]\n",
            "Batch:401\n",
            "d_loss:0.468153219116175\n",
            "g_loss:[0.48825329542160034, 0.48604917526245117, 0.0011020565871149302]\n",
            "Batch:501\n",
            "d_loss:0.22694915044701247\n",
            "g_loss:[0.35169631242752075, 0.3500633239746094, 0.0008164902101270854]\n",
            "========================================\n",
            "Epoch is: 105\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2876102005343455\n",
            "g_loss:[0.4953969717025757, 0.49373072385787964, 0.0008331184508278966]\n",
            "Batch:101\n",
            "d_loss:0.30224116858880734\n",
            "g_loss:[0.3492511808872223, 0.3453746438026428, 0.0019382669124752283]\n",
            "Batch:201\n",
            "d_loss:0.3124298527945939\n",
            "g_loss:[0.38896551728248596, 0.3864400386810303, 0.001262732781469822]\n",
            "Batch:301\n",
            "d_loss:0.20649484847740496\n",
            "g_loss:[0.39079391956329346, 0.38777023553848267, 0.0015118427108973265]\n",
            "Batch:401\n",
            "d_loss:0.2802876590535561\n",
            "g_loss:[0.36021772027015686, 0.3567684292793274, 0.0017246489878743887]\n",
            "Batch:501\n",
            "d_loss:0.25038410914567066\n",
            "g_loss:[0.38413411378860474, 0.3819838762283325, 0.0010751141235232353]\n",
            "========================================\n",
            "Epoch is: 106\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.8674411424490245\n",
            "g_loss:[0.372416615486145, 0.37123578786849976, 0.0005904068239033222]\n",
            "Batch:101\n",
            "d_loss:0.4962531264518475\n",
            "g_loss:[0.3756714165210724, 0.371130108833313, 0.0022706491872668266]\n",
            "Batch:201\n",
            "d_loss:0.4146113972310559\n",
            "g_loss:[0.34497061371803284, 0.34332752227783203, 0.0008215489215217531]\n",
            "Batch:301\n",
            "d_loss:0.309753431298077\n",
            "g_loss:[0.3418833017349243, 0.3397757411003113, 0.0010537828784435987]\n",
            "Batch:401\n",
            "d_loss:0.27591224373963996\n",
            "g_loss:[0.35134607553482056, 0.35054200887680054, 0.00040203044773079455]\n",
            "Batch:501\n",
            "d_loss:0.40904916768431576\n",
            "g_loss:[0.3420203626155853, 0.34131091833114624, 0.0003547153901308775]\n",
            "========================================\n",
            "Epoch is: 107\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.31636403786569645\n",
            "g_loss:[0.3465803861618042, 0.3454991579055786, 0.0005406118580140173]\n",
            "Batch:101\n",
            "d_loss:0.2525427141695218\n",
            "g_loss:[0.3618503510951996, 0.3586679697036743, 0.0015911938389763236]\n",
            "Batch:201\n",
            "d_loss:0.41899862402351573\n",
            "g_loss:[0.34585994482040405, 0.34549248218536377, 0.00018372516206]\n",
            "Batch:301\n",
            "d_loss:0.2793781215668787\n",
            "g_loss:[0.3479582965373993, 0.3450516164302826, 0.0014533426146954298]\n",
            "Batch:401\n",
            "d_loss:0.4790593916641228\n",
            "g_loss:[0.4533008635044098, 0.4517574608325958, 0.0007717047701589763]\n",
            "Batch:501\n",
            "d_loss:0.392118747593031\n",
            "g_loss:[0.3382793366909027, 0.33761823177337646, 0.00033055635867640376]\n",
            "========================================\n",
            "Epoch is: 108\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2271543597184973\n",
            "g_loss:[0.4325738549232483, 0.43181633949279785, 0.000378756521968171]\n",
            "Batch:101\n",
            "d_loss:0.2614976949294032\n",
            "g_loss:[0.3912302255630493, 0.39009207487106323, 0.0005690824473276734]\n",
            "Batch:201\n",
            "d_loss:0.2358310491181328\n",
            "g_loss:[0.345950186252594, 0.34552907943725586, 0.00021054621902294457]\n",
            "Batch:301\n",
            "d_loss:0.24279720852564424\n",
            "g_loss:[0.4033846855163574, 0.40256834030151367, 0.00040817802073433995]\n",
            "Batch:401\n",
            "d_loss:0.30506961245009734\n",
            "g_loss:[0.3512774407863617, 0.3498833477497101, 0.0006970411050133407]\n",
            "Batch:501\n",
            "d_loss:0.28469871277320635\n",
            "g_loss:[0.37133052945137024, 0.3701907992362976, 0.0005698640015907586]\n",
            "========================================\n",
            "Epoch is: 109\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.31816789135493195\n",
            "g_loss:[0.34318649768829346, 0.34132713079452515, 0.000929676229134202]\n",
            "Batch:101\n",
            "d_loss:0.41258008575027816\n",
            "g_loss:[0.3376968502998352, 0.33513766527175903, 0.001279589137993753]\n",
            "Batch:201\n",
            "d_loss:0.250937550400522\n",
            "g_loss:[0.387315571308136, 0.3866378366947174, 0.0003388610784895718]\n",
            "Batch:301\n",
            "d_loss:0.23705571076004617\n",
            "g_loss:[0.4036097228527069, 0.3978961706161499, 0.0028567821718752384]\n",
            "Batch:401\n",
            "d_loss:0.5236582146653745\n",
            "g_loss:[0.39591944217681885, 0.3934752941131592, 0.0012220727512612939]\n",
            "Batch:501\n",
            "d_loss:0.25408483067690213\n",
            "g_loss:[0.4195663630962372, 0.419106662273407, 0.0002298458421137184]\n",
            "========================================\n",
            "Epoch is: 110\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:1.377131146844512\n",
            "g_loss:[0.3483687937259674, 0.3479430079460144, 0.0002128971100319177]\n",
            "Batch:101\n",
            "d_loss:0.2407670555421646\n",
            "g_loss:[0.37750640511512756, 0.37478572130203247, 0.0013603349216282368]\n",
            "Batch:201\n",
            "d_loss:0.34464108455358655\n",
            "g_loss:[0.3429221510887146, 0.3420525789260864, 0.000434778950875625]\n",
            "Batch:301\n",
            "d_loss:0.45635501784670396\n",
            "g_loss:[0.38534602522850037, 0.3839772939682007, 0.0006843656883575022]\n",
            "Batch:401\n",
            "d_loss:0.2881395323367997\n",
            "g_loss:[0.3432338833808899, 0.34055662155151367, 0.0013386283535510302]\n",
            "Batch:501\n",
            "d_loss:0.2714049357928161\n",
            "g_loss:[0.4842914640903473, 0.48018378019332886, 0.002053842879831791]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 111\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.286335906742579\n",
            "g_loss:[0.4365272521972656, 0.4342249035835266, 0.0011511726770550013]\n",
            "Batch:101\n",
            "d_loss:0.2514667625828224\n",
            "g_loss:[0.3481299877166748, 0.3448617458343506, 0.0016341267619282007]\n",
            "Batch:201\n",
            "d_loss:0.22741482723358786\n",
            "g_loss:[0.3474680185317993, 0.3457634150981903, 0.0008523048600181937]\n",
            "Batch:301\n",
            "d_loss:0.19219919649071926\n",
            "g_loss:[0.3539964258670807, 0.35187265276908875, 0.0010618831729516387]\n",
            "Batch:401\n",
            "d_loss:0.2515507559753587\n",
            "g_loss:[0.4024457037448883, 0.40027421712875366, 0.0010857419110834599]\n",
            "Batch:501\n",
            "d_loss:0.749336176723773\n",
            "g_loss:[0.3644264340400696, 0.36384904384613037, 0.000288692070171237]\n",
            "========================================\n",
            "Epoch is: 112\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4247250791540864\n",
            "g_loss:[0.4709588587284088, 0.4705711603164673, 0.00019384437473490834]\n",
            "Batch:101\n",
            "d_loss:0.2810656555357127\n",
            "g_loss:[0.3689756393432617, 0.3680046498775482, 0.0004854892904404551]\n",
            "Batch:201\n",
            "d_loss:0.24682971002766863\n",
            "g_loss:[0.37394651770591736, 0.37281742691993713, 0.0005645438795909286]\n",
            "Batch:301\n",
            "d_loss:0.29988770638010465\n",
            "g_loss:[0.4720602333545685, 0.46550318598747253, 0.0032785218209028244]\n",
            "Batch:401\n",
            "d_loss:0.39095967502998974\n",
            "g_loss:[0.3836785554885864, 0.380093514919281, 0.0017925254069268703]\n",
            "Batch:501\n",
            "d_loss:0.19716329879020122\n",
            "g_loss:[0.3494424521923065, 0.3480660319328308, 0.0006882059969939291]\n",
            "========================================\n",
            "Epoch is: 113\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.20249394389611552\n",
            "g_loss:[0.3911972641944885, 0.3909182548522949, 0.00013949934509582818]\n",
            "Batch:101\n",
            "d_loss:0.32229380362286975\n",
            "g_loss:[0.3812348246574402, 0.37998366355895996, 0.0006255741463974118]\n",
            "Batch:201\n",
            "d_loss:0.7831934741407167\n",
            "g_loss:[0.44151854515075684, 0.4404449760913849, 0.000536787323653698]\n",
            "Batch:301\n",
            "d_loss:0.27448565674421843\n",
            "g_loss:[0.4667924642562866, 0.46516862511634827, 0.0008119247504509985]\n",
            "Batch:401\n",
            "d_loss:0.4854964756082154\n",
            "g_loss:[0.36298683285713196, 0.3609413206577301, 0.0010227607563138008]\n",
            "Batch:501\n",
            "d_loss:0.19384105865674428\n",
            "g_loss:[0.35780787467956543, 0.3568071126937866, 0.0005003854166716337]\n",
            "========================================\n",
            "Epoch is: 114\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.229512113847818\n",
            "g_loss:[0.3649056851863861, 0.3642677664756775, 0.00031896194559521973]\n",
            "Batch:101\n",
            "d_loss:0.2958920762098387\n",
            "g_loss:[0.3549495041370392, 0.3537338376045227, 0.0006078366423025727]\n",
            "Batch:201\n",
            "d_loss:0.2541419825174671\n",
            "g_loss:[0.34284043312072754, 0.3402702212333679, 0.0012851115316152573]\n",
            "Batch:301\n",
            "d_loss:0.23537604699004078\n",
            "g_loss:[0.39989519119262695, 0.3992326259613037, 0.000331285351421684]\n",
            "Batch:401\n",
            "d_loss:0.287317110462709\n",
            "g_loss:[0.37353286147117615, 0.3723032772541046, 0.0006147907115519047]\n",
            "Batch:501\n",
            "d_loss:0.3566658751101386\n",
            "g_loss:[0.3738119602203369, 0.3723055124282837, 0.000753227504901588]\n",
            "========================================\n",
            "Epoch is: 115\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.7256542751566712\n",
            "g_loss:[0.3455527424812317, 0.3441714942455292, 0.0006906238850206137]\n",
            "Batch:101\n",
            "d_loss:0.2867587407713472\n",
            "g_loss:[0.36013665795326233, 0.35821670293807983, 0.0009599829791113734]\n",
            "Batch:201\n",
            "d_loss:0.21142095645882364\n",
            "g_loss:[0.35233864188194275, 0.35059288144111633, 0.0008728838292881846]\n",
            "Batch:301\n",
            "d_loss:0.7450450151548011\n",
            "g_loss:[0.34584423899650574, 0.345219224691391, 0.00031250336905941367]\n",
            "Batch:401\n",
            "d_loss:0.23954632449658675\n",
            "g_loss:[0.337647408246994, 0.336122989654541, 0.0007622096454724669]\n",
            "Batch:501\n",
            "d_loss:0.3580459340782909\n",
            "g_loss:[0.3666210472583771, 0.36556339263916016, 0.0005288243410177529]\n",
            "========================================\n",
            "Epoch is: 116\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.26228938703752647\n",
            "g_loss:[0.3980201482772827, 0.3973379135131836, 0.00034111301647499204]\n",
            "Batch:101\n",
            "d_loss:0.23934395503238193\n",
            "g_loss:[0.35565900802612305, 0.35179072618484497, 0.0019341439474374056]\n",
            "Batch:201\n",
            "d_loss:0.22987235311848053\n",
            "g_loss:[0.33858656883239746, 0.33806702494621277, 0.0002597674319986254]\n",
            "Batch:301\n",
            "d_loss:0.20047062558205653\n",
            "g_loss:[0.39447692036628723, 0.3923991322517395, 0.0010388975497335196]\n",
            "Batch:401\n",
            "d_loss:0.5124065239506308\n",
            "g_loss:[0.3649959862232208, 0.36338523030281067, 0.0008053825004026294]\n",
            "Batch:501\n",
            "d_loss:0.4914725988844566\n",
            "g_loss:[0.3416283428668976, 0.3392512798309326, 0.001188534777611494]\n",
            "========================================\n",
            "Epoch is: 117\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2946581538110422\n",
            "g_loss:[0.3387299180030823, 0.3377520442008972, 0.0004889409756287932]\n",
            "Batch:101\n",
            "d_loss:0.26543823245901876\n",
            "g_loss:[0.41899043321609497, 0.418567031621933, 0.000211699545616284]\n",
            "Batch:201\n",
            "d_loss:0.37592446023700177\n",
            "g_loss:[0.346853107213974, 0.3464428186416626, 0.00020515077630989254]\n",
            "Batch:301\n",
            "d_loss:0.19034184004681265\n",
            "g_loss:[0.44168412685394287, 0.44106680154800415, 0.00030866230372339487]\n",
            "Batch:401\n",
            "d_loss:0.3184220084158369\n",
            "g_loss:[0.36631834506988525, 0.36607199907302856, 0.00012317090295255184]\n",
            "Batch:501\n",
            "d_loss:0.23115208707622514\n",
            "g_loss:[0.4156886339187622, 0.4124113917350769, 0.0016386169008910656]\n",
            "========================================\n",
            "Epoch is: 118\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.36039862549233703\n",
            "g_loss:[0.344279021024704, 0.34053274989128113, 0.001873136032372713]\n",
            "Batch:101\n",
            "d_loss:1.1223740738987544\n",
            "g_loss:[0.34657737612724304, 0.3461851179599762, 0.00019612896721810102]\n",
            "Batch:201\n",
            "d_loss:0.23223574660551094\n",
            "g_loss:[0.3395111858844757, 0.33867138624191284, 0.0004198976675979793]\n",
            "Batch:301\n",
            "d_loss:0.18019513391402597\n",
            "g_loss:[0.3462241590023041, 0.3441600203514099, 0.001032062340527773]\n",
            "Batch:401\n",
            "d_loss:0.4983543530379393\n",
            "g_loss:[0.36748164892196655, 0.36693012714385986, 0.00027576269349083304]\n",
            "Batch:501\n",
            "d_loss:0.5633173368405551\n",
            "g_loss:[0.49234646558761597, 0.48988980054855347, 0.001228339970111847]\n",
            "========================================\n",
            "Epoch is: 119\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2395296279478316\n",
            "g_loss:[0.4236629903316498, 0.42121994495391846, 0.0012215182650834322]\n",
            "Batch:101\n",
            "d_loss:0.2551648585440489\n",
            "g_loss:[0.3609326183795929, 0.35795706510543823, 0.0014877697685733438]\n",
            "Batch:201\n",
            "d_loss:0.21929216026546783\n",
            "g_loss:[0.3496692478656769, 0.34798330068588257, 0.0008429723093286157]\n",
            "Batch:301\n",
            "d_loss:0.23174939144382734\n",
            "g_loss:[0.43985041975975037, 0.43946558237075806, 0.00019242538837715983]\n",
            "Batch:401\n",
            "d_loss:0.23879565867900965\n",
            "g_loss:[0.3620986044406891, 0.3589378595352173, 0.0015803782735019922]\n",
            "Batch:501\n",
            "d_loss:0.21676902214676375\n",
            "g_loss:[0.3807251751422882, 0.3795638382434845, 0.0005806718254461884]\n",
            "========================================\n",
            "Epoch is: 120\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.17999546750661466\n",
            "g_loss:[0.35855960845947266, 0.35576343536376953, 0.0013980809599161148]\n",
            "Batch:101\n",
            "d_loss:0.28290015992615736\n",
            "g_loss:[0.36176806688308716, 0.3583763837814331, 0.0016958359628915787]\n",
            "Batch:201\n",
            "d_loss:0.21507591740009957\n",
            "g_loss:[0.395799845457077, 0.3955425024032593, 0.0001286661281483248]\n",
            "Batch:301\n",
            "d_loss:0.22237412081062757\n",
            "g_loss:[0.39662036299705505, 0.3953086733818054, 0.0006558499298989773]\n",
            "Batch:401\n",
            "d_loss:0.22628676743079268\n",
            "g_loss:[0.3874151408672333, 0.3846287131309509, 0.0013932206202298403]\n",
            "Batch:501\n",
            "d_loss:0.4448965513188341\n",
            "g_loss:[0.3473054766654968, 0.34684789180755615, 0.00022879750758875161]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 121\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3942562736306172\n",
            "g_loss:[0.346213698387146, 0.3453856110572815, 0.00041404302464798093]\n",
            "Batch:101\n",
            "d_loss:0.28934208959981333\n",
            "g_loss:[0.3747256398200989, 0.37131237983703613, 0.0017066298751160502]\n",
            "Batch:201\n",
            "d_loss:0.36724192004066936\n",
            "g_loss:[0.34596824645996094, 0.3447524905204773, 0.000607882859185338]\n",
            "Batch:301\n",
            "d_loss:0.187904045927894\n",
            "g_loss:[0.4735046625137329, 0.471916139125824, 0.000794261519331485]\n",
            "Batch:401\n",
            "d_loss:0.2485939567151263\n",
            "g_loss:[0.3892114460468292, 0.3868313431739807, 0.0011900444515049458]\n",
            "Batch:501\n",
            "d_loss:0.34816910142853885\n",
            "g_loss:[0.3420260548591614, 0.3413981795310974, 0.0003139439504593611]\n",
            "========================================\n",
            "Epoch is: 122\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3751993736134409\n",
            "g_loss:[0.4461347162723541, 0.4440075159072876, 0.001063596224412322]\n",
            "Batch:101\n",
            "d_loss:0.2507485895903301\n",
            "g_loss:[0.392861932516098, 0.3923245370388031, 0.0002686950610950589]\n",
            "Batch:201\n",
            "d_loss:0.24972992016046192\n",
            "g_loss:[0.3437492251396179, 0.33976131677627563, 0.0019939523190259933]\n",
            "Batch:301\n",
            "d_loss:0.3172936413102434\n",
            "g_loss:[0.38662657141685486, 0.38268688321113586, 0.001969837350770831]\n",
            "Batch:401\n",
            "d_loss:0.3697779685462592\n",
            "g_loss:[0.3690175414085388, 0.36768320202827454, 0.000667165091726929]\n",
            "Batch:501\n",
            "d_loss:0.3336567759506579\n",
            "g_loss:[0.39077228307724, 0.38923418521881104, 0.0007690426427870989]\n",
            "========================================\n",
            "Epoch is: 123\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:1.902649255585878\n",
            "g_loss:[0.3657064437866211, 0.3622193932533264, 0.0017435220070183277]\n",
            "Batch:101\n",
            "d_loss:0.41538084465355496\n",
            "g_loss:[0.35537490248680115, 0.3548309803009033, 0.00027195719303563237]\n",
            "Batch:201\n",
            "d_loss:0.64466680662008\n",
            "g_loss:[0.3597221374511719, 0.3592502772808075, 0.00023593312653247267]\n",
            "Batch:301\n",
            "d_loss:0.23088045351823894\n",
            "g_loss:[0.3428284227848053, 0.34159740805625916, 0.0006155089940875769]\n",
            "Batch:401\n",
            "d_loss:0.23833983729582542\n",
            "g_loss:[0.3865521252155304, 0.38464802503585815, 0.0009520549792796373]\n",
            "Batch:501\n",
            "d_loss:0.2132551009344752\n",
            "g_loss:[0.3555948734283447, 0.35451388359069824, 0.0005404884577728808]\n",
            "========================================\n",
            "Epoch is: 124\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.283081127564742\n",
            "g_loss:[0.353667676448822, 0.3532590866088867, 0.00020429378491826355]\n",
            "Batch:101\n",
            "d_loss:0.27511411568957556\n",
            "g_loss:[0.3812398314476013, 0.3810890018939972, 7.542012463090941e-05]\n",
            "Batch:201\n",
            "d_loss:0.2092476112602526\n",
            "g_loss:[0.4057220220565796, 0.4017154574394226, 0.0020032802131026983]\n",
            "Batch:301\n",
            "d_loss:0.20865055739523086\n",
            "g_loss:[0.3589601218700409, 0.358536958694458, 0.00021158013259992003]\n",
            "Batch:401\n",
            "d_loss:0.2815458592540381\n",
            "g_loss:[0.36430785059928894, 0.3620731234550476, 0.0011173600796610117]\n",
            "Batch:501\n",
            "d_loss:0.2304393910744693\n",
            "g_loss:[0.3531726896762848, 0.35198983550071716, 0.0005914286011829972]\n",
            "========================================\n",
            "Epoch is: 125\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18694383418360871\n",
            "g_loss:[0.3474043905735016, 0.3468738794326782, 0.0002652609837241471]\n",
            "Batch:101\n",
            "d_loss:0.24608285404247\n",
            "g_loss:[0.4193022847175598, 0.4129546284675598, 0.0031738304533064365]\n",
            "Batch:201\n",
            "d_loss:0.2805910030601808\n",
            "g_loss:[0.3423394560813904, 0.3404804766178131, 0.0009294855990447104]\n",
            "Batch:301\n",
            "d_loss:0.18534804940009053\n",
            "g_loss:[0.34524962306022644, 0.34340184926986694, 0.0009238868369720876]\n",
            "Batch:401\n",
            "d_loss:0.38979751598662915\n",
            "g_loss:[0.348995566368103, 0.34806638956069946, 0.0004645868029911071]\n",
            "Batch:501\n",
            "d_loss:0.295374105121482\n",
            "g_loss:[0.4362837076187134, 0.4320131242275238, 0.002135292859748006]\n",
            "========================================\n",
            "Epoch is: 126\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.29737325017299554\n",
            "g_loss:[0.34912389516830444, 0.346879780292511, 0.0011220516171306372]\n",
            "Batch:101\n",
            "d_loss:0.33694455204431506\n",
            "g_loss:[0.3696907162666321, 0.36838167905807495, 0.0006545230280607939]\n",
            "Batch:201\n",
            "d_loss:0.6009816767709708\n",
            "g_loss:[0.34920716285705566, 0.3482345938682556, 0.0004862900241278112]\n",
            "Batch:301\n",
            "d_loss:0.20581128820847994\n",
            "g_loss:[0.36531007289886475, 0.358296275138855, 0.0035069063305854797]\n",
            "Batch:401\n",
            "d_loss:0.3099061469679327\n",
            "g_loss:[0.3497713506221771, 0.34925705194473267, 0.0002571514924056828]\n",
            "Batch:501\n",
            "d_loss:0.19959831401092742\n",
            "g_loss:[0.35917648673057556, 0.3575449585914612, 0.0008157621487043798]\n",
            "========================================\n",
            "Epoch is: 127\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.24836360337349106\n",
            "g_loss:[0.410645455121994, 0.40806591510772705, 0.0012897644191980362]\n",
            "Batch:101\n",
            "d_loss:0.21886042342157452\n",
            "g_loss:[0.34411364793777466, 0.3437883257865906, 0.00016265625890810043]\n",
            "Batch:201\n",
            "d_loss:0.21861457398335915\n",
            "g_loss:[0.3479709029197693, 0.3472542464733124, 0.00035832927096635103]\n",
            "Batch:301\n",
            "d_loss:0.1958993312587154\n",
            "g_loss:[0.35802531242370605, 0.3567999303340912, 0.0006126980297267437]\n",
            "Batch:401\n",
            "d_loss:0.23258052053347456\n",
            "g_loss:[0.398447185754776, 0.3949759006500244, 0.001735645579174161]\n",
            "Batch:501\n",
            "d_loss:0.23571288237644694\n",
            "g_loss:[0.3821265399456024, 0.38108792901039124, 0.000519310764502734]\n",
            "========================================\n",
            "Epoch is: 128\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3472744324264454\n",
            "g_loss:[0.3583744168281555, 0.35656750202178955, 0.0009034588583745062]\n",
            "Batch:101\n",
            "d_loss:0.27000766085257055\n",
            "g_loss:[0.35050126910209656, 0.34912973642349243, 0.0006857687258161604]\n",
            "Batch:201\n",
            "d_loss:0.2056684702165512\n",
            "g_loss:[0.34929540753364563, 0.3477499485015869, 0.0007727346383035183]\n",
            "Batch:301\n",
            "d_loss:0.1932194761905066\n",
            "g_loss:[0.39137789607048035, 0.3905639052391052, 0.00040699541568756104]\n",
            "Batch:401\n",
            "d_loss:0.236629409487648\n",
            "g_loss:[0.3502503037452698, 0.3487245440483093, 0.0007628783932887018]\n",
            "Batch:501\n",
            "d_loss:0.1996143092874263\n",
            "g_loss:[0.3428548574447632, 0.34198707342147827, 0.000433892389992252]\n",
            "========================================\n",
            "Epoch is: 129\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.1789227693968769\n",
            "g_loss:[0.34604522585868835, 0.34494441747665405, 0.000550400058273226]\n",
            "Batch:101\n",
            "d_loss:0.23779118218953954\n",
            "g_loss:[0.3510979413986206, 0.3467139005661011, 0.0021920260041952133]\n",
            "Batch:201\n",
            "d_loss:0.20401753731130157\n",
            "g_loss:[0.34898093342781067, 0.34802812337875366, 0.00047640729462727904]\n",
            "Batch:301\n",
            "d_loss:0.21056712048130066\n",
            "g_loss:[0.39211735129356384, 0.390169620513916, 0.0009738603257574141]\n",
            "Batch:401\n",
            "d_loss:0.27731259684833276\n",
            "g_loss:[0.3490317761898041, 0.3488389849662781, 9.639584459364414e-05]\n",
            "Batch:501\n",
            "d_loss:0.20129455864571355\n",
            "g_loss:[0.34223270416259766, 0.3418455123901367, 0.00019359900034032762]\n",
            "========================================\n",
            "Epoch is: 130\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.1811005987729004\n",
            "g_loss:[0.458634614944458, 0.45837464928627014, 0.00012998736929148436]\n",
            "Batch:101\n",
            "d_loss:0.31356320605118526\n",
            "g_loss:[0.3870203495025635, 0.38588201999664307, 0.0005691619589924812]\n",
            "Batch:201\n",
            "d_loss:0.2181251883303048\n",
            "g_loss:[0.35982251167297363, 0.3587149977684021, 0.0005537586403079331]\n",
            "Batch:301\n",
            "d_loss:0.21025880774686811\n",
            "g_loss:[0.3637683689594269, 0.3601072430610657, 0.0018305657431483269]\n",
            "Batch:401\n",
            "d_loss:0.28917341352371295\n",
            "g_loss:[0.3669700026512146, 0.3632228970527649, 0.0018735453486442566]\n",
            "Batch:501\n",
            "d_loss:0.22391787935748653\n",
            "g_loss:[0.3707673251628876, 0.36563295125961304, 0.0025671820621937513]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 131\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2048492474532395\n",
            "g_loss:[0.34388113021850586, 0.34219250082969666, 0.000844318070448935]\n",
            "Batch:101\n",
            "d_loss:0.35474233229842866\n",
            "g_loss:[0.4123244285583496, 0.411584734916687, 0.000369852758012712]\n",
            "Batch:201\n",
            "d_loss:0.22708221019820485\n",
            "g_loss:[0.3457982838153839, 0.34298157691955566, 0.0014083499554544687]\n",
            "Batch:301\n",
            "d_loss:0.21353800922224764\n",
            "g_loss:[0.4401547610759735, 0.43864646553993225, 0.0007541453815065324]\n",
            "Batch:401\n",
            "d_loss:0.6164414298473275\n",
            "g_loss:[0.47466444969177246, 0.4698755145072937, 0.0023944659624248743]\n",
            "Batch:501\n",
            "d_loss:0.19817295811571967\n",
            "g_loss:[0.37213975191116333, 0.3710111379623413, 0.0005643079057335854]\n",
            "========================================\n",
            "Epoch is: 132\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.24998615380491174\n",
            "g_loss:[0.3535289764404297, 0.3518484830856323, 0.0008402492967434227]\n",
            "Batch:101\n",
            "d_loss:0.20930959459565202\n",
            "g_loss:[0.3661975860595703, 0.3636842370033264, 0.001256673946045339]\n",
            "Batch:201\n",
            "d_loss:0.3055779051137506\n",
            "g_loss:[0.3430432379245758, 0.341958612203598, 0.0005423142574727535]\n",
            "Batch:301\n",
            "d_loss:0.27772204872326256\n",
            "g_loss:[0.3571571707725525, 0.356635719537735, 0.00026072608307003975]\n",
            "Batch:401\n",
            "d_loss:0.23825090310856467\n",
            "g_loss:[0.3408278226852417, 0.337634801864624, 0.0015965071506798267]\n",
            "Batch:501\n",
            "d_loss:0.232431574486327\n",
            "g_loss:[0.42942389845848083, 0.4238128066062927, 0.0028055428992956877]\n",
            "========================================\n",
            "Epoch is: 133\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3978480859766478\n",
            "g_loss:[0.43582025170326233, 0.4306239187717438, 0.002598167397081852]\n",
            "Batch:101\n",
            "d_loss:0.2129188138860627\n",
            "g_loss:[0.3576345443725586, 0.35673022270202637, 0.0004521605442278087]\n",
            "Batch:201\n",
            "d_loss:0.496689450534177\n",
            "g_loss:[0.376919150352478, 0.37670546770095825, 0.000106843639514409]\n",
            "Batch:301\n",
            "d_loss:0.18249094391740073\n",
            "g_loss:[0.4106268882751465, 0.40877044200897217, 0.0009282168466597795]\n",
            "Batch:401\n",
            "d_loss:0.18972112861956703\n",
            "g_loss:[0.33971554040908813, 0.33683717250823975, 0.001439184881746769]\n",
            "Batch:501\n",
            "d_loss:0.20604925708357769\n",
            "g_loss:[0.3397518992424011, 0.3384037911891937, 0.0006740469834767282]\n",
            "========================================\n",
            "Epoch is: 134\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.37852333323644416\n",
            "g_loss:[0.33915555477142334, 0.3389536440372467, 0.00010095912148244679]\n",
            "Batch:101\n",
            "d_loss:0.21285339312453289\n",
            "g_loss:[0.37976959347724915, 0.3775380849838257, 0.0011157514527440071]\n",
            "Batch:201\n",
            "d_loss:0.2104038478428265\n",
            "g_loss:[0.3815141022205353, 0.3804778754711151, 0.0005181155866011977]\n",
            "Batch:301\n",
            "d_loss:0.2155724699050552\n",
            "g_loss:[0.3508346974849701, 0.3481079936027527, 0.0013633461203426123]\n",
            "Batch:401\n",
            "d_loss:0.25305099414595134\n",
            "g_loss:[0.3485037386417389, 0.3473658859729767, 0.000568919291254133]\n",
            "Batch:501\n",
            "d_loss:0.2280356999299329\n",
            "g_loss:[0.34902137517929077, 0.3469187617301941, 0.001051309984177351]\n",
            "========================================\n",
            "Epoch is: 135\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.36432703146329004\n",
            "g_loss:[0.38369160890579224, 0.3825584053993225, 0.0005666010547429323]\n",
            "Batch:101\n",
            "d_loss:0.2425511972651293\n",
            "g_loss:[0.3771666884422302, 0.37336266040802, 0.0019020208856090903]\n",
            "Batch:201\n",
            "d_loss:0.3173580206657789\n",
            "g_loss:[0.34838035702705383, 0.347886860370636, 0.0002467515296302736]\n",
            "Batch:301\n",
            "d_loss:0.38902218901921515\n",
            "g_loss:[0.3489157259464264, 0.3487445116043091, 8.560388232581317e-05]\n",
            "Batch:401\n",
            "d_loss:0.30296230444037064\n",
            "g_loss:[0.4519791901111603, 0.4510807991027832, 0.00044919521315023303]\n",
            "Batch:501\n",
            "d_loss:0.1989122996255901\n",
            "g_loss:[0.38903602957725525, 0.3888404369354248, 9.779234824236482e-05]\n",
            "========================================\n",
            "Epoch is: 136\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18288828386425848\n",
            "g_loss:[0.361565500497818, 0.3614926040172577, 3.6455436202231795e-05]\n",
            "Batch:101\n",
            "d_loss:0.3263941846835223\n",
            "g_loss:[0.4132304787635803, 0.4118663966655731, 0.0006820398266427219]\n",
            "Batch:201\n",
            "d_loss:0.3502119042495906\n",
            "g_loss:[0.35056957602500916, 0.34900742769241333, 0.0007810682873241603]\n",
            "Batch:301\n",
            "d_loss:0.5248070363959414\n",
            "g_loss:[0.3626263737678528, 0.3613666892051697, 0.0006298433290794492]\n",
            "Batch:401\n",
            "d_loss:0.2773343275835032\n",
            "g_loss:[0.3714333772659302, 0.3707740008831024, 0.0003296861541457474]\n",
            "Batch:501\n",
            "d_loss:0.22108459559240146\n",
            "g_loss:[0.4803415536880493, 0.4799766540527344, 0.00018245309183839709]\n",
            "========================================\n",
            "Epoch is: 137\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18097054470132434\n",
            "g_loss:[0.39469024538993835, 0.39453309774398804, 7.856845331843942e-05]\n",
            "Batch:101\n",
            "d_loss:0.735041211412863\n",
            "g_loss:[0.3518476188182831, 0.35079920291900635, 0.0005242028273642063]\n",
            "Batch:201\n",
            "d_loss:0.20478107537655887\n",
            "g_loss:[0.3476223349571228, 0.34546616673469543, 0.001078085508197546]\n",
            "Batch:301\n",
            "d_loss:0.2875105403290945\n",
            "g_loss:[0.45719143748283386, 0.45670896768569946, 0.00024123358889482915]\n",
            "Batch:401\n",
            "d_loss:0.23862061138504487\n",
            "g_loss:[0.3422986567020416, 0.3410201072692871, 0.0006392802461050451]\n",
            "Batch:501\n",
            "d_loss:0.24558907166942845\n",
            "g_loss:[0.369829922914505, 0.36591652035713196, 0.001956694759428501]\n",
            "========================================\n",
            "Epoch is: 138\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18173310596284864\n",
            "g_loss:[0.342849463224411, 0.3406292498111725, 0.0011101138079538941]\n",
            "Batch:101\n",
            "d_loss:0.2241907616289609\n",
            "g_loss:[0.35428035259246826, 0.35278522968292236, 0.0007475586025975645]\n",
            "Batch:201\n",
            "d_loss:0.19395512783012236\n",
            "g_loss:[0.35589078068733215, 0.3554408848285675, 0.00022494775475934148]\n",
            "Batch:301\n",
            "d_loss:0.24567685140573303\n",
            "g_loss:[0.40420085191726685, 0.40327775478363037, 0.00046154874144122005]\n",
            "Batch:401\n",
            "d_loss:0.19650742458225068\n",
            "g_loss:[0.3493897616863251, 0.3466838002204895, 0.0013529863208532333]\n",
            "Batch:501\n",
            "d_loss:0.18949790704937186\n",
            "g_loss:[0.34854352474212646, 0.3468526601791382, 0.0008454332710243762]\n",
            "========================================\n",
            "Epoch is: 139\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18011059449133882\n",
            "g_loss:[0.3432236909866333, 0.3387928903102875, 0.002215396612882614]\n",
            "Batch:101\n",
            "d_loss:0.2486245737554782\n",
            "g_loss:[0.34910377860069275, 0.34747231006622314, 0.0008157345582731068]\n",
            "Batch:201\n",
            "d_loss:0.21135931025446553\n",
            "g_loss:[0.4785439074039459, 0.47743576765060425, 0.0005540757556445897]\n",
            "Batch:301\n",
            "d_loss:0.4858900420458667\n",
            "g_loss:[0.3401280343532562, 0.3394874930381775, 0.0003202656516805291]\n",
            "Batch:401\n",
            "d_loss:0.5338714595567353\n",
            "g_loss:[0.3586484491825104, 0.3569628596305847, 0.000842789129819721]\n",
            "Batch:501\n",
            "d_loss:0.6342900907651483\n",
            "g_loss:[0.3525945842266083, 0.35166358947753906, 0.0004654997610487044]\n",
            "========================================\n",
            "Epoch is: 140\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.22516027915753511\n",
            "g_loss:[0.349505215883255, 0.34835150837898254, 0.0005768580012954772]\n",
            "Batch:101\n",
            "d_loss:0.32076504153883434\n",
            "g_loss:[0.3447574973106384, 0.343661904335022, 0.0005477998638525605]\n",
            "Batch:201\n",
            "d_loss:0.22715586116282793\n",
            "g_loss:[0.34480637311935425, 0.3438985347747803, 0.00045391221647150815]\n",
            "Batch:301\n",
            "d_loss:0.20200535438834777\n",
            "g_loss:[0.3458297848701477, 0.34247860312461853, 0.001675592502579093]\n",
            "Batch:401\n",
            "d_loss:0.23424367906318366\n",
            "g_loss:[0.3612237572669983, 0.3597204387187958, 0.0007516636978834867]\n",
            "Batch:501\n",
            "d_loss:0.18571262737214056\n",
            "g_loss:[0.3587077856063843, 0.35791853070259094, 0.00039462640415877104]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 141\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3644800233008709\n",
            "g_loss:[0.3943159878253937, 0.3934023082256317, 0.0004568359872791916]\n",
            "Batch:101\n",
            "d_loss:0.23025248410340282\n",
            "g_loss:[0.35378360748291016, 0.35258790850639343, 0.000597846694290638]\n",
            "Batch:201\n",
            "d_loss:0.2707078520252253\n",
            "g_loss:[0.3652903139591217, 0.3640238642692566, 0.0006332210032269359]\n",
            "Batch:301\n",
            "d_loss:0.20206929431606113\n",
            "g_loss:[0.3621734082698822, 0.35112667083740234, 0.005523367784917355]\n",
            "Batch:401\n",
            "d_loss:0.22685482733982099\n",
            "g_loss:[0.3476841151714325, 0.3472746014595032, 0.00020475548808462918]\n",
            "Batch:501\n",
            "d_loss:0.20389380452525074\n",
            "g_loss:[0.3506357967853546, 0.34814921021461487, 0.001243295264430344]\n",
            "========================================\n",
            "Epoch is: 142\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:1.129479098952288\n",
            "g_loss:[0.35023272037506104, 0.3480162024497986, 0.0011082598939538002]\n",
            "Batch:101\n",
            "d_loss:0.21458252579850523\n",
            "g_loss:[0.3410617709159851, 0.3390800952911377, 0.0009908360661938787]\n",
            "Batch:201\n",
            "d_loss:0.48070354026458517\n",
            "g_loss:[0.4518374502658844, 0.4507622718811035, 0.0005375926848500967]\n",
            "Batch:301\n",
            "d_loss:0.24372651096928166\n",
            "g_loss:[0.34438541531562805, 0.34299468994140625, 0.0006953635020181537]\n",
            "Batch:401\n",
            "d_loss:0.21725923721896834\n",
            "g_loss:[0.39050889015197754, 0.38988929986953735, 0.0003098006418440491]\n",
            "Batch:501\n",
            "d_loss:0.246358375352429\n",
            "g_loss:[0.3788589537143707, 0.37653690576553345, 0.001161022111773491]\n",
            "========================================\n",
            "Epoch is: 143\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.7734287593078761\n",
            "g_loss:[0.38869792222976685, 0.38750532269477844, 0.0005962976720184088]\n",
            "Batch:101\n",
            "d_loss:0.23991771867440548\n",
            "g_loss:[0.3455239534378052, 0.3449389934539795, 0.00029248447390273213]\n",
            "Batch:201\n",
            "d_loss:0.20628181411848345\n",
            "g_loss:[0.3761742115020752, 0.37570467591285706, 0.00023477345530409366]\n",
            "Batch:301\n",
            "d_loss:0.27792997645929063\n",
            "g_loss:[0.4098011255264282, 0.40857023000717163, 0.0006154406582936645]\n",
            "Batch:401\n",
            "d_loss:0.32037885530735366\n",
            "g_loss:[0.4485078752040863, 0.44664305448532104, 0.0009324051206931472]\n",
            "Batch:501\n",
            "d_loss:0.2017805211189625\n",
            "g_loss:[0.3431756794452667, 0.3381715416908264, 0.0025020684115588665]\n",
            "========================================\n",
            "Epoch is: 144\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.23653491657694303\n",
            "g_loss:[0.5273317098617554, 0.5219209790229797, 0.0027053775265812874]\n",
            "Batch:101\n",
            "d_loss:0.3389424764582145\n",
            "g_loss:[0.351995587348938, 0.34799742698669434, 0.001999075524508953]\n",
            "Batch:201\n",
            "d_loss:0.4061895743361674\n",
            "g_loss:[0.3988088369369507, 0.3948003947734833, 0.0020042199175804853]\n",
            "Batch:301\n",
            "d_loss:0.19462112553992483\n",
            "g_loss:[0.3495231568813324, 0.34864914417266846, 0.00043701124377548695]\n",
            "Batch:401\n",
            "d_loss:0.3244210379625656\n",
            "g_loss:[0.4241672456264496, 0.42330291867256165, 0.00043216132326051593]\n",
            "Batch:501\n",
            "d_loss:0.20299024764244677\n",
            "g_loss:[0.3515114188194275, 0.3479176461696625, 0.0017968887696042657]\n",
            "========================================\n",
            "Epoch is: 145\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4753231222730392\n",
            "g_loss:[0.3504357635974884, 0.34931787848472595, 0.0005589424981735647]\n",
            "Batch:101\n",
            "d_loss:0.21889589076954508\n",
            "g_loss:[0.34011074900627136, 0.33887606859207153, 0.0006173420697450638]\n",
            "Batch:201\n",
            "d_loss:0.19424257271748502\n",
            "g_loss:[0.374337375164032, 0.37056612968444824, 0.0018856299575418234]\n",
            "Batch:301\n",
            "d_loss:0.2174570892329939\n",
            "g_loss:[0.4353903532028198, 0.4286959171295166, 0.003347211517393589]\n",
            "Batch:401\n",
            "d_loss:0.36367047374824324\n",
            "g_loss:[0.3391062021255493, 0.3380756378173828, 0.000515278079546988]\n",
            "Batch:501\n",
            "d_loss:0.18521822119873832\n",
            "g_loss:[0.3694973587989807, 0.36524057388305664, 0.002128398511558771]\n",
            "========================================\n",
            "Epoch is: 146\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.22723044478959764\n",
            "g_loss:[0.46412980556488037, 0.4597310423851013, 0.002199377864599228]\n",
            "Batch:101\n",
            "d_loss:0.2486206253306591\n",
            "g_loss:[0.3427974581718445, 0.34245094656944275, 0.00017325408407486975]\n",
            "Batch:201\n",
            "d_loss:0.22158900448994245\n",
            "g_loss:[0.35136404633522034, 0.3511337637901306, 0.00011514047218952328]\n",
            "Batch:301\n",
            "d_loss:0.19024544433887058\n",
            "g_loss:[0.4288311004638672, 0.4231024980545044, 0.0028643072582781315]\n",
            "Batch:401\n",
            "d_loss:0.23236590900705778\n",
            "g_loss:[0.41468319296836853, 0.41392990946769714, 0.0003766458248719573]\n",
            "Batch:501\n",
            "d_loss:0.21014545620528224\n",
            "g_loss:[0.3827640414237976, 0.38237035274505615, 0.00019684468861669302]\n",
            "========================================\n",
            "Epoch is: 147\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2554777110822215\n",
            "g_loss:[0.39842984080314636, 0.3981836140155792, 0.00012311339378356934]\n",
            "Batch:101\n",
            "d_loss:0.22619796247818158\n",
            "g_loss:[0.3957883417606354, 0.3950158357620239, 0.0003862566372845322]\n",
            "Batch:201\n",
            "d_loss:0.27996274851466296\n",
            "g_loss:[0.3734886646270752, 0.3725459575653076, 0.00047134998021647334]\n",
            "Batch:301\n",
            "d_loss:0.17924746217795473\n",
            "g_loss:[0.3442361056804657, 0.3430996537208557, 0.000568223767913878]\n",
            "Batch:401\n",
            "d_loss:0.5747070035868092\n",
            "g_loss:[0.40874093770980835, 0.4060975909233093, 0.001321671879850328]\n",
            "Batch:501\n",
            "d_loss:0.2339263561862026\n",
            "g_loss:[0.3791539967060089, 0.37806493043899536, 0.0005445285933092237]\n",
            "========================================\n",
            "Epoch is: 148\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18885468761504853\n",
            "g_loss:[0.5976192951202393, 0.5966910719871521, 0.00046410990762524307]\n",
            "Batch:101\n",
            "d_loss:0.4510692051094338\n",
            "g_loss:[0.33641117811203003, 0.3353027403354645, 0.0005542209837585688]\n",
            "Batch:201\n",
            "d_loss:0.205249681856003\n",
            "g_loss:[0.34183555841445923, 0.33962953090667725, 0.0011030181776732206]\n",
            "Batch:301\n",
            "d_loss:0.17482331888822955\n",
            "g_loss:[0.36297714710235596, 0.36108702421188354, 0.0009450679644942284]\n",
            "Batch:401\n",
            "d_loss:0.22696844423126095\n",
            "g_loss:[0.3776457607746124, 0.37223416566848755, 0.002705793362110853]\n",
            "Batch:501\n",
            "d_loss:0.239954179724009\n",
            "g_loss:[0.395891398191452, 0.39454972743988037, 0.0006708336295560002]\n",
            "========================================\n",
            "Epoch is: 149\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.20683008694868477\n",
            "g_loss:[0.45565348863601685, 0.45444926619529724, 0.0006021045846864581]\n",
            "Batch:101\n",
            "d_loss:0.21239258821879048\n",
            "g_loss:[0.3728940784931183, 0.37224218249320984, 0.0003259497752878815]\n",
            "Batch:201\n",
            "d_loss:0.31265226871073537\n",
            "g_loss:[0.3596504032611847, 0.35669416189193726, 0.0014781220816075802]\n",
            "Batch:301\n",
            "d_loss:0.1752307764136276\n",
            "g_loss:[0.3424369990825653, 0.3414934575557709, 0.0004717655829153955]\n",
            "Batch:401\n",
            "d_loss:0.1881103045375312\n",
            "g_loss:[0.42468786239624023, 0.42447444796562195, 0.00010671286145225167]\n",
            "Batch:501\n",
            "d_loss:0.4488466911125215\n",
            "g_loss:[0.3469046354293823, 0.34295082092285156, 0.0019769102800637484]\n",
            "========================================\n",
            "Epoch is: 150\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.3571580173675102\n",
            "g_loss:[0.33810925483703613, 0.33740875124931335, 0.00035024687531404197]\n",
            "Batch:101\n",
            "d_loss:0.26531389609590406\n",
            "g_loss:[0.37206903100013733, 0.36783912777900696, 0.0021149558015167713]\n",
            "Batch:201\n",
            "d_loss:0.2026527154393989\n",
            "g_loss:[0.3613785207271576, 0.36026784777641296, 0.0005553411319851875]\n",
            "Batch:301\n",
            "d_loss:0.20278782424702513\n",
            "g_loss:[0.3416323661804199, 0.34081709384918213, 0.00040763505967333913]\n",
            "Batch:401\n",
            "d_loss:0.3203378883345067\n",
            "g_loss:[0.4179287850856781, 0.3666013181209564, 0.02566373161971569]\n",
            "Batch:501\n",
            "d_loss:0.1790626053948472\n",
            "g_loss:[0.35981693863868713, 0.35938459634780884, 0.00021617449237965047]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "Guardo pesos\n",
            "========================================\n",
            "Epoch is: 151\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.1835605534744218\n",
            "g_loss:[0.3627132773399353, 0.3622853755950928, 0.0002139499702025205]\n",
            "Batch:101\n",
            "d_loss:0.24667050349580677\n",
            "g_loss:[0.3642169237136841, 0.363969624042511, 0.00012365082511678338]\n",
            "Batch:201\n",
            "d_loss:0.20112070196955756\n",
            "g_loss:[0.34107717871665955, 0.3409501016139984, 6.353884964482859e-05]\n",
            "Batch:301\n",
            "d_loss:0.23892181682458613\n",
            "g_loss:[0.37643423676490784, 0.3759295344352722, 0.00025235229986719787]\n",
            "Batch:401\n",
            "d_loss:0.37713727612754155\n",
            "g_loss:[0.4427350163459778, 0.44246336817741394, 0.00013582303654402494]\n",
            "Batch:501\n",
            "d_loss:0.1909702293241935\n",
            "g_loss:[0.38061094284057617, 0.3803071677684784, 0.00015188999532256275]\n",
            "========================================\n",
            "Epoch is: 152\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.17922985717012807\n",
            "g_loss:[0.33947351574897766, 0.3391977846622467, 0.00013786405907012522]\n",
            "Batch:101\n",
            "d_loss:0.33646728180792707\n",
            "g_loss:[0.3667376935482025, 0.36609187722206116, 0.0003229097346775234]\n",
            "Batch:201\n",
            "d_loss:0.1853909682486119\n",
            "g_loss:[0.33825981616973877, 0.3380299210548401, 0.00011495302896946669]\n",
            "Batch:301\n",
            "d_loss:0.18554950213638222\n",
            "g_loss:[0.4215841591358185, 0.42110541462898254, 0.00023937149671837687]\n",
            "Batch:401\n",
            "d_loss:0.30258008366581635\n",
            "g_loss:[0.4710772633552551, 0.47048845887184143, 0.0002943967410828918]\n",
            "Batch:501\n",
            "d_loss:0.20158100926801126\n",
            "g_loss:[0.35246533155441284, 0.3515854477882385, 0.00043994217412546277]\n",
            "========================================\n",
            "Epoch is: 153\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.4302607572191164\n",
            "g_loss:[0.33654478192329407, 0.3347117304801941, 0.0009165189694613218]\n",
            "Batch:101\n",
            "d_loss:0.2740141705314727\n",
            "g_loss:[0.35798054933547974, 0.3562805950641632, 0.0008499696850776672]\n",
            "Batch:201\n",
            "d_loss:0.23511332776433846\n",
            "g_loss:[0.3611219823360443, 0.3599622845649719, 0.0005798515630885959]\n",
            "Batch:301\n",
            "d_loss:0.19413286100461846\n",
            "g_loss:[0.3530949056148529, 0.3521381616592407, 0.00047837640158832073]\n",
            "Batch:401\n",
            "d_loss:0.5352354733186075\n",
            "g_loss:[0.36704692244529724, 0.36477911472320557, 0.0011339002521708608]\n",
            "Batch:501\n",
            "d_loss:0.19413549935143237\n",
            "g_loss:[0.38152578473091125, 0.3806034326553345, 0.00046117365127429366]\n",
            "========================================\n",
            "Epoch is: 154\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.21163362803986274\n",
            "g_loss:[0.3388417661190033, 0.3387131690979004, 6.430103530874476e-05]\n",
            "Batch:101\n",
            "d_loss:0.23660481017941493\n",
            "g_loss:[0.3482217788696289, 0.34757956862449646, 0.00032110774191096425]\n",
            "Batch:201\n",
            "d_loss:0.1908958808562602\n",
            "g_loss:[0.3425396978855133, 0.3411049544811249, 0.0007173748454079032]\n",
            "Batch:301\n",
            "d_loss:0.18482477573343203\n",
            "g_loss:[0.34417590498924255, 0.3426007926464081, 0.0007875529117882252]\n",
            "Batch:401\n",
            "d_loss:0.21641968680933132\n",
            "g_loss:[0.34739506244659424, 0.3467681407928467, 0.0003134641156066209]\n",
            "Batch:501\n",
            "d_loss:0.19762898389308248\n",
            "g_loss:[0.35483163595199585, 0.3535047173500061, 0.0006634638411924243]\n",
            "========================================\n",
            "Epoch is: 155\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18327833574835495\n",
            "g_loss:[0.4081716537475586, 0.40547484159469604, 0.0013484037481248379]\n",
            "Batch:101\n",
            "d_loss:0.20695687978513888\n",
            "g_loss:[0.3667764365673065, 0.3661837577819824, 0.0002963389561045915]\n",
            "Batch:201\n",
            "d_loss:0.183874930262391\n",
            "g_loss:[0.3491766154766083, 0.3476031422615051, 0.0007867311360314488]\n",
            "Batch:301\n",
            "d_loss:0.18185017939686077\n",
            "g_loss:[0.3933895528316498, 0.3871695399284363, 0.003110012970864773]\n",
            "Batch:401\n",
            "d_loss:0.37430869948821055\n",
            "g_loss:[0.35990116000175476, 0.3585613965988159, 0.0006698787328787148]\n",
            "Batch:501\n",
            "d_loss:0.21087155439454364\n",
            "g_loss:[0.3936270475387573, 0.3921099901199341, 0.0007585326675325632]\n",
            "========================================\n",
            "Epoch is: 156\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.6348689046317304\n",
            "g_loss:[0.3701355457305908, 0.3696030378341675, 0.0002662539482116699]\n",
            "Batch:101\n",
            "d_loss:0.21643441597507262\n",
            "g_loss:[0.3427506387233734, 0.3405737578868866, 0.0010884383227676153]\n",
            "Batch:201\n",
            "d_loss:0.19706517674785573\n",
            "g_loss:[0.3381989598274231, 0.33779728412628174, 0.00020083182607777417]\n",
            "Batch:301\n",
            "d_loss:0.175689703619355\n",
            "g_loss:[0.33724159002304077, 0.3369990885257721, 0.00012125686043873429]\n",
            "Batch:401\n",
            "d_loss:0.3020853583839198\n",
            "g_loss:[0.4130927622318268, 0.407134085893631, 0.0029793367721140385]\n",
            "Batch:501\n",
            "d_loss:0.2153779364998627\n",
            "g_loss:[0.4758199155330658, 0.4740525186061859, 0.0008836911874823272]\n",
            "========================================\n",
            "Epoch is: 157\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.30125158063310664\n",
            "g_loss:[0.3405739665031433, 0.3401745557785034, 0.0001997026993194595]\n",
            "Batch:101\n",
            "d_loss:0.6588980196697776\n",
            "g_loss:[0.3407043516635895, 0.33974963426589966, 0.00047735226689837873]\n",
            "Batch:201\n",
            "d_loss:0.20012310054153204\n",
            "g_loss:[0.34571221470832825, 0.34435415267944336, 0.0006790301995351911]\n",
            "Batch:301\n",
            "d_loss:0.20565499586518854\n",
            "g_loss:[0.384785532951355, 0.38353097438812256, 0.0006272825412452221]\n",
            "Batch:401\n",
            "d_loss:0.23889751182650798\n",
            "g_loss:[0.3382495045661926, 0.33672332763671875, 0.0007630921900272369]\n",
            "Batch:501\n",
            "d_loss:0.19139340075798827\n",
            "g_loss:[0.3820362985134125, 0.3765290081501007, 0.0027536447159945965]\n",
            "========================================\n",
            "Epoch is: 158\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.23297593035204045\n",
            "g_loss:[0.34808415174484253, 0.3458966314792633, 0.0010937645565718412]\n",
            "Batch:101\n",
            "d_loss:0.5356116459151963\n",
            "g_loss:[0.39615491032600403, 0.3952144980430603, 0.0004702121368609369]\n",
            "Batch:201\n",
            "d_loss:0.1998253812889743\n",
            "g_loss:[0.3436843454837799, 0.34151768684387207, 0.001083332346752286]\n",
            "Batch:301\n",
            "d_loss:0.5085001274774186\n",
            "g_loss:[0.3789190351963043, 0.377983033657074, 0.0004680013516917825]\n",
            "Batch:401\n",
            "d_loss:0.2114120442482772\n",
            "g_loss:[0.39039525389671326, 0.3898043632507324, 0.00029545198776759207]\n",
            "Batch:501\n",
            "d_loss:0.22685536093467817\n",
            "g_loss:[0.372657835483551, 0.3719906210899353, 0.00033360766246914864]\n",
            "========================================\n",
            "Epoch is: 159\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.26874106090690475\n",
            "g_loss:[0.43297311663627625, 0.4320840835571289, 0.000444514473201707]\n",
            "Batch:101\n",
            "d_loss:0.2155481278496154\n",
            "g_loss:[0.35164889693260193, 0.35134097933769226, 0.00015395745867863297]\n",
            "Batch:201\n",
            "d_loss:0.19588392993682646\n",
            "g_loss:[0.34811270236968994, 0.34733545780181885, 0.0003886246995534748]\n",
            "Batch:301\n",
            "d_loss:0.19302310641614895\n",
            "g_loss:[0.5362216234207153, 0.5359418392181396, 0.00013988831778988242]\n",
            "Batch:401\n",
            "d_loss:0.22950015543187874\n",
            "g_loss:[0.34590181708335876, 0.34383851289749146, 0.0010316537227481604]\n",
            "Batch:501\n",
            "d_loss:0.1887794221497643\n",
            "g_loss:[0.35742971301078796, 0.34520915150642395, 0.006110284477472305]\n",
            "========================================\n",
            "Epoch is: 160\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.277040538848496\n",
            "g_loss:[0.354431688785553, 0.34531694650650024, 0.004557366482913494]\n",
            "Batch:101\n",
            "d_loss:0.3935872776000906\n",
            "g_loss:[0.36674439907073975, 0.3636035621166229, 0.001570422202348709]\n",
            "Batch:201\n",
            "d_loss:0.313443667257161\n",
            "g_loss:[0.33807089924812317, 0.3372921943664551, 0.00038934865733608603]\n",
            "Batch:301\n",
            "d_loss:0.1992343672827701\n",
            "g_loss:[0.3834396302700043, 0.38224780559539795, 0.0005959161790087819]\n",
            "Batch:401\n",
            "d_loss:0.20987645656987297\n",
            "g_loss:[0.3726975619792938, 0.37145206332206726, 0.0006227535777725279]\n",
            "Batch:501\n",
            "d_loss:0.19139433971395192\n",
            "g_loss:[0.3728454113006592, 0.3726857304573059, 7.984582771314308e-05]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 161\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18291685447547934\n",
            "g_loss:[0.3408968448638916, 0.34072184562683105, 8.750394044909626e-05]\n",
            "Batch:101\n",
            "d_loss:0.1992457342587386\n",
            "g_loss:[0.3445408046245575, 0.34403109550476074, 0.0002548613410908729]\n",
            "Batch:201\n",
            "d_loss:0.17727742318857054\n",
            "g_loss:[0.3720414936542511, 0.3716907203197479, 0.00017538962129037827]\n",
            "Batch:301\n",
            "d_loss:0.2623217132750142\n",
            "g_loss:[0.40635865926742554, 0.40078800916671753, 0.0027853213250637054]\n",
            "Batch:401\n",
            "d_loss:0.20649756654847806\n",
            "g_loss:[0.4753797948360443, 0.47412899136543274, 0.0006253995234146714]\n",
            "Batch:501\n",
            "d_loss:0.2872381361257794\n",
            "g_loss:[0.3574812114238739, 0.35687363147735596, 0.00030378735391423106]\n",
            "========================================\n",
            "Epoch is: 162\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.26671075909507636\n",
            "g_loss:[0.36976614594459534, 0.3689022958278656, 0.00043192622251808643]\n",
            "Batch:101\n",
            "d_loss:0.18630290680039252\n",
            "g_loss:[0.3436072766780853, 0.3430406153202057, 0.00028333801310509443]\n",
            "Batch:201\n",
            "d_loss:0.17628561338278814\n",
            "g_loss:[0.34446075558662415, 0.3441419303417206, 0.0001594058849150315]\n",
            "Batch:301\n",
            "d_loss:0.24828016724131885\n",
            "g_loss:[0.43683093786239624, 0.4345400333404541, 0.001145452493801713]\n",
            "Batch:401\n",
            "d_loss:0.27980812313171555\n",
            "g_loss:[0.33822038769721985, 0.33635398745536804, 0.0009331952896900475]\n",
            "Batch:501\n",
            "d_loss:0.19550199391051137\n",
            "g_loss:[0.36499089002609253, 0.36361414194107056, 0.0006883789319545031]\n",
            "========================================\n",
            "Epoch is: 163\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18227305942968997\n",
            "g_loss:[0.3420122265815735, 0.3412538766860962, 0.00037918012822046876]\n",
            "Batch:101\n",
            "d_loss:0.21363978240287906\n",
            "g_loss:[0.34255579113960266, 0.3406996726989746, 0.0009280607337132096]\n",
            "Batch:201\n",
            "d_loss:0.1907603713189019\n",
            "g_loss:[0.33898869156837463, 0.3385070264339447, 0.0002408359869150445]\n",
            "Batch:301\n",
            "d_loss:0.24452302730242081\n",
            "g_loss:[0.3468628525733948, 0.3417796492576599, 0.0025416056159883738]\n",
            "Batch:401\n",
            "d_loss:0.19501674477953657\n",
            "g_loss:[0.3920517861843109, 0.3850066661834717, 0.0035225667525082827]\n",
            "Batch:501\n",
            "d_loss:0.22014822039272985\n",
            "g_loss:[0.39998579025268555, 0.39807987213134766, 0.0009529631934128702]\n",
            "========================================\n",
            "Epoch is: 164\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.40347958199708955\n",
            "g_loss:[0.346296489238739, 0.3453603982925415, 0.00046803822624497116]\n",
            "Batch:101\n",
            "d_loss:0.2842345109947928\n",
            "g_loss:[0.3773682713508606, 0.37552204728126526, 0.0009231067379005253]\n",
            "Batch:201\n",
            "d_loss:0.28161628045381804\n",
            "g_loss:[0.3592563271522522, 0.35678714513778687, 0.0012345879804342985]\n",
            "Batch:301\n",
            "d_loss:0.2378883030560246\n",
            "g_loss:[0.36730214953422546, 0.36682236194610596, 0.000239893066463992]\n",
            "Batch:401\n",
            "d_loss:0.19396155469667065\n",
            "g_loss:[0.34162482619285583, 0.33709827065467834, 0.002263277303427458]\n",
            "Batch:501\n",
            "d_loss:0.3269008662282431\n",
            "g_loss:[0.46086493134498596, 0.45777302980422974, 0.001545948558486998]\n",
            "========================================\n",
            "Epoch is: 165\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2016633547609672\n",
            "g_loss:[0.3498702347278595, 0.34722620248794556, 0.0013220130931586027]\n",
            "Batch:101\n",
            "d_loss:0.20889350790275785\n",
            "g_loss:[0.34323182702064514, 0.34222543239593506, 0.0005031937034800649]\n",
            "Batch:201\n",
            "d_loss:0.28405690961517394\n",
            "g_loss:[0.3437085449695587, 0.34204983711242676, 0.0008293612627312541]\n",
            "Batch:301\n",
            "d_loss:0.1867852040059006\n",
            "g_loss:[0.33467480540275574, 0.3342346251010895, 0.00022009052918292582]\n",
            "Batch:401\n",
            "d_loss:0.22689746778769404\n",
            "g_loss:[0.37311112880706787, 0.3703305423259735, 0.0013902989448979497]\n",
            "Batch:501\n",
            "d_loss:0.18258843652211\n",
            "g_loss:[0.3398216664791107, 0.3389661908149719, 0.00042773684253916144]\n",
            "========================================\n",
            "Epoch is: 166\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18503361319744727\n",
            "g_loss:[0.3396492302417755, 0.3392890393733978, 0.00018009157793130726]\n",
            "Batch:101\n",
            "d_loss:0.2290036562080786\n",
            "g_loss:[0.41090127825737, 0.4059494733810425, 0.0024759024381637573]\n",
            "Batch:201\n",
            "d_loss:0.2331307130807545\n",
            "g_loss:[0.3456312417984009, 0.3396119475364685, 0.003009648295119405]\n",
            "Batch:301\n",
            "d_loss:0.18375578481209232\n",
            "g_loss:[0.3562784492969513, 0.35555052757263184, 0.0003639617934823036]\n",
            "Batch:401\n",
            "d_loss:0.2765869186364398\n",
            "g_loss:[0.3386830687522888, 0.33726513385772705, 0.0007089689606800675]\n",
            "Batch:501\n",
            "d_loss:0.17394661485855067\n",
            "g_loss:[0.33712753653526306, 0.33675435185432434, 0.0001865927770268172]\n",
            "========================================\n",
            "Epoch is: 167\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.19037773352101794\n",
            "g_loss:[0.3441692888736725, 0.3438813090324402, 0.00014399457722902298]\n",
            "Batch:101\n",
            "d_loss:0.40467178810649784\n",
            "g_loss:[0.36419200897216797, 0.36245787143707275, 0.0008670694078318775]\n",
            "Batch:201\n",
            "d_loss:0.2746016824748949\n",
            "g_loss:[0.3415912687778473, 0.341012179851532, 0.00028954423032701015]\n",
            "Batch:301\n",
            "d_loss:0.2001637766152271\n",
            "g_loss:[0.40628281235694885, 0.4039151072502136, 0.0011838467326015234]\n",
            "Batch:401\n",
            "d_loss:0.27116382006897766\n",
            "g_loss:[0.34733009338378906, 0.3428734540939331, 0.002228317316621542]\n",
            "Batch:501\n",
            "d_loss:0.22135428410388158\n",
            "g_loss:[0.36164477467536926, 0.3603758215904236, 0.0006344729335978627]\n",
            "========================================\n",
            "Epoch is: 168\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2349373279395195\n",
            "g_loss:[0.3494323194026947, 0.34886807203292847, 0.0002821189700625837]\n",
            "Batch:101\n",
            "d_loss:0.19023343022990957\n",
            "g_loss:[0.35598763823509216, 0.35255134105682373, 0.0017181492876261473]\n",
            "Batch:201\n",
            "d_loss:0.20730807907602866\n",
            "g_loss:[0.3559359014034271, 0.352617084980011, 0.0016594091430306435]\n",
            "Batch:301\n",
            "d_loss:0.28579816722412943\n",
            "g_loss:[0.3525696396827698, 0.3516460061073303, 0.00046182330697774887]\n",
            "Batch:401\n",
            "d_loss:0.23454715127377312\n",
            "g_loss:[0.34550154209136963, 0.34293270111083984, 0.0012844158336520195]\n",
            "Batch:501\n",
            "d_loss:0.24912908633223196\n",
            "g_loss:[0.34790268540382385, 0.3460277318954468, 0.0009374704677611589]\n",
            "========================================\n",
            "Epoch is: 169\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.1885748586214504\n",
            "g_loss:[0.3695233166217804, 0.3673963248729706, 0.001063499366864562]\n",
            "Batch:101\n",
            "d_loss:0.19488583727934383\n",
            "g_loss:[0.34245383739471436, 0.3419429063796997, 0.000255461607594043]\n",
            "Batch:201\n",
            "d_loss:0.7191322241415037\n",
            "g_loss:[0.3601118326187134, 0.35544338822364807, 0.0023342277854681015]\n",
            "Batch:301\n",
            "d_loss:0.18064618517564668\n",
            "g_loss:[0.346269816160202, 0.34448516368865967, 0.0008923225104808807]\n",
            "Batch:401\n",
            "d_loss:0.1975992578641126\n",
            "g_loss:[0.37619104981422424, 0.37554484605789185, 0.00032310147071257234]\n",
            "Batch:501\n",
            "d_loss:0.19562666330239153\n",
            "g_loss:[0.37474411725997925, 0.35697802901268005, 0.008883041329681873]\n",
            "========================================\n",
            "Epoch is: 170\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.19072161013400546\n",
            "g_loss:[0.36099061369895935, 0.34514036774635315, 0.0079251229763031]\n",
            "Batch:101\n",
            "d_loss:0.25735897183972156\n",
            "g_loss:[0.35879600048065186, 0.35821962356567383, 0.0002881848195102066]\n",
            "Batch:201\n",
            "d_loss:0.28410370588244405\n",
            "g_loss:[0.3596256971359253, 0.3593822121620178, 0.0001217411772813648]\n",
            "Batch:301\n",
            "d_loss:0.18863625101948855\n",
            "g_loss:[0.3932439088821411, 0.3931053578853607, 6.927968934178352e-05]\n",
            "Batch:401\n",
            "d_loss:0.3104564536606631\n",
            "g_loss:[0.48317718505859375, 0.4818512201309204, 0.000662981066852808]\n",
            "Batch:501\n",
            "d_loss:0.1774492364386333\n",
            "g_loss:[0.36697685718536377, 0.3663925528526306, 0.0002921454724855721]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 171\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.17379778604299645\n",
            "g_loss:[0.3394421637058258, 0.3378795087337494, 0.0007813246338628232]\n",
            "Batch:101\n",
            "d_loss:0.2603466283276248\n",
            "g_loss:[0.3470459282398224, 0.3438568115234375, 0.0015945539344102144]\n",
            "Batch:201\n",
            "d_loss:0.3227369859232567\n",
            "g_loss:[0.3377574682235718, 0.33594048023223877, 0.0009084893390536308]\n",
            "Batch:301\n",
            "d_loss:0.20062964453245513\n",
            "g_loss:[0.35842686891555786, 0.35825657844543457, 8.514238288626075e-05]\n",
            "Batch:401\n",
            "d_loss:0.8501050251196602\n",
            "g_loss:[0.38446834683418274, 0.383914053440094, 0.0002771510917227715]\n",
            "Batch:501\n",
            "d_loss:0.2740291641657677\n",
            "g_loss:[0.3834820091724396, 0.38261550664901733, 0.00043325015576556325]\n",
            "========================================\n",
            "Epoch is: 172\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.178918983047879\n",
            "g_loss:[0.33598029613494873, 0.3349297046661377, 0.0005253019044175744]\n",
            "Batch:101\n",
            "d_loss:0.2184032942423073\n",
            "g_loss:[0.3450115919113159, 0.3439108729362488, 0.0005503619904629886]\n",
            "Batch:201\n",
            "d_loss:0.20849780732532963\n",
            "g_loss:[0.34701433777809143, 0.34530550241470337, 0.000854412151966244]\n",
            "Batch:301\n",
            "d_loss:0.19676228975731647\n",
            "g_loss:[0.3403237760066986, 0.33920857310295105, 0.0005575995892286301]\n",
            "Batch:401\n",
            "d_loss:0.21625056789252994\n",
            "g_loss:[0.37743309140205383, 0.37714052200317383, 0.0001462782674934715]\n",
            "Batch:501\n",
            "d_loss:0.18605585590103146\n",
            "g_loss:[0.3502434492111206, 0.3462717533111572, 0.0019858484156429768]\n",
            "========================================\n",
            "Epoch is: 173\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.29406172879498627\n",
            "g_loss:[0.3441765606403351, 0.3430151343345642, 0.0005807137349620461]\n",
            "Batch:101\n",
            "d_loss:0.20183361235763186\n",
            "g_loss:[0.34249597787857056, 0.3419262170791626, 0.00028488400857895613]\n",
            "Batch:201\n",
            "d_loss:0.1883095282719296\n",
            "g_loss:[0.34041669964790344, 0.34014612436294556, 0.0001352812978439033]\n",
            "Batch:301\n",
            "d_loss:0.2442554607951024\n",
            "g_loss:[0.3564268946647644, 0.35391050577163696, 0.0012581951450556517]\n",
            "Batch:401\n",
            "d_loss:0.19258311422117913\n",
            "g_loss:[0.3510967493057251, 0.3505679965019226, 0.00026437273481860757]\n",
            "Batch:501\n",
            "d_loss:0.48215816603442363\n",
            "g_loss:[0.35343730449676514, 0.35253775119781494, 0.0004497751360759139]\n",
            "========================================\n",
            "Epoch is: 174\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.32228274181397865\n",
            "g_loss:[0.3369034230709076, 0.336433470249176, 0.0002349714341107756]\n",
            "Batch:101\n",
            "d_loss:0.23068645821149403\n",
            "g_loss:[0.3433847725391388, 0.3426644206047058, 0.0003601807402446866]\n",
            "Batch:201\n",
            "d_loss:0.19669064985282603\n",
            "g_loss:[0.3406256139278412, 0.3393401801586151, 0.0006427146727219224]\n",
            "Batch:301\n",
            "d_loss:0.19641516165756912\n",
            "g_loss:[0.36282557249069214, 0.360050767660141, 0.0013874092837795615]\n",
            "Batch:401\n",
            "d_loss:0.20708070862474415\n",
            "g_loss:[0.36375266313552856, 0.36066561937332153, 0.001543527701869607]\n",
            "Batch:501\n",
            "d_loss:0.2150832505820972\n",
            "g_loss:[0.34838059544563293, 0.3472411036491394, 0.0005697437445633113]\n",
            "========================================\n",
            "Epoch is: 175\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18503289559430414\n",
            "g_loss:[0.3427756726741791, 0.34175848960876465, 0.0005085908924229443]\n",
            "Batch:101\n",
            "d_loss:0.5012810156586056\n",
            "g_loss:[0.3589096963405609, 0.3576089143753052, 0.0006503905169665813]\n",
            "Batch:201\n",
            "d_loss:0.1822685795596044\n",
            "g_loss:[0.3507687747478485, 0.3472892642021179, 0.0017397520132362843]\n",
            "Batch:301\n",
            "d_loss:0.9384159084247585\n",
            "g_loss:[0.35768184065818787, 0.35592329502105713, 0.0008792720618657768]\n",
            "Batch:401\n",
            "d_loss:0.2507246325567394\n",
            "g_loss:[0.39884626865386963, 0.3979060649871826, 0.0004701085854321718]\n",
            "Batch:501\n",
            "d_loss:0.38266850044783496\n",
            "g_loss:[0.3926094174385071, 0.3921542763710022, 0.00022757024271413684]\n",
            "========================================\n",
            "Epoch is: 176\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5969062391798161\n",
            "g_loss:[0.34065571427345276, 0.33982717990875244, 0.0004142731777392328]\n",
            "Batch:101\n",
            "d_loss:0.40632703124811087\n",
            "g_loss:[0.3380896747112274, 0.33633968234062195, 0.0008749968837946653]\n",
            "Batch:201\n",
            "d_loss:0.48666729621982086\n",
            "g_loss:[0.3740524649620056, 0.3724757432937622, 0.0007883568177931011]\n",
            "Batch:301\n",
            "d_loss:0.3811154348900345\n",
            "g_loss:[0.3819464445114136, 0.37837469577789307, 0.0017858705250546336]\n",
            "Batch:401\n",
            "d_loss:0.5283383363875487\n",
            "g_loss:[0.46575695276260376, 0.34390753507614136, 0.0609247125685215]\n",
            "Batch:501\n",
            "d_loss:0.24212482180610095\n",
            "g_loss:[0.36889955401420593, 0.36806610226631165, 0.0004167195875197649]\n",
            "========================================\n",
            "Epoch is: 177\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.21540337475494198\n",
            "g_loss:[0.48368242383003235, 0.4830329716205597, 0.00032472843304276466]\n",
            "Batch:101\n",
            "d_loss:0.21202863525104476\n",
            "g_loss:[0.41461557149887085, 0.4142177104949951, 0.00019893657008651644]\n",
            "Batch:201\n",
            "d_loss:0.27885207302188064\n",
            "g_loss:[0.3400126099586487, 0.3398594260215759, 7.659318362129852e-05]\n",
            "Batch:301\n",
            "d_loss:0.40328809532547893\n",
            "g_loss:[0.4086138606071472, 0.40837037563323975, 0.00012174126459285617]\n",
            "Batch:401\n",
            "d_loss:0.24619101384007536\n",
            "g_loss:[0.34041208028793335, 0.3400149941444397, 0.00019853710546158254]\n",
            "Batch:501\n",
            "d_loss:0.26081495290463863\n",
            "g_loss:[0.43755418062210083, 0.4373501241207123, 0.00010202956036664546]\n",
            "========================================\n",
            "Epoch is: 178\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.22148271930848296\n",
            "g_loss:[0.486006498336792, 0.48580458760261536, 0.00010095637117046863]\n",
            "Batch:101\n",
            "d_loss:0.19225328165339306\n",
            "g_loss:[0.3645807206630707, 0.3643222451210022, 0.00012924126349389553]\n",
            "Batch:201\n",
            "d_loss:0.1973338995303493\n",
            "g_loss:[0.38058575987815857, 0.38038361072540283, 0.00010106730042025447]\n",
            "Batch:301\n",
            "d_loss:0.17703915027959738\n",
            "g_loss:[0.3809095323085785, 0.3803582787513733, 0.00027562546893022954]\n",
            "Batch:401\n",
            "d_loss:0.2044875347079369\n",
            "g_loss:[0.4510962665081024, 0.44733601808547974, 0.0018801279366016388]\n",
            "Batch:501\n",
            "d_loss:0.23063105334767897\n",
            "g_loss:[0.38796356320381165, 0.38590213656425476, 0.001030710875056684]\n",
            "========================================\n",
            "Epoch is: 179\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.21627601065756608\n",
            "g_loss:[0.33914172649383545, 0.3381425142288208, 0.0004996056668460369]\n",
            "Batch:101\n",
            "d_loss:0.226609821736929\n",
            "g_loss:[0.4365770220756531, 0.43586984276771545, 0.00035359131288714707]\n",
            "Batch:201\n",
            "d_loss:0.19003546855674358\n",
            "g_loss:[0.3457861542701721, 0.34523287415504456, 0.00027664611116051674]\n",
            "Batch:301\n",
            "d_loss:0.17372431283456535\n",
            "g_loss:[0.34028491377830505, 0.33876752853393555, 0.0007586900610476732]\n",
            "Batch:401\n",
            "d_loss:0.18135408336547698\n",
            "g_loss:[0.34664446115493774, 0.3458102345466614, 0.00041711036465130746]\n",
            "Batch:501\n",
            "d_loss:0.19934393215771706\n",
            "g_loss:[0.4067765772342682, 0.40652206540107727, 0.00012725431588478386]\n",
            "========================================\n",
            "Epoch is: 180\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.1876495543619967\n",
            "g_loss:[0.36049336194992065, 0.36025112867355347, 0.00012112313561374322]\n",
            "Batch:101\n",
            "d_loss:0.35420225938423755\n",
            "g_loss:[0.3497197926044464, 0.3483026921749115, 0.0007085561519488692]\n",
            "Batch:201\n",
            "d_loss:0.20184140686706087\n",
            "g_loss:[0.34085404872894287, 0.33877480030059814, 0.0010396200232207775]\n",
            "Batch:301\n",
            "d_loss:0.18166770651350816\n",
            "g_loss:[0.3741353154182434, 0.3724128007888794, 0.0008612576639279723]\n",
            "Batch:401\n",
            "d_loss:0.20880881609582502\n",
            "g_loss:[0.3883441686630249, 0.3866397440433502, 0.00085220712935552]\n",
            "Batch:501\n",
            "d_loss:0.2507496646994696\n",
            "g_loss:[0.3462401330471039, 0.3423672020435333, 0.0019364680629223585]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 181\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.20734265743521973\n",
            "g_loss:[0.3458976149559021, 0.3443084955215454, 0.0007945633842609823]\n",
            "Batch:101\n",
            "d_loss:0.20203245463517305\n",
            "g_loss:[0.34076571464538574, 0.33814629912376404, 0.001309701008722186]\n",
            "Batch:201\n",
            "d_loss:0.18092897304450162\n",
            "g_loss:[0.3518041670322418, 0.35010674595832825, 0.0008487139130011201]\n",
            "Batch:301\n",
            "d_loss:0.19424506667746755\n",
            "g_loss:[0.3535469174385071, 0.3512459397315979, 0.0011504851281642914]\n",
            "Batch:401\n",
            "d_loss:0.19969092240989994\n",
            "g_loss:[0.378576397895813, 0.3755893111228943, 0.0014935440849512815]\n",
            "Batch:501\n",
            "d_loss:0.4464308730271114\n",
            "g_loss:[0.3594512641429901, 0.35862407088279724, 0.0004136015777476132]\n",
            "========================================\n",
            "Epoch is: 182\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.17752321837178897\n",
            "g_loss:[0.34436166286468506, 0.3440208435058594, 0.00017041689716279507]\n",
            "Batch:101\n",
            "d_loss:0.2165325674959604\n",
            "g_loss:[0.3953719139099121, 0.3946291208267212, 0.0003714016929734498]\n",
            "Batch:201\n",
            "d_loss:0.18774156155996025\n",
            "g_loss:[0.3496097922325134, 0.346768319606781, 0.001420733635313809]\n",
            "Batch:301\n",
            "d_loss:0.26108037663652794\n",
            "g_loss:[0.3440004587173462, 0.341178297996521, 0.0014110791962593794]\n",
            "Batch:401\n",
            "d_loss:0.22156653671754611\n",
            "g_loss:[0.3427621126174927, 0.341256320476532, 0.0007528997957706451]\n",
            "Batch:501\n",
            "d_loss:0.255418920426564\n",
            "g_loss:[0.40549957752227783, 0.4044848680496216, 0.0005073507782071829]\n",
            "========================================\n",
            "Epoch is: 183\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.290097495631926\n",
            "g_loss:[0.34133049845695496, 0.33893734216690063, 0.0011965727899223566]\n",
            "Batch:101\n",
            "d_loss:0.21633793251442057\n",
            "g_loss:[0.34289097785949707, 0.34061840176582336, 0.0011362845543771982]\n",
            "Batch:201\n",
            "d_loss:0.34646748918748926\n",
            "g_loss:[0.35644766688346863, 0.35594457387924194, 0.0002515490632504225]\n",
            "Batch:301\n",
            "d_loss:0.2365483969952038\n",
            "g_loss:[0.3678390085697174, 0.3676883578300476, 7.53186977817677e-05]\n",
            "Batch:401\n",
            "d_loss:0.5160693640584668\n",
            "g_loss:[0.3753643333911896, 0.37497377395629883, 0.00019527909171301872]\n",
            "Batch:501\n",
            "d_loss:0.19901674405946324\n",
            "g_loss:[0.3424721658229828, 0.3401000499725342, 0.0011860565282404423]\n",
            "========================================\n",
            "Epoch is: 184\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.20180741606964148\n",
            "g_loss:[0.3877719044685364, 0.3868843913078308, 0.0004437608877196908]\n",
            "Batch:101\n",
            "d_loss:0.2493783100624114\n",
            "g_loss:[0.33701008558273315, 0.33648571372032166, 0.00026218261336907744]\n",
            "Batch:201\n",
            "d_loss:0.1887603719769686\n",
            "g_loss:[0.33847588300704956, 0.3380783200263977, 0.00019878345483448356]\n",
            "Batch:301\n",
            "d_loss:0.2136833765762276\n",
            "g_loss:[0.3541593849658966, 0.3519369959831238, 0.0011111937928944826]\n",
            "Batch:401\n",
            "d_loss:0.5093994185572228\n",
            "g_loss:[0.3678849935531616, 0.36212775111198425, 0.0028786202892661095]\n",
            "Batch:501\n",
            "d_loss:0.174553473789274\n",
            "g_loss:[0.3607834577560425, 0.3602774441242218, 0.00025300460401922464]\n",
            "========================================\n",
            "Epoch is: 185\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.20437313994943906\n",
            "g_loss:[0.35631871223449707, 0.35567039251327515, 0.0003241628874093294]\n",
            "Batch:101\n",
            "d_loss:0.19798318834079964\n",
            "g_loss:[0.34541282057762146, 0.3354395031929016, 0.004986658692359924]\n",
            "Batch:201\n",
            "d_loss:0.24119025331310695\n",
            "g_loss:[0.34023240208625793, 0.33949464559555054, 0.00036888447357341647]\n",
            "Batch:301\n",
            "d_loss:0.27303716641608844\n",
            "g_loss:[0.37565648555755615, 0.37278228998184204, 0.0014371019788086414]\n",
            "Batch:401\n",
            "d_loss:0.215820775617658\n",
            "g_loss:[0.41063565015792847, 0.4095499515533447, 0.000542854075320065]\n",
            "Batch:501\n",
            "d_loss:0.19884344504134788\n",
            "g_loss:[0.3447405993938446, 0.34258636832237244, 0.0010771207744255662]\n",
            "========================================\n",
            "Epoch is: 186\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.17987371211347636\n",
            "g_loss:[0.3795746862888336, 0.3783642053604126, 0.0006052350508980453]\n",
            "Batch:101\n",
            "d_loss:0.1866708231927987\n",
            "g_loss:[0.34503689408302307, 0.3442118763923645, 0.0004125125415157527]\n",
            "Batch:201\n",
            "d_loss:0.4287657799432054\n",
            "g_loss:[0.46762216091156006, 0.46534380316734314, 0.0011391789885237813]\n",
            "Batch:301\n",
            "d_loss:0.1711685295067582\n",
            "g_loss:[0.3625643253326416, 0.3606809079647064, 0.0009417110704816878]\n",
            "Batch:401\n",
            "d_loss:0.35384267102961076\n",
            "g_loss:[0.35015082359313965, 0.349602073431015, 0.000274379039183259]\n",
            "Batch:501\n",
            "d_loss:0.27227845659217564\n",
            "g_loss:[0.37278103828430176, 0.37081119418144226, 0.000984923797659576]\n",
            "========================================\n",
            "Epoch is: 187\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.1849758552871208\n",
            "g_loss:[0.3995589315891266, 0.3984822928905487, 0.0005383139941841364]\n",
            "Batch:101\n",
            "d_loss:0.1939749557199093\n",
            "g_loss:[0.3445967733860016, 0.34028059244155884, 0.0021580872125923634]\n",
            "Batch:201\n",
            "d_loss:0.1921940573156462\n",
            "g_loss:[0.41850966215133667, 0.38086894154548645, 0.01882035657763481]\n",
            "Batch:301\n",
            "d_loss:0.2496862246243836\n",
            "g_loss:[0.364690363407135, 0.3615242838859558, 0.001583037432283163]\n",
            "Batch:401\n",
            "d_loss:0.2072629733054896\n",
            "g_loss:[0.3660620152950287, 0.3654443025588989, 0.00030886087915860116]\n",
            "Batch:501\n",
            "d_loss:0.18366755029819615\n",
            "g_loss:[0.3816028833389282, 0.3814997673034668, 5.155771941645071e-05]\n",
            "========================================\n",
            "Epoch is: 188\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.21885610615981932\n",
            "g_loss:[0.3405662477016449, 0.34045466780662537, 5.578273339779116e-05]\n",
            "Batch:101\n",
            "d_loss:0.2474330201430348\n",
            "g_loss:[0.34124740958213806, 0.34065335988998413, 0.00029702720348723233]\n",
            "Batch:201\n",
            "d_loss:0.19745733006402588\n",
            "g_loss:[0.3390314280986786, 0.33883267641067505, 9.936945571098477e-05]\n",
            "Batch:301\n",
            "d_loss:0.20064580942926113\n",
            "g_loss:[0.34555500745773315, 0.3452319800853729, 0.0001615132496226579]\n",
            "Batch:401\n",
            "d_loss:0.17803544599200904\n",
            "g_loss:[0.3790731728076935, 0.3787747621536255, 0.00014919970999471843]\n",
            "Batch:501\n",
            "d_loss:0.20329074725015062\n",
            "g_loss:[0.38973280787467957, 0.3889538049697876, 0.0003894948458764702]\n",
            "========================================\n",
            "Epoch is: 189\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.7457863918981502\n",
            "g_loss:[0.34069016575813293, 0.3400235176086426, 0.0003333231434226036]\n",
            "Batch:101\n",
            "d_loss:0.30042620220569916\n",
            "g_loss:[0.3459419906139374, 0.34555184841156006, 0.00019506830722093582]\n",
            "Batch:201\n",
            "d_loss:0.4848024125494703\n",
            "g_loss:[0.3407474458217621, 0.33979684114456177, 0.00047530006850138307]\n",
            "Batch:301\n",
            "d_loss:0.21871399496740196\n",
            "g_loss:[0.3644150495529175, 0.36383581161499023, 0.0002896252553910017]\n",
            "Batch:401\n",
            "d_loss:0.19485828327594845\n",
            "g_loss:[0.39411404728889465, 0.3925497531890869, 0.000782152870669961]\n",
            "Batch:501\n",
            "d_loss:0.36334112905115035\n",
            "g_loss:[0.34849223494529724, 0.3475028872489929, 0.000494672276545316]\n",
            "========================================\n",
            "Epoch is: 190\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.5906277103204047\n",
            "g_loss:[0.3522047698497772, 0.35050955414772034, 0.0008476112270727754]\n",
            "Batch:101\n",
            "d_loss:0.1816074762054427\n",
            "g_loss:[0.41479405760765076, 0.41155385971069336, 0.0016201038379222155]\n",
            "Batch:201\n",
            "d_loss:0.18377661439808435\n",
            "g_loss:[0.3837181627750397, 0.38206857442855835, 0.0008247891673818231]\n",
            "Batch:301\n",
            "d_loss:0.17295706148934187\n",
            "g_loss:[0.3402634561061859, 0.3395385444164276, 0.00036244853981770575]\n",
            "Batch:401\n",
            "d_loss:0.24267698638220736\n",
            "g_loss:[0.38890185952186584, 0.3860372304916382, 0.0014323149807751179]\n",
            "Batch:501\n",
            "d_loss:0.197572791491325\n",
            "g_loss:[0.3387880027294159, 0.33801645040512085, 0.0003857793053612113]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Guardo 3 imagenes\n",
            "========================================\n",
            "Epoch is: 191\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.1800304708267504\n",
            "g_loss:[0.33649852871894836, 0.3361887037754059, 0.00015490828081965446]\n",
            "Batch:101\n",
            "d_loss:0.3335428203281481\n",
            "g_loss:[0.33591416478157043, 0.333626925945282, 0.0011436250060796738]\n",
            "Batch:201\n",
            "d_loss:0.1775454842045292\n",
            "g_loss:[0.3838571012020111, 0.37721818685531616, 0.003319456009194255]\n",
            "Batch:301\n",
            "d_loss:0.173842031706954\n",
            "g_loss:[0.3752024173736572, 0.3743639290332794, 0.00041924271499738097]\n",
            "Batch:401\n",
            "d_loss:0.1764571911191979\n",
            "g_loss:[0.37556180357933044, 0.37436747550964355, 0.0005971658392809331]\n",
            "Batch:501\n",
            "d_loss:0.24020415730996092\n",
            "g_loss:[0.5201935768127441, 0.5178437232971191, 0.0011749176774173975]\n",
            "========================================\n",
            "Epoch is: 192\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2431552095367806\n",
            "g_loss:[0.34784963726997375, 0.3458494544029236, 0.0010000881738960743]\n",
            "Batch:101\n",
            "d_loss:0.20868719610189146\n",
            "g_loss:[0.3864768147468567, 0.3843109607696533, 0.001082932110875845]\n",
            "Batch:201\n",
            "d_loss:0.18809323795358068\n",
            "g_loss:[0.34972861409187317, 0.3491417169570923, 0.0002934420481324196]\n",
            "Batch:301\n",
            "d_loss:0.2968625222938499\n",
            "g_loss:[0.3434719741344452, 0.3405962288379669, 0.0014378788182511926]\n",
            "Batch:401\n",
            "d_loss:0.347786149251192\n",
            "g_loss:[0.47043129801750183, 0.45176875591278076, 0.009331267327070236]\n",
            "Batch:501\n",
            "d_loss:0.23167102179172616\n",
            "g_loss:[0.34312957525253296, 0.34251487255096436, 0.0003073581028729677]\n",
            "========================================\n",
            "Epoch is: 193\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.425105276092836\n",
            "g_loss:[0.4110560119152069, 0.41079801321029663, 0.00012899564171675593]\n",
            "Batch:101\n",
            "d_loss:0.21095397355020395\n",
            "g_loss:[0.3622555434703827, 0.36213162541389465, 6.195589958224446e-05]\n",
            "Batch:201\n",
            "d_loss:0.17901821679333807\n",
            "g_loss:[0.3406517207622528, 0.34049808979034424, 7.681279384996742e-05]\n",
            "Batch:301\n",
            "d_loss:0.21929394240032707\n",
            "g_loss:[0.33444076776504517, 0.33419573307037354, 0.00012252037413418293]\n",
            "Batch:401\n",
            "d_loss:0.2765791245519722\n",
            "g_loss:[0.45337679982185364, 0.45201486349105835, 0.0006809743354097009]\n",
            "Batch:501\n",
            "d_loss:0.3038731148417355\n",
            "g_loss:[0.40591633319854736, 0.40563952922821045, 0.00013840768951922655]\n",
            "========================================\n",
            "Epoch is: 194\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18972289308157997\n",
            "g_loss:[0.45433884859085083, 0.45277899503707886, 0.0007799332379363477]\n",
            "Batch:101\n",
            "d_loss:0.28366313828541934\n",
            "g_loss:[0.3818190395832062, 0.3814088702201843, 0.0002050776092801243]\n",
            "Batch:201\n",
            "d_loss:0.19401502008986427\n",
            "g_loss:[0.3357650339603424, 0.33453133702278137, 0.0006168510299175978]\n",
            "Batch:301\n",
            "d_loss:0.18829760595735934\n",
            "g_loss:[0.33591216802597046, 0.335721492767334, 9.533105185255408e-05]\n",
            "Batch:401\n",
            "d_loss:1.0489882808331004\n",
            "g_loss:[0.425662100315094, 0.42460575699806213, 0.0005281674093566835]\n",
            "Batch:501\n",
            "d_loss:0.534290643199256\n",
            "g_loss:[0.38285622000694275, 0.3825048804283142, 0.00017567712347954512]\n",
            "========================================\n",
            "Epoch is: 195\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.18832821981891357\n",
            "g_loss:[0.3472769558429718, 0.3460940718650818, 0.0005914382636547089]\n",
            "Batch:101\n",
            "d_loss:0.2027833818574436\n",
            "g_loss:[0.34125375747680664, 0.3403739333152771, 0.0004399128374643624]\n",
            "Batch:201\n",
            "d_loss:0.2538874444217072\n",
            "g_loss:[0.3707663416862488, 0.36973837018013, 0.0005139854620210826]\n",
            "Batch:301\n",
            "d_loss:0.22719004801592746\n",
            "g_loss:[0.35045212507247925, 0.3498496413230896, 0.00030123619944788516]\n",
            "Batch:401\n",
            "d_loss:0.19186729192867347\n",
            "g_loss:[0.34705933928489685, 0.34427475929260254, 0.0013922901125624776]\n",
            "Batch:501\n",
            "d_loss:0.3648605368371136\n",
            "g_loss:[0.43692493438720703, 0.4346686005592346, 0.0011281684273853898]\n",
            "========================================\n",
            "Epoch is: 196\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.28533933550829715\n",
            "g_loss:[0.34944722056388855, 0.34787455201148987, 0.0007863406790420413]\n",
            "Batch:101\n",
            "d_loss:0.20854598381674805\n",
            "g_loss:[0.3920016288757324, 0.3907148540019989, 0.0006433906964957714]\n",
            "Batch:201\n",
            "d_loss:0.4097730192443123\n",
            "g_loss:[0.4203086197376251, 0.4189213812351227, 0.0006936243735253811]\n",
            "Batch:301\n",
            "d_loss:0.18631397869376087\n",
            "g_loss:[0.3454066812992096, 0.34480756521224976, 0.00029955964419059455]\n",
            "Batch:401\n",
            "d_loss:0.3947204954458243\n",
            "g_loss:[0.36212989687919617, 0.35089486837387085, 0.005617509130388498]\n",
            "Batch:501\n",
            "d_loss:0.21201946037945163\n",
            "g_loss:[0.3528585731983185, 0.35216882824897766, 0.0003448684001341462]\n",
            "========================================\n",
            "Epoch is: 197\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.24968461546495746\n",
            "g_loss:[0.34810537099838257, 0.34742435812950134, 0.00034050625981763005]\n",
            "Batch:101\n",
            "d_loss:0.18611540669917304\n",
            "g_loss:[0.3399863541126251, 0.3397022485733032, 0.00014205749903339893]\n",
            "Batch:201\n",
            "d_loss:0.6631804444878071\n",
            "g_loss:[0.3434349596500397, 0.34291955828666687, 0.0002576978295110166]\n",
            "Batch:301\n",
            "d_loss:0.17244846619541931\n",
            "g_loss:[0.3435730040073395, 0.3433384299278259, 0.00011729382094927132]\n",
            "Batch:401\n",
            "d_loss:0.2897251152905653\n",
            "g_loss:[0.3456571102142334, 0.34462034702301025, 0.0005183884641155601]\n",
            "Batch:501\n",
            "d_loss:0.1724080606759344\n",
            "g_loss:[0.35199859738349915, 0.35166868567466736, 0.00016496142779942602]\n",
            "========================================\n",
            "Epoch is: 198\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.20489294784056256\n",
            "g_loss:[0.3401511013507843, 0.34001395106315613, 6.858018605271354e-05]\n",
            "Batch:101\n",
            "d_loss:0.19246254091649462\n",
            "g_loss:[0.39275750517845154, 0.39268001914024353, 3.874773028655909e-05]\n",
            "Batch:201\n",
            "d_loss:0.2533466241757196\n",
            "g_loss:[0.34444791078567505, 0.34426602721214294, 9.094511187868193e-05]\n",
            "Batch:301\n",
            "d_loss:0.19451554052011488\n",
            "g_loss:[0.4100486636161804, 0.4093722999095917, 0.0003381893038749695]\n",
            "Batch:401\n",
            "d_loss:0.2914651217901678\n",
            "g_loss:[0.3698866069316864, 0.3696466088294983, 0.00011999787238892168]\n",
            "Batch:501\n",
            "d_loss:0.19212570821719055\n",
            "g_loss:[0.35588279366493225, 0.35525646805763245, 0.00031316722743213177]\n",
            "========================================\n",
            "Epoch is: 199\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.2034597925619437\n",
            "g_loss:[0.35172510147094727, 0.3512392044067383, 0.00024295449838973582]\n",
            "Batch:101\n",
            "d_loss:0.1942073286568302\n",
            "g_loss:[0.3396165072917938, 0.33862408995628357, 0.0004962116945534945]\n",
            "Batch:201\n",
            "d_loss:0.17602933821399347\n",
            "g_loss:[0.34172433614730835, 0.34027814865112305, 0.0007230960763990879]\n",
            "Batch:301\n",
            "d_loss:0.17368870932750724\n",
            "g_loss:[0.3777654767036438, 0.37745463848114014, 0.00015542347682639956]\n",
            "Batch:401\n",
            "d_loss:0.17765614253971762\n",
            "g_loss:[0.4168527126312256, 0.41552454233169556, 0.0006640824722126126]\n",
            "Batch:501\n",
            "d_loss:0.2284125285632399\n",
            "g_loss:[0.4523274004459381, 0.4517633318901062, 0.000282036024145782]\n",
            "========================================\n",
            "Epoch is: 200\n",
            "Number of batches 505\n",
            "Batch:1\n",
            "d_loss:0.1893211553724541\n",
            "g_loss:[0.34127843379974365, 0.3407618999481201, 0.00025827408535405993]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPdYmYpG64Hk",
        "colab_type": "code",
        "outputId": "2213ba6d-f189-43a9-8b92-2ca91afbcba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "#salva alguna imagenes\n",
        "\n",
        "z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "embedding_batch = emb_test[0:batch_size]\n",
        "fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])\n",
        "\n",
        "  # Save images\n",
        "for i, img in enumerate(fake_images[:10]):\n",
        "  save_rgb_img(img, \"/content/drive/My Drive/fake_img/gen_{}_{}.png\".format(epoch, i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR479_u7HIUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# guarda los pesos de la red\n",
        "stage1_gen.save_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_gen_{}.h5\".format(epoch))\n",
        "stage1_dis.save_weights(\"/content/drive/My Drive/red_infersent_2048/stage1_gen_{}.h5\".format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}